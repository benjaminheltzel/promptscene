{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an anaconda environment called openscene as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo apt-get install libopenexr-dev # for linux\n",
    "conda create -n openscene python=3.8\n",
    "conda activate openscene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: install PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: install MinkowskiNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "brew install gcc python3 openblas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: install all the remaining dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 (optional): if you need to run multi-view feature fusion with OpenSeg (especially for your own dataset), remember to install:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "%pip install clip\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd demo && \\\n",
    "wget https://cvg-data.inf.ethz.ch/openscene/demo/demo_data.zip && \\\n",
    "unzip demo_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd gaps\n",
    "make VERBOSE=1 > make_log.txt 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Compile gaps library\n",
    "cd gaps\n",
    "make\n",
    "\n",
    "# Download and compile RNNets into gaps/pkgs/RNNets\n",
    "cd pkgs\n",
    "wget https://cvg-data.inf.ethz.ch/openscene/demo/RNNets.zip\n",
    "unzip RNNets.zip\n",
    "cd RNNets\n",
    "make\n",
    "\n",
    "# Download and compile osview into gaps/apps/osview\n",
    "# The executable will be in gaps/bin/x86_64/osview\n",
    "cd ../apps\n",
    "wget https://cvg-data.inf.ethz.ch/openscene/demo/osview.zip\n",
    "unzip osview.zip\n",
    "cd osview\n",
    "make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure you are under demo/, and you can simply run to have fun with the interactive demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../demo\n",
    "./run_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script downloads pre-processed datasets used in the OpenScene project.\n",
    "Choose from the following options:\n",
    "- 0 - ScanNet 3D (point clouds with GT semantic labels)\n",
    "- 1 - ScanNet 2D (RGB-D images with camera poses)\n",
    "- 2 - Matterport 3D (point clouds with GT semantic labels)\n",
    "- 3 - Matterport 2D (RGB-D images with camera poses)\n",
    "- 4 - nuScenes 3D - Validation Set (lidar point clouds with GT semantic labels)\n",
    "- 5 - nuScenes 3D - Training Set (lidar point clouds with GT semantic labels), 379.9G\n",
    "- 6 - nuScenes 2D (RGB images with camera poses)\n",
    "- 7 - Replica 3D (point clouds)\n",
    "- 8 - Replica 2D (RGB-D images)\n",
    "- 9 - Matterport 3D with top 40 NYU classes\n",
    "- 10 - Matterport 3D with top 80 NYU classes\n",
    "- 11- Matterport 3D with top 160 NYU classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number after !echo to download the respective dataset\n",
    "!echo \"7\" | bash scripts/download_dataset.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script downloads multi-view fused features used in the OpenScene project.\n",
    "Choose from the following options:\n",
    "- 0 - ScanNet - Multi-view fused OpenSeg features, train/val (234.8G)\n",
    "- 1 - ScanNet - Multi-view fused LSeg features, train/val (175.8G)\n",
    "- 2 - Matterport - Multi-view fused OpenSeg features, train/val (198.3G)\n",
    "- 3 - Matterport - Multi-view fused OpenSeg features, test set (66.7G)\n",
    "- 4 - Replica - Multi-view fused OpenSeg features (9.0G)\n",
    "- 5 - Matterport - Multi-view fused LSeg features (coming)\n",
    "- 6 - nuScenes - Multi-view fused OpenSeg features, validation set (165G) \n",
    "- 7 - nuScenes - Multi-view fused LSeg features (coming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number after !echo to download the respective dataset\n",
    "!echo \"4\" | bash scripts/download_fused_features.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have installed the environment and obtained the processed 3D data and multi-view fused features, you are ready to run our OpenScene disilled/ensemble model for 3D semantic segmentation, or distill your own model from scratch.\n",
    "\n",
    "### Evaluation for 3D Semantic Segmentation with a Pre-defined Labelsets\n",
    "\n",
    "Here you can evaluate OpenScene features on different dataset (ScanNet/Matterport3D/nuScenes/Replica) that have pre-defined labelsets. We already include the following labelsets in label_constants.py:\n",
    "\n",
    "- ScanNet 20 classes (wall, door, chair, ...)\n",
    "- Matterport3D 21 classes (ScanNet 20 classes + floor)\n",
    "- Matterport top 40, 80, 160 NYU classes (more rare object classes)\n",
    "- nuScenes 16 classes (road, bicycle, sidewalk, ...)\n",
    "  \n",
    "The general command to run evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ exp_dir=EXP_DIR\n",
      "+ config=CONFIG.yaml\n",
      "+ feature_type=feature_type\n",
      "+ mkdir -p EXP_DIR\n",
      "+ result_dir=EXP_DIR/result_eval\n",
      "+ export PYTHONPATH=.\n",
      "+ PYTHONPATH=.\n",
      "+ python -u run/evaluate.py --config=CONFIG.yaml feature_type feature_type save_folder EXP_DIR/result_eval\n",
      "++ date +%Y%m%d_%H%M\n",
      "+ tee -a EXP_DIR/eval-20241223_1841.log\n",
      "Traceback (most recent call last):\n",
      "  File \"run/evaluate.py\", line 18, in <module>\n",
      "    from MinkowskiEngine import SparseTensor\n",
      "ModuleNotFoundError: No module named 'MinkowskiEngine'\n"
     ]
    }
   ],
   "source": [
    "!sh run/eval.sh EXP_DIR CONFIG.yaml feature_type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openscene",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
