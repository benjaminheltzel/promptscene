{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9e7098",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/KaiyangZhou/Dassl.pytorch.git\n",
    "cd Dassl.pytorch/\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "# Install this library (no need to re-build if the source code is modified)\n",
    "python setup.py develop\n",
    "cd ..\n",
    "# Install dependencies of MaPLe\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ad673",
   "metadata": {},
   "source": [
    "### Download dataset (OxfordPets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../../datasets/data\n",
    "mkdir oxford_pets\n",
    "cd oxford_pets\n",
    "wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
    "gdown 1501r8Ber4nNKvmlFVQZ8SeUHTcdTTEqs\n",
    "tar -zxvf images.tar.gz\n",
    "tar -zxvf annotations.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f024b29",
   "metadata": {},
   "source": [
    "### Run MaPLe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# seed=1\n",
    "# trains and evaluates on base classes\n",
    "bash scripts/maple/base2new_train_maple.sh oxford_pets 1 ../../datasets/data/\n",
    "# evaluates on novel classes\n",
    "bash scripts/maple/base2new_test_maple.sh oxford_pets 1 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# seed=2\n",
    "# trains and evaluates on base classes\n",
    "bash scripts/maple/base2new_train_maple.sh oxford_pets 2 ../../datasets/data/\n",
    "# evaluates on novel classes\n",
    "bash scripts/maple/base2new_test_maple.sh oxford_pets 2 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# seed=3\n",
    "# trains and evaluates on base classes\n",
    "bash scripts/maple/base2new_train_maple.sh oxford_pets 3 ../../datasets/data/\n",
    "# evaluates on novel classes\n",
    "bash scripts/maple/base2new_test_maple.sh oxford_pets 3 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a34a4",
   "metadata": {},
   "source": [
    "## Prompt Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc8cee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this job and save the output to output/base2new/train_base/replica/shots_16/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx/seed1\n",
      "Error while terminating subprocess (pid=2879446): \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash scripts/maple_prompt_scene/base2new_train_maple_prompt_scene.sh replica 1 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40eea4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "Runing the first phase job and save the output to output/base2new/test_new/replica/shots_16/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx/seed1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/54/nanriayaka/ml3d/models/multimodal-prompt-learning/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended\n",
      "  warnings.warn(\"PyTorch version 1.7.1 or higher is recommended\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while terminating subprocess (pid=2879966): \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash scripts/maple_prompt_scene/base2new_test_maple_prompt_scene.sh replica 1 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e220989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this job and save the output to output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/seed1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/54/nanriayaka/ml3d/models/multimodal-prompt-learning/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended\n",
      "  warnings.warn(\"PyTorch version 1.7.1 or higher is recommended\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting fixed seed: 1\n",
      "***************\n",
      "** Arguments **\n",
      "***************\n",
      "backbone: \n",
      "config_file: configs/trainers/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets.yaml\n",
      "dataset_config_file: configs/datasets/replica.yaml\n",
      "eval_only: False\n",
      "head: \n",
      "load_epoch: None\n",
      "model_dir: \n",
      "no_train: False\n",
      "opts: ['DATASET.NUM_SHOTS', '16']\n",
      "output_dir: output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/seed1\n",
      "resume: \n",
      "root: ../../datasets/data/\n",
      "seed: 1\n",
      "source_domains: None\n",
      "target_domains: None\n",
      "trainer: MaPLePromptScene\n",
      "transforms: None\n",
      "************\n",
      "** Config **\n",
      "************\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 8\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 100\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 4\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: Replica\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: 16\n",
      "  ROOT: ../../datasets/data/\n",
      "  SOURCE_DOMAINS: ()\n",
      "  STL10_FOLD: -1\n",
      "  SUBSAMPLE_CLASSES: all\n",
      "  TARGET_DOMAINS: ()\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.0026\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 2\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: sgd\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: constant\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/seed1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: False\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 20\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  COCOOP:\n",
      "    CTX_INIT: \n",
      "    N_CTX: 16\n",
      "    PREC: fp16\n",
      "  COOP:\n",
      "    CLASS_TOKEN_POSITION: end\n",
      "    CSC: False\n",
      "    CTX_INIT: \n",
      "    N_CTX: 16\n",
      "    PREC: fp16\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  IVLP:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX_TEXT: 2\n",
      "    N_CTX_VISION: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH_TEXT: 9\n",
      "    PROMPT_DEPTH_VISION: 9\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MAPLE:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH: 9\n",
      "  MAPLE_PROMPT_SCENE:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH: 3\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: MaPLePromptScene\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "  VPT:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX_VISION: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH_VISION: 1\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Collecting env info ...\n",
      "** System info **\n",
      "PyTorch version: 1.12.1+cu113\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 11.3\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 20.04.4 LTS (x86_64)\n",
      "GCC version: (conda-forge gcc 9.5.0-17) 9.5.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.16.3\n",
      "Libc version: glibc-2.31\n",
      "\n",
      "Python version: 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0] (64-bit runtime)\n",
      "Python platform: Linux-5.15.0-92-generic-x86_64-with-glibc2.31\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 11.3.122\n",
      "GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090\n",
      "Nvidia driver version: 525.147.05\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.24.2\n",
      "[pip3] pytorch-lightning==1.7.2\n",
      "[pip3] torch==1.12.1+cu113\n",
      "[pip3] torch-scatter==2.1.2\n",
      "[pip3] torchvision==0.13.1+cu113\n",
      "[conda] nomkl                     3.0                           0    anaconda\n",
      "[conda] numpy                     1.24.2                   pypi_0    pypi\n",
      "[conda] pytorch-lightning         1.7.2                    pypi_0    pypi\n",
      "[conda] torch                     1.12.1+cu113             pypi_0    pypi\n",
      "[conda] torch-scatter             2.1.2                    pypi_0    pypi\n",
      "[conda] torchvision               0.13.1+cu113             pypi_0    pypi\n",
      "        Pillow (9.5.0)\n",
      "\n",
      "Loading trainer: MaPLePromptScene\n",
      "Loading dataset: Replica\n",
      "Creating a 16-shot dataset\n",
      "Saving preprocessed few-shot data to /cluster/54/nanriayaka/ml3d/datasets/data/replica_feature/split_fewshot/shot_16-seed_1.pkl\n",
      "-----------------------------------------------------------\n",
      "train: [<datasets.replica.Datum_feature object at 0x7f674c95a6e0>, <datasets.replica.Datum_feature object at 0x7f674c95a590>, <datasets.replica.Datum_feature object at 0x7f674c95a380>, <datasets.replica.Datum_feature object at 0x7f674c95a3e0>, <datasets.replica.Datum_feature object at 0x7f674c95a1a0>, <datasets.replica.Datum_feature object at 0x7f674c95a4a0>, <datasets.replica.Datum_feature object at 0x7f674c95a1d0>, <datasets.replica.Datum_feature object at 0x7f674c95a2c0>, <datasets.replica.Datum_feature object at 0x7f674c959fc0>, <datasets.replica.Datum_feature object at 0x7f674c95a320>, <datasets.replica.Datum_feature object at 0x7f674c959e10>]\n",
      "val: [<datasets.replica.Datum_feature object at 0x7f674c95a200>, <datasets.replica.Datum_feature object at 0x7f674c95a740>, <datasets.replica.Datum_feature object at 0x7f674c95a140>, <datasets.replica.Datum_feature object at 0x7f674c959f90>, <datasets.replica.Datum_feature object at 0x7f674c95a080>]\n",
      "test: [<datasets.replica.Datum_feature object at 0x7f674c95a5c0>, <datasets.replica.Datum_feature object at 0x7f674c959c60>, <datasets.replica.Datum_feature object at 0x7f674c959f30>]\n",
      "-----------------------------------------------------------\n",
      "SUBSAMPLE ALL CLASSES!\n",
      "-----------------------------------------------------------\n",
      "train: [<datasets.replica.Datum_feature object at 0x7f674c959d20>, <datasets.replica.Datum_feature object at 0x7f674c959e70>, <datasets.replica.Datum_feature object at 0x7f674c959bd0>, <datasets.replica.Datum_feature object at 0x7f674c959db0>, <datasets.replica.Datum_feature object at 0x7f674c959990>, <datasets.replica.Datum_feature object at 0x7f674c959cf0>, <datasets.replica.Datum_feature object at 0x7f674c959a50>, <datasets.replica.Datum_feature object at 0x7f674c959540>, <datasets.replica.Datum_feature object at 0x7f674c9598a0>, <datasets.replica.Datum_feature object at 0x7f674c9599c0>, <datasets.replica.Datum_feature object at 0x7f674c959780>]\n",
      "val: [<datasets.replica.Datum_feature object at 0x7f674c959900>, <datasets.replica.Datum_feature object at 0x7f674c959870>]\n",
      "test: [<datasets.replica.Datum_feature object at 0x7f674c959600>, <datasets.replica.Datum_feature object at 0x7f674c959720>]\n",
      "-----------------------------------------------------------\n",
      "Building transform_train\n",
      "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
      "+ random flip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Building transform_test\n",
      "+ resize the smaller edge to 224\n",
      "+ 224x224 center crop\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "---------  -------\n",
      "Dataset    Replica\n",
      "# classes  5\n",
      "# train_x  11\n",
      "# val      2\n",
      "# test     2\n",
      "---------  -------\n",
      "Loading CLIP (backbone: ViT-B/16)\n",
      "Building custom CLIP\n",
      "MaPLe design: Multi-modal Prompt Learning\n",
      "Initial context: \"a photo of a\"\n",
      "Number of MaPLe context words (tokens): 2\n",
      "Turning off gradients in both the image and the text encoder\n",
      "Parameters to be updated: {'prompt_learner.proj.weight', 'prompt_learner.compound_prompts_text.4', 'prompt_learner.compound_prompt_projections.3.weight', 'prompt_learner.compound_prompt_projections.0.bias', 'prompt_learner.ctx', 'prompt_learner.compound_prompt_projections.5.weight', 'prompt_learner.compound_prompts_text.3', 'prompt_learner.compound_prompt_projections.4.weight', 'prompt_learner.compound_prompt_projections.6.weight', 'prompt_learner.compound_prompt_projections.1.bias', 'prompt_learner.compound_prompts_text.0', 'prompt_learner.compound_prompts_text.5', 'prompt_learner.compound_prompts_text.6', 'prompt_learner.compound_prompt_projections.5.bias', 'prompt_learner.compound_prompts_text.1', 'prompt_learner.compound_prompt_projections.1.weight', 'prompt_learner.proj.bias', 'prompt_learner.compound_prompt_projections.7.bias', 'prompt_learner.compound_prompts_text.7', 'prompt_learner.compound_prompt_projections.0.weight', 'prompt_learner.compound_prompt_projections.7.weight', 'prompt_learner.compound_prompt_projections.2.weight', 'prompt_learner.compound_prompts_text.2', 'prompt_learner.compound_prompt_projections.2.bias', 'prompt_learner.compound_prompt_projections.3.bias', 'prompt_learner.compound_prompt_projections.4.bias', 'prompt_learner.compound_prompt_projections.6.bias'}\n",
      "Loading evaluator: Classification\n",
      "No checkpoint found, train from scratch\n",
      "Initialize tensorboard (log_dir=output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/seed1/tensorboard)\n",
      "epoch [1/2] batch [1/2] time 0.893 (0.893) data 0.245 (0.245) loss 3.8848 (3.8848) lr 1.0000e-05 eta 0:00:02\n",
      "epoch [1/2] batch [2/2] time 0.023 (0.458) data 0.000 (0.123) loss 2.5352 (3.2100) lr 2.6000e-03 eta 0:00:00\n",
      "epoch [2/2] batch [1/2] time 0.241 (0.241) data 0.209 (0.209) loss 2.2617 (2.2617) lr 2.6000e-03 eta 0:00:00\n",
      "epoch [2/2] batch [2/2] time 0.031 (0.136) data 0.000 (0.105) loss 2.3516 (2.3066) lr 1.3000e-03 eta 0:00:00\n",
      "Checkpoint saved to output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/seed1/MultiModalPromptSceneLearner/model.pth.tar-2\n",
      "Finish training\n",
      "Deploy the last-epoch model\n",
      "Evaluate on the *test* set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]\r",
      "100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\r",
      "100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[4.3750, 5.0859, 3.8438, 3.8203, 5.3633],\n",
      "        [4.5977, 5.6211, 5.2305, 7.1211, 6.8438]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "label: tensor([1, 4], device='cuda:0')\n",
      "=> result\n",
      "* total: 2\n",
      "* correct: 0\n",
      "* accuracy: 0.0%\n",
      "* error: 100.0%\n",
      "* macro_f1: 0.0%\n",
      "Elapsed: 0:00:02\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash scripts/maple_prompt_scene/xd_train_maple_prompt_scene.sh replica 1 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb54a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this job and save the output to output/evaluation/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/replica/seed1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/54/nanriayaka/ml3d/models/multimodal-prompt-learning/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended\n",
      "  warnings.warn(\"PyTorch version 1.7.1 or higher is recommended\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting fixed seed: 1\n",
      "***************\n",
      "** Arguments **\n",
      "***************\n",
      "backbone: \n",
      "config_file: configs/trainers/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets.yaml\n",
      "dataset_config_file: configs/datasets/replica.yaml\n",
      "eval_only: True\n",
      "head: \n",
      "load_epoch: 2\n",
      "model_dir: output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/seed1\n",
      "no_train: False\n",
      "opts: []\n",
      "output_dir: output/evaluation/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/replica/seed1\n",
      "resume: \n",
      "root: ../../datasets/data/\n",
      "seed: 1\n",
      "source_domains: None\n",
      "target_domains: None\n",
      "trainer: MaPLePromptScene\n",
      "transforms: None\n",
      "************\n",
      "** Config **\n",
      "************\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 8\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 100\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 4\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: Replica\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: ../../datasets/data/\n",
      "  SOURCE_DOMAINS: ()\n",
      "  STL10_FOLD: -1\n",
      "  SUBSAMPLE_CLASSES: all\n",
      "  TARGET_DOMAINS: ()\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.0026\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 2\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: sgd\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: constant\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/evaluation/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/replica/seed1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: False\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 20\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  COCOOP:\n",
      "    CTX_INIT: \n",
      "    N_CTX: 16\n",
      "    PREC: fp16\n",
      "  COOP:\n",
      "    CLASS_TOKEN_POSITION: end\n",
      "    CSC: False\n",
      "    CTX_INIT: \n",
      "    N_CTX: 16\n",
      "    PREC: fp16\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  IVLP:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX_TEXT: 2\n",
      "    N_CTX_VISION: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH_TEXT: 9\n",
      "    PROMPT_DEPTH_VISION: 9\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MAPLE:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH: 9\n",
      "  MAPLE_PROMPT_SCENE:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH: 3\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: MaPLePromptScene\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "  VPT:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX_VISION: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH_VISION: 1\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Collecting env info ...\n",
      "** System info **\n",
      "PyTorch version: 1.12.1+cu113\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 11.3\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 20.04.4 LTS (x86_64)\n",
      "GCC version: (conda-forge gcc 9.5.0-17) 9.5.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.16.3\n",
      "Libc version: glibc-2.31\n",
      "\n",
      "Python version: 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0] (64-bit runtime)\n",
      "Python platform: Linux-5.15.0-92-generic-x86_64-with-glibc2.31\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 11.3.122\n",
      "GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090\n",
      "Nvidia driver version: 525.147.05\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.24.2\n",
      "[pip3] pytorch-lightning==1.7.2\n",
      "[pip3] torch==1.12.1+cu113\n",
      "[pip3] torch-scatter==2.1.2\n",
      "[pip3] torchvision==0.13.1+cu113\n",
      "[conda] nomkl                     3.0                           0    anaconda\n",
      "[conda] numpy                     1.24.2                   pypi_0    pypi\n",
      "[conda] pytorch-lightning         1.7.2                    pypi_0    pypi\n",
      "[conda] torch                     1.12.1+cu113             pypi_0    pypi\n",
      "[conda] torch-scatter             2.1.2                    pypi_0    pypi\n",
      "[conda] torchvision               0.13.1+cu113             pypi_0    pypi\n",
      "        Pillow (9.5.0)\n",
      "\n",
      "Loading trainer: MaPLePromptScene\n",
      "Loading dataset: Replica\n",
      "-----------------------------------------------------------\n",
      "train: [<datasets.replica.Datum_feature object at 0x7f212d23a920>, <datasets.replica.Datum_feature object at 0x7f212d23a0b0>, <datasets.replica.Datum_feature object at 0x7f212d23a770>, <datasets.replica.Datum_feature object at 0x7f212d23a6e0>, <datasets.replica.Datum_feature object at 0x7f212d23a530>, <datasets.replica.Datum_feature object at 0x7f212d23a620>, <datasets.replica.Datum_feature object at 0x7f212d23a3e0>, <datasets.replica.Datum_feature object at 0x7f212d23a5c0>, <datasets.replica.Datum_feature object at 0x7f212d23a320>, <datasets.replica.Datum_feature object at 0x7f212d23a500>, <datasets.replica.Datum_feature object at 0x7f212d239db0>]\n",
      "val: [<datasets.replica.Datum_feature object at 0x7f212d23a440>, <datasets.replica.Datum_feature object at 0x7f212d23a230>, <datasets.replica.Datum_feature object at 0x7f212d23a380>, <datasets.replica.Datum_feature object at 0x7f212d23a1a0>, <datasets.replica.Datum_feature object at 0x7f212d23a2c0>]\n",
      "test: [<datasets.replica.Datum_feature object at 0x7f212d23a1d0>, <datasets.replica.Datum_feature object at 0x7f212d239e70>, <datasets.replica.Datum_feature object at 0x7f212d239f60>]\n",
      "-----------------------------------------------------------\n",
      "SUBSAMPLE ALL CLASSES!\n",
      "-----------------------------------------------------------\n",
      "train: [<datasets.replica.Datum_feature object at 0x7f212d239ea0>, <datasets.replica.Datum_feature object at 0x7f212d239e10>, <datasets.replica.Datum_feature object at 0x7f212d23a050>, <datasets.replica.Datum_feature object at 0x7f212d239e40>, <datasets.replica.Datum_feature object at 0x7f212d239f90>, <datasets.replica.Datum_feature object at 0x7f212d239d50>, <datasets.replica.Datum_feature object at 0x7f212d239ed0>, <datasets.replica.Datum_feature object at 0x7f212d239cc0>, <datasets.replica.Datum_feature object at 0x7f212d239a20>, <datasets.replica.Datum_feature object at 0x7f212d239c00>, <datasets.replica.Datum_feature object at 0x7f212d239840>]\n",
      "val: [<datasets.replica.Datum_feature object at 0x7f212d239ae0>, <datasets.replica.Datum_feature object at 0x7f212d2399c0>]\n",
      "test: [<datasets.replica.Datum_feature object at 0x7f212d239a80>, <datasets.replica.Datum_feature object at 0x7f212d239750>]\n",
      "-----------------------------------------------------------\n",
      "Building transform_train\n",
      "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building transform_test\n",
      "+ resize the smaller edge to 224\n",
      "+ 224x224 center crop\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "---------  -------\n",
      "Dataset    Replica\n",
      "# classes  5\n",
      "# train_x  11\n",
      "# val      2\n",
      "# test     2\n",
      "---------  -------\n",
      "Loading CLIP (backbone: ViT-B/16)\n",
      "Building custom CLIP\n",
      "MaPLe design: Multi-modal Prompt Learning\n",
      "Initial context: \"a photo of a\"\n",
      "Number of MaPLe context words (tokens): 2\n",
      "Turning off gradients in both the image and the text encoder\n",
      "Parameters to be updated: {'prompt_learner.proj.weight', 'prompt_learner.compound_prompts_text.2', 'prompt_learner.compound_prompts_text.5', 'prompt_learner.compound_prompt_projections.1.bias', 'prompt_learner.compound_prompt_projections.2.weight', 'prompt_learner.compound_prompt_projections.0.bias', 'prompt_learner.compound_prompts_text.4', 'prompt_learner.compound_prompts_text.1', 'prompt_learner.compound_prompts_text.6', 'prompt_learner.compound_prompt_projections.4.weight', 'prompt_learner.ctx', 'prompt_learner.compound_prompts_text.3', 'prompt_learner.compound_prompt_projections.3.weight', 'prompt_learner.compound_prompts_text.0', 'prompt_learner.proj.bias', 'prompt_learner.compound_prompt_projections.1.weight', 'prompt_learner.compound_prompt_projections.6.weight', 'prompt_learner.compound_prompt_projections.0.weight', 'prompt_learner.compound_prompt_projections.5.bias', 'prompt_learner.compound_prompt_projections.7.bias', 'prompt_learner.compound_prompt_projections.7.weight', 'prompt_learner.compound_prompt_projections.6.bias', 'prompt_learner.compound_prompt_projections.3.bias', 'prompt_learner.compound_prompt_projections.2.bias', 'prompt_learner.compound_prompt_projections.5.weight', 'prompt_learner.compound_prompt_projections.4.bias', 'prompt_learner.compound_prompts_text.7'}\n",
      "Loading evaluator: Classification\n",
      "Loading weights to MultiModalPromptSceneLearner from \"output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_16shots/seed1/MultiModalPromptSceneLearner/model.pth.tar-2\" (epoch = 2)\n",
      "Evaluate on the *test* set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]\r",
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\r",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[4.3750, 5.0859, 3.8438, 3.8203, 5.3633],\n",
      "        [4.5977, 5.6211, 5.2305, 7.1211, 6.8438]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "label: tensor([1, 4], device='cuda:0')\n",
      "=> result\n",
      "* total: 2\n",
      "* correct: 0\n",
      "* accuracy: 0.0%\n",
      "* error: 100.0%\n",
      "* macro_f1: 0.0%\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash scripts/maple_prompt_scene/xd_test_maple_prompt_scene.sh replica 1 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56909032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
