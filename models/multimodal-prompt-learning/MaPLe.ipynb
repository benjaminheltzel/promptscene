{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9e7098",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# git clone https://github.com/KaiyangZhou/Dassl.pytorch.git\n",
    "cd Dassl.pytorch/\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "# Install this library (no need to re-build if the source code is modified)\n",
    "python setup.py develop\n",
    "cd ..\n",
    "# Install dependencies of MaPLe\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ad673",
   "metadata": {},
   "source": [
    "### Download dataset (OxfordPets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../../datasets/data\n",
    "mkdir oxford_pets\n",
    "cd oxford_pets\n",
    "wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
    "gdown 1501r8Ber4nNKvmlFVQZ8SeUHTcdTTEqs\n",
    "tar -zxvf images.tar.gz\n",
    "tar -zxvf annotations.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f024b29",
   "metadata": {},
   "source": [
    "### Run MaPLe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# seed=1\n",
    "# trains and evaluates on base classes\n",
    "bash scripts/maple/base2new_train_maple.sh oxford_pets 1 ../../datasets/data/\n",
    "# evaluates on novel classes\n",
    "bash scripts/maple/base2new_test_maple.sh oxford_pets 1 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# seed=2\n",
    "# trains and evaluates on base classes\n",
    "bash scripts/maple/base2new_train_maple.sh oxford_pets 2 ../../datasets/data/\n",
    "# evaluates on novel classes\n",
    "bash scripts/maple/base2new_test_maple.sh oxford_pets 2 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# seed=3\n",
    "# trains and evaluates on base classes\n",
    "bash scripts/maple/base2new_train_maple.sh oxford_pets 3 ../../datasets/data/\n",
    "# evaluates on novel classes\n",
    "bash scripts/maple/base2new_test_maple.sh oxford_pets 3 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a34a4",
   "metadata": {},
   "source": [
    "## Prompt Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc8cee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this job and save the output to output/base2new/train_base/replica/shots_16/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx/seed1\n",
      "Error while terminating subprocess (pid=2879446): \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash scripts/maple_prompt_scene/base2new_train_maple_prompt_scene.sh replica 1 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40eea4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "Runing the first phase job and save the output to output/base2new/test_new/replica/shots_16/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx/seed1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/54/nanriayaka/ml3d/models/multimodal-prompt-learning/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended\n",
      "  warnings.warn(\"PyTorch version 1.7.1 or higher is recommended\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while terminating subprocess (pid=2879966): \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash scripts/maple_prompt_scene/base2new_test_maple_prompt_scene.sh replica 1 ../../datasets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e220989e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this job and save the output to output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/seed1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/54/nanriayaka/ml3d/models/multimodal-prompt-learning/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended\n",
      "  warnings.warn(\"PyTorch version 1.7.1 or higher is recommended\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting fixed seed: 1\n",
      "***************\n",
      "** Arguments **\n",
      "***************\n",
      "backbone: \n",
      "config_file: configs/trainers/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets.yaml\n",
      "dataset_config_file: configs/datasets/replica.yaml\n",
      "eval_only: False\n",
      "head: \n",
      "load_epoch: None\n",
      "model_dir: \n",
      "no_train: False\n",
      "opts: ['DATASET.NUM_SHOTS', '10000']\n",
      "output_dir: output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/seed1\n",
      "resume: \n",
      "root: ../../experiments/merged_pipline/run_2025-01-27-03-27-30/\n",
      "seed: 1\n",
      "source_domains: None\n",
      "target_domains: None\n",
      "trainer: MaPLePromptScene\n",
      "transforms: None\n",
      "************\n",
      "** Config **\n",
      "************\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 8\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 100\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 4\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: Replica\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: 10000\n",
      "  ROOT: ../../experiments/merged_pipline/run_2025-01-27-03-27-30/\n",
      "  SOURCE_DOMAINS: ()\n",
      "  STL10_FOLD: -1\n",
      "  SUBSAMPLE_CLASSES: all\n",
      "  TARGET_DOMAINS: ()\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.0026\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 2\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: sgd\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: constant\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/seed1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: False\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 20\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  COCOOP:\n",
      "    CTX_INIT: \n",
      "    N_CTX: 16\n",
      "    PREC: fp16\n",
      "  COOP:\n",
      "    CLASS_TOKEN_POSITION: end\n",
      "    CSC: False\n",
      "    CTX_INIT: \n",
      "    N_CTX: 16\n",
      "    PREC: fp16\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  IVLP:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX_TEXT: 2\n",
      "    N_CTX_VISION: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH_TEXT: 9\n",
      "    PROMPT_DEPTH_VISION: 9\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MAPLE:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH: 9\n",
      "  MAPLE_PROMPT_SCENE:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH: 3\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: MaPLePromptScene\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "  VPT:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX_VISION: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH_VISION: 1\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Collecting env info ...\n",
      "** System info **\n",
      "PyTorch version: 1.12.1+cu113\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 11.3\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 20.04.4 LTS (x86_64)\n",
      "GCC version: (conda-forge gcc 9.5.0-17) 9.5.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.16.3\n",
      "Libc version: glibc-2.31\n",
      "\n",
      "Python version: 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0] (64-bit runtime)\n",
      "Python platform: Linux-5.15.0-92-generic-x86_64-with-glibc2.31\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 11.3.122\n",
      "GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090\n",
      "Nvidia driver version: 525.147.05\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.24.2\n",
      "[pip3] pytorch-lightning==1.7.2\n",
      "[pip3] torch==1.12.1+cu113\n",
      "[pip3] torch-scatter==2.1.2\n",
      "[pip3] torchvision==0.13.1+cu113\n",
      "[conda] nomkl                     3.0                           0    anaconda\n",
      "[conda] numpy                     1.24.2                   pypi_0    pypi\n",
      "[conda] pytorch-lightning         1.7.2                    pypi_0    pypi\n",
      "[conda] torch                     1.12.1+cu113             pypi_0    pypi\n",
      "[conda] torch-scatter             2.1.2                    pypi_0    pypi\n",
      "[conda] torchvision               0.13.1+cu113             pypi_0    pypi\n",
      "        Pillow (9.5.0)\n",
      "\n",
      "Loading trainer: MaPLePromptScene\n",
      "Loading dataset: Replica\n",
      "Loading preprocessed few-shot data from /cluster/54/nanriayaka/ml3d/experiments/merged_pipline/run_2025-01-27-03-27-30/instance_features/split_fewshot/shot_10000-seed_1.pkl\n",
      "-----------------------------------------------------------\n",
      "train: [<datasets.replica.Datum_feature object at 0x7f63fe71f9a0>, <datasets.replica.Datum_feature object at 0x7f63f108a9b0>, <datasets.replica.Datum_feature object at 0x7f63f1088dc0>, <datasets.replica.Datum_feature object at 0x7f63f108a680>, <datasets.replica.Datum_feature object at 0x7f63f10893f0>, <datasets.replica.Datum_feature object at 0x7f63f1089210>, <datasets.replica.Datum_feature object at 0x7f63f1089ae0>, <datasets.replica.Datum_feature object at 0x7f63f1088f40>, <datasets.replica.Datum_feature object at 0x7f63f10892a0>, <datasets.replica.Datum_feature object at 0x7f63f1089300>]\n",
      "val: [<datasets.replica.Datum_feature object at 0x7f63f108a260>, <datasets.replica.Datum_feature object at 0x7f63f1089840>, <datasets.replica.Datum_feature object at 0x7f63f1089090>, <datasets.replica.Datum_feature object at 0x7f63f10898a0>, <datasets.replica.Datum_feature object at 0x7f63f108a170>, <datasets.replica.Datum_feature object at 0x7f63f108ac80>]\n",
      "test: [<datasets.replica.Datum_feature object at 0x7f63fe71f310>, <datasets.replica.Datum_feature object at 0x7f63fe71f820>, <datasets.replica.Datum_feature object at 0x7f63fe71f610>, <datasets.replica.Datum_feature object at 0x7f63fe71dea0>, <datasets.replica.Datum_feature object at 0x7f63fe71feb0>]\n",
      "-----------------------------------------------------------\n",
      "SUBSAMPLE ALL CLASSES!\n",
      "-----------------------------------------------------------\n",
      "train: [<datasets.replica.Datum_feature object at 0x7f63f108a9e0>, <datasets.replica.Datum_feature object at 0x7f63f108a500>, <datasets.replica.Datum_feature object at 0x7f63f108a440>, <datasets.replica.Datum_feature object at 0x7f63f108a2c0>, <datasets.replica.Datum_feature object at 0x7f63f108a560>, <datasets.replica.Datum_feature object at 0x7f63f108a620>, <datasets.replica.Datum_feature object at 0x7f63f108a290>, <datasets.replica.Datum_feature object at 0x7f63f108a320>, <datasets.replica.Datum_feature object at 0x7f63f108a5f0>, <datasets.replica.Datum_feature object at 0x7f63f1089f00>]\n",
      "val: [<datasets.replica.Datum_feature object at 0x7f63f1089ff0>, <datasets.replica.Datum_feature object at 0x7f63f1089810>, <datasets.replica.Datum_feature object at 0x7f63f1089f90>, <datasets.replica.Datum_feature object at 0x7f63f108aa70>, <datasets.replica.Datum_feature object at 0x7f63f10899c0>, <datasets.replica.Datum_feature object at 0x7f63f1089cf0>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: [<datasets.replica.Datum_feature object at 0x7f63f1089e70>, <datasets.replica.Datum_feature object at 0x7f63f1089a50>, <datasets.replica.Datum_feature object at 0x7f63f1089a80>, <datasets.replica.Datum_feature object at 0x7f63f1089de0>, <datasets.replica.Datum_feature object at 0x7f63f108a4d0>]\n",
      "-----------------------------------------------------------\n",
      "Label range: 0-17\n",
      "Unique labels: Counter({2: 2, 3: 2, 0: 1, 1: 1, 17: 1, 10: 1, 11: 1, 4: 1})\n",
      "Label range: 5-14\n",
      "Unique labels: Counter({12: 1, 13: 1, 14: 1, 5: 1, 6: 1, 7: 1})\n",
      "Label range: 8-16\n",
      "Unique labels: Counter({15: 1, 16: 1, 14: 1, 8: 1, 9: 1})\n",
      "Building transform_train\n",
      "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Building transform_test\n",
      "+ resize the smaller edge to 224\n",
      "+ 224x224 center crop\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "---------  -------\n",
      "Dataset    Replica\n",
      "# classes  18\n",
      "# train_x  10\n",
      "# val      6\n",
      "# test     5\n",
      "---------  -------\n",
      "Loading CLIP (backbone: ViT-B/16)\n",
      "Building custom CLIP\n",
      "MaPLe design: Multi-modal Prompt Learning\n",
      "Initial context: \"a photo of a\"\n",
      "Number of MaPLe context words (tokens): 2\n",
      "Turning off gradients in both the image and the text encoder\n",
      "Parameters to be updated: {'prompt_learner.proj.weight', 'prompt_learner.proj.bias', 'prompt_learner.compound_prompts_text.1', 'prompt_learner.compound_prompt_projections.7.weight', 'prompt_learner.compound_prompt_projections.0.weight', 'prompt_learner.compound_prompt_projections.4.bias', 'prompt_learner.compound_prompt_projections.2.bias', 'prompt_learner.compound_prompt_projections.1.weight', 'prompt_learner.compound_prompts_text.0', 'prompt_learner.compound_prompts_text.6', 'prompt_learner.compound_prompts_text.4', 'prompt_learner.compound_prompts_text.5', 'prompt_learner.compound_prompts_text.3', 'prompt_learner.compound_prompt_projections.6.weight', 'prompt_learner.compound_prompt_projections.5.weight', 'prompt_learner.compound_prompt_projections.5.bias', 'prompt_learner.compound_prompt_projections.3.weight', 'prompt_learner.compound_prompt_projections.0.bias', 'prompt_learner.ctx', 'prompt_learner.compound_prompt_projections.2.weight', 'prompt_learner.compound_prompt_projections.3.bias', 'prompt_learner.compound_prompts_text.7', 'prompt_learner.compound_prompt_projections.6.bias', 'prompt_learner.compound_prompt_projections.7.bias', 'prompt_learner.compound_prompt_projections.4.weight', 'prompt_learner.compound_prompt_projections.1.bias', 'prompt_learner.compound_prompts_text.2'}\n",
      "Loading evaluator: Classification\n",
      "No checkpoint found, train from scratch\n",
      "Initialize tensorboard (log_dir=output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/seed1/tensorboard)\n",
      "epoch [1/2] batch [1/2] time 1.596 (1.596) data 0.194 (0.194) loss 5.8828 (5.8828) lr 1.0000e-05 eta 0:00:04\n",
      "epoch [1/2] batch [2/2] time 0.070 (0.833) data 0.000 (0.097) loss 5.8828 (5.8828) lr 2.6000e-03 eta 0:00:01\n",
      "epoch [2/2] batch [1/2] time 0.225 (0.225) data 0.192 (0.192) loss 6.3047 (6.3047) lr 2.6000e-03 eta 0:00:00\n",
      "epoch [2/2] batch [2/2] time 0.031 (0.128) data 0.000 (0.096) loss 3.6641 (4.9844) lr 1.3000e-03 eta 0:00:00\n",
      "Checkpoint saved to output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/seed1/MultiModalPromptSceneLearner/model.pth.tar-2\n",
      "Finish training\n",
      "Deploy the last-epoch model\n",
      "Evaluate on the *test* set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]\r",
      "100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\r",
      "100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[ 5.4258,  7.3125,  6.4453,  7.1836,  7.6797,  6.6914,  6.1211,  5.8203,\n",
      "          5.9492,  6.4180,  6.5312,  6.9180,  5.6641,  5.7031,  6.2188,  7.6602,\n",
      "          6.3398,  7.5117],\n",
      "        [ 6.7695,  8.9844,  7.6484,  8.5000,  9.1406,  7.4414,  7.2422,  6.6094,\n",
      "          7.3906,  7.6172,  8.0312,  8.2422,  7.3789,  7.1016,  8.1875,  9.0938,\n",
      "          8.1250,  9.1484],\n",
      "        [ 7.7422,  9.8047,  9.3984,  8.6797, 10.8047,  8.8125,  8.2578,  8.8906,\n",
      "          8.6016,  8.3906,  6.8828,  9.8906,  8.4375,  9.4062,  8.7656,  9.1719,\n",
      "          7.5352,  8.1328],\n",
      "        [ 6.7695,  8.8828,  7.6289,  8.4531,  9.0156,  7.5156,  7.1797,  6.6875,\n",
      "          7.3828,  7.5117,  7.9297,  8.2734,  7.3672,  7.0742,  8.2188,  9.1797,\n",
      "          8.0391,  9.1406],\n",
      "        [ 8.1406, 10.1016,  9.6094,  8.9297, 11.0156,  8.9375,  8.8516,  9.1719,\n",
      "          9.2734,  8.2734,  6.7773, 10.4453,  9.4141, 10.2266,  9.1875,  9.0938,\n",
      "          7.6641,  7.9336]], device='cuda:0', dtype=torch.float16)\n",
      "label: tensor([15, 16, 14,  8,  9], device='cuda:0')\n",
      "=> result\n",
      "* total: 5\n",
      "* correct: 0\n",
      "* accuracy: 0.0%\n",
      "* error: 100.0%\n",
      "* macro_f1: 0.0%\n",
      "Elapsed: 0:00:03\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash scripts/maple_prompt_scene/xd_train_maple_prompt_scene.sh replica 1 ../../experiments/merged_pipline/run_2025-01-27-03-27-30/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb54a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this job and save the output to output/evaluation/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/replica/seed1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/54/nanriayaka/ml3d/models/multimodal-prompt-learning/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended\n",
      "  warnings.warn(\"PyTorch version 1.7.1 or higher is recommended\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting fixed seed: 1\n",
      "***************\n",
      "** Arguments **\n",
      "***************\n",
      "backbone: \n",
      "config_file: configs/trainers/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets.yaml\n",
      "dataset_config_file: configs/datasets/replica.yaml\n",
      "eval_only: True\n",
      "head: \n",
      "load_epoch: 2\n",
      "model_dir: output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/seed1\n",
      "no_train: False\n",
      "opts: []\n",
      "output_dir: output/evaluation/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/replica/seed1\n",
      "resume: \n",
      "root: ../../experiments/merged_pipline/run_2025-01-27-03-27-30/\n",
      "seed: 1\n",
      "source_domains: None\n",
      "target_domains: None\n",
      "trainer: MaPLePromptScene\n",
      "transforms: None\n",
      "************\n",
      "** Config **\n",
      "************\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 8\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 100\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 4\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: Replica\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: ../../experiments/merged_pipline/run_2025-01-27-03-27-30/\n",
      "  SOURCE_DOMAINS: ()\n",
      "  STL10_FOLD: -1\n",
      "  SUBSAMPLE_CLASSES: all\n",
      "  TARGET_DOMAINS: ()\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.0026\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 2\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: sgd\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: constant\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/evaluation/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/replica/seed1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: False\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 20\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  COCOOP:\n",
      "    CTX_INIT: \n",
      "    N_CTX: 16\n",
      "    PREC: fp16\n",
      "  COOP:\n",
      "    CLASS_TOKEN_POSITION: end\n",
      "    CSC: False\n",
      "    CTX_INIT: \n",
      "    N_CTX: 16\n",
      "    PREC: fp16\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  IVLP:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX_TEXT: 2\n",
      "    N_CTX_VISION: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH_TEXT: 9\n",
      "    PROMPT_DEPTH_VISION: 9\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MAPLE:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH: 9\n",
      "  MAPLE_PROMPT_SCENE:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH: 3\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: MaPLePromptScene\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "  VPT:\n",
      "    CTX_INIT: a photo of a\n",
      "    N_CTX_VISION: 2\n",
      "    PREC: fp16\n",
      "    PROMPT_DEPTH_VISION: 1\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Collecting env info ...\n",
      "** System info **\n",
      "PyTorch version: 1.12.1+cu113\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 11.3\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 20.04.4 LTS (x86_64)\n",
      "GCC version: (conda-forge gcc 9.5.0-17) 9.5.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.16.3\n",
      "Libc version: glibc-2.31\n",
      "\n",
      "Python version: 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0] (64-bit runtime)\n",
      "Python platform: Linux-5.15.0-92-generic-x86_64-with-glibc2.31\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 11.3.122\n",
      "GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090\n",
      "Nvidia driver version: 525.147.05\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.24.2\n",
      "[pip3] pytorch-lightning==1.7.2\n",
      "[pip3] torch==1.12.1+cu113\n",
      "[pip3] torch-scatter==2.1.2\n",
      "[pip3] torchvision==0.13.1+cu113\n",
      "[conda] nomkl                     3.0                           0    anaconda\n",
      "[conda] numpy                     1.24.2                   pypi_0    pypi\n",
      "[conda] pytorch-lightning         1.7.2                    pypi_0    pypi\n",
      "[conda] torch                     1.12.1+cu113             pypi_0    pypi\n",
      "[conda] torch-scatter             2.1.2                    pypi_0    pypi\n",
      "[conda] torchvision               0.13.1+cu113             pypi_0    pypi\n",
      "        Pillow (9.5.0)\n",
      "\n",
      "Loading trainer: MaPLePromptScene\n",
      "Loading dataset: Replica\n",
      "-----------------------------------------------------------\n",
      "train: [<datasets.replica.Datum_feature object at 0x7f44122d2590>, <datasets.replica.Datum_feature object at 0x7f44122d29b0>, <datasets.replica.Datum_feature object at 0x7f44122d2140>, <datasets.replica.Datum_feature object at 0x7f44122d2410>, <datasets.replica.Datum_feature object at 0x7f44122d16f0>, <datasets.replica.Datum_feature object at 0x7f44122d2050>, <datasets.replica.Datum_feature object at 0x7f44122d1b70>, <datasets.replica.Datum_feature object at 0x7f44122d1c90>, <datasets.replica.Datum_feature object at 0x7f44122d2260>, <datasets.replica.Datum_feature object at 0x7f44122d12a0>]\n",
      "val: [<datasets.replica.Datum_feature object at 0x7f44122d1f60>, <datasets.replica.Datum_feature object at 0x7f44122d15d0>, <datasets.replica.Datum_feature object at 0x7f44122d0f70>, <datasets.replica.Datum_feature object at 0x7f44122d1810>, <datasets.replica.Datum_feature object at 0x7f44122d1a80>, <datasets.replica.Datum_feature object at 0x7f44122d27a0>]\n",
      "test: [<datasets.replica.Datum_feature object at 0x7f441f963a60>, <datasets.replica.Datum_feature object at 0x7f441f963940>, <datasets.replica.Datum_feature object at 0x7f441f963b20>, <datasets.replica.Datum_feature object at 0x7f441f963bb0>, <datasets.replica.Datum_feature object at 0x7f441f963850>]\n",
      "-----------------------------------------------------------\n",
      "SUBSAMPLE ALL CLASSES!\n",
      "-----------------------------------------------------------\n",
      "train: [<datasets.replica.Datum_feature object at 0x7f44122d27d0>, <datasets.replica.Datum_feature object at 0x7f44122d11e0>, <datasets.replica.Datum_feature object at 0x7f44122d1150>, <datasets.replica.Datum_feature object at 0x7f44122d1780>, <datasets.replica.Datum_feature object at 0x7f44122d1930>, <datasets.replica.Datum_feature object at 0x7f44122d1d80>, <datasets.replica.Datum_feature object at 0x7f44122d0d90>, <datasets.replica.Datum_feature object at 0x7f44122d18a0>, <datasets.replica.Datum_feature object at 0x7f44122d23b0>, <datasets.replica.Datum_feature object at 0x7f44122d0be0>]\n",
      "val: [<datasets.replica.Datum_feature object at 0x7f44122d2770>, <datasets.replica.Datum_feature object at 0x7f44122d1030>, <datasets.replica.Datum_feature object at 0x7f44122d1180>, <datasets.replica.Datum_feature object at 0x7f44122d14e0>, <datasets.replica.Datum_feature object at 0x7f44122d0c40>, <datasets.replica.Datum_feature object at 0x7f44122d1330>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: [<datasets.replica.Datum_feature object at 0x7f44122d1540>, <datasets.replica.Datum_feature object at 0x7f44122d21a0>, <datasets.replica.Datum_feature object at 0x7f44122d1d20>, <datasets.replica.Datum_feature object at 0x7f44122d17e0>, <datasets.replica.Datum_feature object at 0x7f44122d1960>]\n",
      "-----------------------------------------------------------\n",
      "Label range: 0-17\n",
      "Unique labels: Counter({2: 2, 3: 2, 0: 1, 1: 1, 17: 1, 10: 1, 11: 1, 4: 1})\n",
      "Label range: 5-14\n",
      "Unique labels: Counter({12: 1, 13: 1, 14: 1, 5: 1, 6: 1, 7: 1})\n",
      "Label range: 8-16\n",
      "Unique labels: Counter({15: 1, 16: 1, 14: 1, 8: 1, 9: 1})\n",
      "Building transform_train\n",
      "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Building transform_test\n",
      "+ resize the smaller edge to 224\n",
      "+ 224x224 center crop\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "---------  -------\n",
      "Dataset    Replica\n",
      "# classes  18\n",
      "# train_x  10\n",
      "# val      6\n",
      "# test     5\n",
      "---------  -------\n",
      "Loading CLIP (backbone: ViT-B/16)\n",
      "Building custom CLIP\n",
      "MaPLe design: Multi-modal Prompt Learning\n",
      "Initial context: \"a photo of a\"\n",
      "Number of MaPLe context words (tokens): 2\n",
      "Turning off gradients in both the image and the text encoder\n",
      "Parameters to be updated: {'prompt_learner.compound_prompt_projections.2.weight', 'prompt_learner.compound_prompts_text.3', 'prompt_learner.compound_prompt_projections.1.weight', 'prompt_learner.compound_prompts_text.0', 'prompt_learner.proj.bias', 'prompt_learner.compound_prompt_projections.1.bias', 'prompt_learner.ctx', 'prompt_learner.compound_prompts_text.7', 'prompt_learner.compound_prompt_projections.3.bias', 'prompt_learner.compound_prompt_projections.6.weight', 'prompt_learner.compound_prompt_projections.7.bias', 'prompt_learner.compound_prompts_text.4', 'prompt_learner.compound_prompt_projections.0.weight', 'prompt_learner.compound_prompt_projections.6.bias', 'prompt_learner.compound_prompt_projections.4.bias', 'prompt_learner.compound_prompt_projections.5.weight', 'prompt_learner.proj.weight', 'prompt_learner.compound_prompt_projections.7.weight', 'prompt_learner.compound_prompt_projections.2.bias', 'prompt_learner.compound_prompt_projections.3.weight', 'prompt_learner.compound_prompt_projections.5.bias', 'prompt_learner.compound_prompt_projections.0.bias', 'prompt_learner.compound_prompts_text.2', 'prompt_learner.compound_prompt_projections.4.weight', 'prompt_learner.compound_prompts_text.5', 'prompt_learner.compound_prompts_text.1', 'prompt_learner.compound_prompts_text.6'}\n",
      "Loading evaluator: Classification\n",
      "Loading weights to MultiModalPromptSceneLearner from \"output/replica/MaPLePromptScene/vit_b16_c2_ep5_batch4_2ctx_cross_datasets_10000shots/seed1/MultiModalPromptSceneLearner/model.pth.tar-2\" (epoch = 2)\n",
      "Evaluate on the *test* set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]\r",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\r",
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[ 5.4258,  7.3125,  6.4453,  7.1836,  7.6797,  6.6914,  6.1211,  5.8203,\n",
      "          5.9492,  6.4180,  6.5312,  6.9180,  5.6641,  5.7031,  6.2188,  7.6602,\n",
      "          6.3398,  7.5117],\n",
      "        [ 6.7695,  8.9844,  7.6484,  8.5000,  9.1406,  7.4414,  7.2422,  6.6094,\n",
      "          7.3906,  7.6172,  8.0312,  8.2422,  7.3789,  7.1016,  8.1875,  9.0938,\n",
      "          8.1250,  9.1484],\n",
      "        [ 7.7422,  9.8047,  9.3984,  8.6797, 10.8047,  8.8125,  8.2578,  8.8906,\n",
      "          8.6016,  8.3906,  6.8828,  9.8906,  8.4375,  9.4062,  8.7656,  9.1719,\n",
      "          7.5352,  8.1328],\n",
      "        [ 6.7695,  8.8828,  7.6289,  8.4531,  9.0156,  7.5156,  7.1797,  6.6875,\n",
      "          7.3828,  7.5117,  7.9297,  8.2734,  7.3672,  7.0742,  8.2188,  9.1797,\n",
      "          8.0391,  9.1406],\n",
      "        [ 8.1406, 10.1016,  9.6094,  8.9297, 11.0156,  8.9375,  8.8516,  9.1719,\n",
      "          9.2734,  8.2734,  6.7773, 10.4453,  9.4141, 10.2266,  9.1875,  9.0938,\n",
      "          7.6641,  7.9336]], device='cuda:0', dtype=torch.float16)\n",
      "label: tensor([15, 16, 14,  8,  9], device='cuda:0')\n",
      "=> result\n",
      "* total: 5\n",
      "* correct: 0\n",
      "* accuracy: 0.0%\n",
      "* error: 100.0%\n",
      "* macro_f1: 0.0%\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bash scripts/maple_prompt_scene/xd_test_maple_prompt_scene.sh replica 1 ../../experiments/merged_pipline/run_2025-01-27-03-27-30/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56909032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = build_trainer(cfg)\n",
    "trainer.load_model(args.model_dir, epoch=args.load_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
