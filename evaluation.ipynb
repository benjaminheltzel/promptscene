{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f655763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import experiment\n",
    "import utils\n",
    "import clip_utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e4afecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = experiment.get_current_path()\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0506a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(output_path, \"instance_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4304d063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/test/office4_predicted_classes.pl',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/test/room2_predicted_classes.pl',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/train/office0_predicted_classes.pl',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/train/office1_predicted_classes.pl',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/train/office2_predicted_classes.pl',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/train/room0_predicted_classes.pl',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/val/office3_predicted_classes.pl',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/val/room1_predicted_classes.pl']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = utils.get_all_files_in_dir_and_subdir(path, \"classes.pl\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d273a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels = \"dataset/data/replica_split/ground_truth\"\n",
    "mask_paths = \"experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d51f15eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office4\n",
      "test\n",
      "(993008,)\n",
      "Mask 3D instance masks:  74\n",
      "torch.Size([74])\n",
      "room2\n",
      "test\n",
      "(722496,)\n",
      "Mask 3D instance masks:  80\n",
      "torch.Size([80])\n",
      "office0\n",
      "train\n",
      "(589517,)\n",
      "Mask 3D instance masks:  76\n",
      "torch.Size([76])\n",
      "office1\n",
      "train\n",
      "(423007,)\n",
      "Mask 3D instance masks:  61\n",
      "torch.Size([61])\n",
      "office2\n",
      "train\n",
      "(858623,)\n",
      "Mask 3D instance masks:  69\n",
      "torch.Size([69])\n",
      "room0\n",
      "train\n",
      "(954492,)\n",
      "Mask 3D instance masks:  73\n",
      "torch.Size([73])\n",
      "office3\n",
      "val\n",
      "(1187140,)\n",
      "Mask 3D instance masks:  63\n",
      "torch.Size([63])\n",
      "room1\n",
      "val\n",
      "(645512,)\n",
      "Mask 3D instance masks:  70\n",
      "torch.Size([70])\n",
      "Accuracy:  0.038181818181818185\n"
     ]
    }
   ],
   "source": [
    "total = 0.0\n",
    "correct = 0.0\n",
    "\n",
    "for file in files:\n",
    "    name = os.path.basename(file).split(\"_\")[0]\n",
    "    print(name)\n",
    "    split = os.path.basename(os.path.dirname(file))\n",
    "    print(split)\n",
    "    gt = np.load(os.path.join(gt_labels, f\"{name}.npy\"))\n",
    "    print(gt.shape)\n",
    "    masks = torch.load(os.path.join(mask_paths, split, f\"{name}_masks.pt\"))\n",
    "    print(\"Mask 3D instance masks: \", len(masks))\n",
    "    pred_classes = torch.load(file)\n",
    "    print(pred_classes.shape)\n",
    "    \n",
    "    for i, mask in enumerate(masks):\n",
    "        mask = mask != 0\n",
    "        gt_instance_label = int(gt[mask].mean())\n",
    "        if gt_instance_label == -1:\n",
    "            continue\n",
    "        #print(gt_instance_label, pred_classes[i])\n",
    "        if gt_instance_label == pred_classes[i]:\n",
    "            correct += 1.0\n",
    "        total += 1.0\n",
    "print(\"Accuracy: \", correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddade0b",
   "metadata": {},
   "source": [
    "## Openscene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12d8a28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/office4_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/room2_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/room1_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/office3_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office1_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/room0_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office0_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office2_features.npy']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_path = os.path.join(output_path, \"openscene\")\n",
    "npy_files = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(instance_path)\n",
    "    for file in files\n",
    "    if file.endswith(\".npy\")\n",
    "]\n",
    "npy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a79139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip_utils import extract_text_feature, REPLICA_LABELS#, MATTERPORT_LABELS_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d78b1b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use prompt engineering: a XX in a scene\n",
      "Loading CLIP ViT-B/32 model...\n",
      "Finish loading\n"
     ]
    }
   ],
   "source": [
    "labelset = list(REPLICA_LABELS)\n",
    "text_features, new_label_set = extract_text_feature(labelset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7f1c3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basket',\n",
       " 'bed',\n",
       " 'bench',\n",
       " 'bin',\n",
       " 'blanket',\n",
       " 'blinds',\n",
       " 'book',\n",
       " 'bottle',\n",
       " 'box',\n",
       " 'bowl',\n",
       " 'camera',\n",
       " 'cabinet',\n",
       " 'candle',\n",
       " 'chair',\n",
       " 'clock',\n",
       " 'cloth',\n",
       " 'comforter',\n",
       " 'cushion',\n",
       " 'desk',\n",
       " 'desk-organizer',\n",
       " 'door',\n",
       " 'indoor-plant',\n",
       " 'lamp',\n",
       " 'monitor',\n",
       " 'nightstand',\n",
       " 'panel',\n",
       " 'picture',\n",
       " 'pillar',\n",
       " 'pillow',\n",
       " 'pipe',\n",
       " 'plant-stand',\n",
       " 'plate',\n",
       " 'pot',\n",
       " 'sculpture',\n",
       " 'shelf',\n",
       " 'sofa',\n",
       " 'stool',\n",
       " 'switch',\n",
       " 'table',\n",
       " 'tablet',\n",
       " 'tissue-paper',\n",
       " 'tv-screen',\n",
       " 'tv-stand',\n",
       " 'vase',\n",
       " 'vent',\n",
       " 'wall-plug',\n",
       " 'window',\n",
       " 'rug']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0bc4b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing office4\n",
      "torch.Size([48, 512])\n",
      "torch.Size([993008, 512])\n",
      "(993008,)\n",
      "Predicted_classes:  torch.Size([993008])\n",
      "\n",
      "Processing room2\n",
      "torch.Size([48, 512])\n",
      "torch.Size([722496, 512])\n",
      "(722496,)\n",
      "Predicted_classes:  torch.Size([722496])\n",
      "\n",
      "Processing room1\n",
      "torch.Size([48, 512])\n",
      "torch.Size([645512, 512])\n",
      "(645512,)\n",
      "Predicted_classes:  torch.Size([645512])\n",
      "\n",
      "Processing office3\n",
      "torch.Size([48, 512])\n",
      "torch.Size([1187140, 512])\n",
      "(1187140,)\n",
      "Predicted_classes:  torch.Size([1187140])\n",
      "\n",
      "Processing office1\n",
      "torch.Size([48, 512])\n",
      "torch.Size([423007, 512])\n",
      "(423007,)\n",
      "Predicted_classes:  torch.Size([423007])\n",
      "\n",
      "Processing room0\n",
      "torch.Size([48, 512])\n",
      "torch.Size([954492, 512])\n",
      "(954492,)\n",
      "Predicted_classes:  torch.Size([954492])\n",
      "\n",
      "Processing office0\n",
      "torch.Size([48, 512])\n",
      "torch.Size([589517, 512])\n",
      "(589517,)\n",
      "Predicted_classes:  torch.Size([589517])\n",
      "\n",
      "Processing office2\n",
      "torch.Size([48, 512])\n",
      "torch.Size([858623, 512])\n",
      "(858623,)\n",
      "Predicted_classes:  torch.Size([858623])\n",
      "Accuracy:  0.434133585684646\n"
     ]
    }
   ],
   "source": [
    "total = 0.0\n",
    "correct = 0.0\n",
    "\n",
    "for file in npy_files:\n",
    "    instance_features = np.load(file)\n",
    "    instance_features = torch.Tensor(instance_features)\n",
    "    \n",
    "    sample_name = os.path.basename(file).split('_')[0]\n",
    "    \n",
    "    print(f\"\\nProcessing {sample_name}\")\n",
    "    \n",
    "    print(text_features.shape)\n",
    "    print(instance_features.shape)\n",
    "\n",
    "    gt = np.load(os.path.join(gt_labels, f\"{sample_name}.npy\")) \n",
    "    print(gt.shape) \n",
    "    predicted_classes, confidence_scores = clip_utils.classify_features(text_features, instance_features)\n",
    "    print(\"Predicted_classes: \", predicted_classes.shape)\n",
    "    for i,point in enumerate(gt):\n",
    "        if point == -1:\n",
    "            continue\n",
    "        total += 1.0\n",
    "        if point == predicted_classes[i]:\n",
    "            correct += 1.0\n",
    "            \n",
    "print(\"Accuracy: \", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c49b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f49ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d524e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "168bf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATTERPORT_COLOR_MAP_160 = {\n",
    "    1: (174., 199., 232.), # wall\n",
    "    2: (214., 39., 40.), # door\n",
    "    3: (186., 197., 62.), # ceiling\n",
    "    4: (152., 223., 138.), # floor\n",
    "    5: (196., 156., 148.), # picture\n",
    "    6: (197., 176., 213.), # window\n",
    "    7: (188., 189., 34.), # chair\n",
    "    8: (141., 91., 229.), # pillow\n",
    "    9: (237.0, 204.0, 37.0), # lamp\n",
    "    10: (31., 119., 180.), # cabinet\n",
    "    11: (219., 219., 141.), # curtain\n",
    "    12: (255., 152., 150.), # table\n",
    "    13: (150.0, 53.0, 56.0), # plant\n",
    "    14: (162.0, 62.0, 60.0), # mirror\n",
    "    15: (62.0, 143.0, 148.0), # towel\n",
    "    16: (112., 128., 144.), # sink\n",
    "    17: (229.0, 91.0, 104.0), # shelves\n",
    "    18: (140., 86., 75.), # sofa\n",
    "    19: (255., 187., 120.), # bed\n",
    "    20: (137.0, 63.0, 14.0), # night stand\n",
    "    21: (44., 160., 44.), # toilet\n",
    "    22: (39.0, 19.0, 208.0), # column\n",
    "    23: (64.0, 158.0, 70.0), # banister\n",
    "    24: (208.0, 49.0, 84.0), # stairs\n",
    "    25: (90.0, 119.0, 201.0), # stool\n",
    "    26: (118., 174., 76.), # vase\n",
    "    27: (143.0, 45.0, 115.0), # television\n",
    "    28: (153., 108., 234.), # pot\n",
    "    29: (247., 182., 210.), # desk\n",
    "    30: (177.0, 82.0, 239.0), # box\n",
    "    31: (58.0, 98.0, 137.0), # coffee table\n",
    "    32: (23., 190., 207.), # counter\n",
    "    33: (17.0, 242.0, 171.0), # bench\n",
    "    34: (79.0, 55.0, 137.0), # garbage bin\n",
    "    35: (127.0, 63.0, 52.0), # fireplace\n",
    "    36: (34.0, 14.0, 130.0), # clothes\n",
    "    37: (227., 119., 194.), # bathtub\n",
    "    38: (192.0, 229.0, 91.0), # book\n",
    "    39: (49.0, 206.0, 87.0), # air vent\n",
    "    40: (250., 253., 26.), # faucet\n",
    "    41: (0., 0., 0.), # unlabel/unknown\n",
    "    80: (82., 75., 227.),\n",
    "    82: (253., 59., 222.),\n",
    "    84: (240., 130., 89.),\n",
    "    86: (123., 172., 47.),\n",
    "    87: (71., 194., 133.),\n",
    "    88: (24., 94., 205.),\n",
    "    89: (134., 16., 179.),\n",
    "    90: (159., 32., 52.),\n",
    "    93: (213., 208., 88.),\n",
    "    95: (64., 158., 70.),\n",
    "    96: (18., 163., 194.),\n",
    "    97: (65., 29., 153.),\n",
    "    98: (177., 10., 109.),\n",
    "    99: (152., 83., 7.),\n",
    "    100: (83., 175., 30.),\n",
    "    101: (18., 199., 153.),\n",
    "    102: (61., 81., 208.),\n",
    "    103: (213., 85., 216.),\n",
    "    104: (170., 53., 42.),\n",
    "    105: (161., 192., 38.),\n",
    "    106: (23., 241., 91.),\n",
    "    107: (12., 103., 170.),\n",
    "    110: (151., 41., 245.),\n",
    "    112: (133., 51., 80.),\n",
    "    115: (184., 162., 91.),\n",
    "    116: (50., 138., 38.),\n",
    "    118: (31., 237., 236.),\n",
    "    120: (39., 19., 208.),\n",
    "    121: (223., 27., 180.),\n",
    "    122: (254., 141., 85.),\n",
    "    125: (97., 144., 39.),\n",
    "    128: (106., 231., 176.),\n",
    "    130: (12., 61., 162.),\n",
    "    131: (124., 66., 140.),\n",
    "    132: (137., 66., 73.),\n",
    "    134: (250., 253., 26.),\n",
    "    136: (55., 191., 73.),\n",
    "    138: (60., 126., 146.),\n",
    "    139: (153., 108., 234.),\n",
    "    140: (184., 58., 125.),\n",
    "    141: (135., 84., 14.),\n",
    "    145: (139., 248., 91.),\n",
    "    148: (53., 200., 172.),\n",
    "    154: (63., 69., 134.),\n",
    "    155: (190., 75., 186.),\n",
    "    156: (127., 63., 52.),\n",
    "    157: (141., 182., 25.),\n",
    "    159: (56., 144., 89.),\n",
    "    161: (64., 160., 250.),\n",
    "    163: (182., 86., 245.),\n",
    "    165: (139., 18., 53.),\n",
    "    166: (134., 120., 54.),\n",
    "    168: (49., 165., 42.),\n",
    "    169: (51., 128., 133.),\n",
    "    170: (44., 21., 163.),\n",
    "    177: (232., 93., 193.),\n",
    "    180: (176., 102., 54.),\n",
    "    185: (116., 217., 17.),\n",
    "    188: (54., 209., 150.),\n",
    "    191: (60., 99., 204.),\n",
    "    193: (129., 43., 144.),\n",
    "    195: (252., 100., 106.),\n",
    "    202: (187., 196., 73.),\n",
    "    208: (13., 158., 40.),\n",
    "    213: (52., 122., 152.),\n",
    "    214: (128., 76., 202.),\n",
    "    221: (187., 50., 115.),\n",
    "    229: (180., 141., 71.),\n",
    "    230: (77., 208., 35.),\n",
    "    232: (72., 183., 168.),\n",
    "    233: (97., 99., 203.),\n",
    "    242: (172., 22., 158.),\n",
    "    250: (155., 64., 40.),\n",
    "    261: (118., 159., 30.),\n",
    "    264: (69., 252., 148.),\n",
    "    276: (45., 103., 173.),\n",
    "    283: (111., 38., 149.),\n",
    "    286: (184., 9., 49.),\n",
    "    300: (188., 174., 67.),\n",
    "    304: (53., 206., 53.),\n",
    "    312: (97., 235., 252.),\n",
    "    323: (66., 32., 182.),\n",
    "    325: (236., 114., 195.),\n",
    "    331: (241., 154., 83.),\n",
    "    342: (133., 240., 52.),\n",
    "    356: (16., 205., 144.),\n",
    "    370: (75., 101., 198.),\n",
    "    392: (237., 95., 251.),\n",
    "    395: (191., 52., 49.),\n",
    "    399: (227., 254., 54.),\n",
    "    408: (49., 206., 87.),\n",
    "    417: (48., 113., 150.),\n",
    "    488: (125., 73., 182.),\n",
    "    540: (229., 32., 114.),\n",
    "    562: (158., 119., 28.),\n",
    "    570: (60., 205., 27.),\n",
    "    572: (18., 215., 201.),\n",
    "    581: (79., 76., 153.),\n",
    "    609: (134., 13., 116.),\n",
    "    748: (192., 97., 63.),\n",
    "    776: (108., 163., 18.),\n",
    "    1156: (95., 220., 156.),\n",
    "    1163: (98., 141., 208.),\n",
    "    1164: (144., 19., 193.),\n",
    "    1165: (166., 36., 57.),\n",
    "    1166: (212., 202., 34.),\n",
    "    1167: (23., 206., 34.),\n",
    "    1168: (91., 211., 236.),\n",
    "    1169: (79., 55., 137.),\n",
    "    1170: (182., 19., 117.),\n",
    "    1171: (134., 76., 14.),\n",
    "    1172: (87., 185., 28.),\n",
    "    1173: (82., 224., 187.),\n",
    "    1174: (92., 110., 214.),\n",
    "    1175: (168., 80., 171.),\n",
    "    1176: (197., 63., 51.),\n",
    "    1178: (175., 199., 77.),\n",
    "    1179: (62., 180., 98.),\n",
    "    1180: (8., 91., 150.),\n",
    "    1181: (77., 15., 130.),\n",
    "    1182: (154., 65., 96.),\n",
    "    1183: (197., 152., 11.),\n",
    "    1184: (59., 155., 45.),\n",
    "    1185: (12., 147., 145.),\n",
    "    1186: (54., 35., 219.),\n",
    "    1187: (210., 73., 181.),\n",
    "    1188: (221., 124., 77.),\n",
    "    1189: (149., 214., 66.),\n",
    "    1190: (72., 185., 134.),\n",
    "    1191: (42., 94., 198.),\n",
    "    1200: (0, 0, 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e2d1f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_labels(u_index, labels, palette, out_name, loc='lower left', ncol=7):\n",
    "    patches = []\n",
    "    for i, index in enumerate(u_index):\n",
    "        label = labels[index]\n",
    "        cur_color = [palette[index * 3] / 255.0, palette[index * 3 + 1] / 255.0, palette[index * 3 + 2] / 255.0]\n",
    "        red_patch = mpatches.Patch(color=cur_color, label=label)\n",
    "        patches.append(red_patch)\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    legend = plt.legend(frameon=False, handles=patches, loc=loc, ncol=ncol, bbox_to_anchor=(0, -0.3), prop={'size': 5}, handlelength=0.7)\n",
    "    fig  = legend.figure\n",
    "    fig.canvas.draw()\n",
    "    bbox  = legend.get_window_extent()\n",
    "    bbox = bbox.from_extents(*(bbox.extents + np.array([-5,-5,5,5])))\n",
    "    bbox = bbox.transformed(fig.dpi_scale_trans.inverted())\n",
    "    plt.savefig(out_name, bbox_inches=bbox, dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "def get_palette(num_cls=21, colormap='scannet'):\n",
    "    if colormap == 'scannet':\n",
    "        scannet_palette = []\n",
    "        for _, value in SCANNET_COLOR_MAP_20.items():\n",
    "            scannet_palette.append(np.array(value))\n",
    "        palette = np.concatenate(scannet_palette)\n",
    "    elif colormap == 'matterport':\n",
    "        scannet_palette = []\n",
    "        for _, value in MATTERPORT_COLOR_MAP_21.items():\n",
    "            scannet_palette.append(np.array(value))\n",
    "        palette = np.concatenate(scannet_palette)\n",
    "    elif colormap == 'matterport_160':\n",
    "        scannet_palette = []\n",
    "        for _, value in MATTERPORT_COLOR_MAP_160.items():\n",
    "            scannet_palette.append(np.array(value))\n",
    "        palette = np.concatenate(scannet_palette)\n",
    "    elif colormap == 'nuscenes16':\n",
    "        nuscenes16_palette = []\n",
    "        for _, value in NUSCENES16_COLORMAP.items():\n",
    "            nuscenes16_palette.append(np.array(value))\n",
    "        palette = np.concatenate(nuscenes16_palette)\n",
    "    else:\n",
    "        n = num_cls\n",
    "        palette = [0]*(n*3)\n",
    "        for j in range(0,n):\n",
    "            lab = j\n",
    "            palette[j*3+0] = 0\n",
    "            palette[j*3+1] = 0\n",
    "            palette[j*3+2] = 0\n",
    "            i = 0\n",
    "            while lab > 0:\n",
    "                palette[j*3+0] |= (((lab >> 0) & 1) << (7-i))\n",
    "                palette[j*3+1] |= (((lab >> 1) & 1) << (7-i))\n",
    "                palette[j*3+2] |= (((lab >> 2) & 1) << (7-i))\n",
    "                i = i + 1\n",
    "                lab >>= 3\n",
    "    return palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "82bb9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174. 199. 232. 214.  39.  40. 186. 197.  62. 152. 223. 138. 196. 156.\n",
      " 148. 197. 176. 213. 188. 189.  34. 141.  91. 229. 237. 204.  37.  31.\n",
      " 119. 180. 219. 219. 141. 255. 152. 150. 150.  53.  56. 162.  62.  60.\n",
      "  62. 143. 148. 112. 128. 144. 229.  91. 104. 140.  86.  75. 255. 187.\n",
      " 120. 137.  63.  14.  44. 160.  44.  39.  19. 208.  64. 158.  70. 208.\n",
      "  49.  84.  90. 119. 201. 118. 174.  76. 143.  45. 115. 153. 108. 234.\n",
      " 247. 182. 210. 177.  82. 239.  58.  98. 137.  23. 190. 207.  17. 242.\n",
      " 171.  79.  55. 137. 127.  63.  52.  34.  14. 130. 227. 119. 194. 192.\n",
      " 229.  91.  49. 206.  87. 250. 253.  26.   0.   0.   0.  82.  75. 227.\n",
      " 253.  59. 222. 240. 130.  89. 123. 172.  47.  71. 194. 133.  24.  94.\n",
      " 205. 134.  16. 179. 159.  32.  52. 213. 208.  88.  64. 158.  70.  18.\n",
      " 163. 194.  65.  29. 153. 177.  10. 109. 152.  83.   7.  83. 175.  30.\n",
      "  18. 199. 153.  61.  81. 208. 213.  85. 216. 170.  53.  42. 161. 192.\n",
      "  38.  23. 241.  91.  12. 103. 170. 151.  41. 245. 133.  51.  80. 184.\n",
      " 162.  91.  50. 138.  38.  31. 237. 236.  39.  19. 208. 223.  27. 180.\n",
      " 254. 141.  85.  97. 144.  39. 106. 231. 176.  12.  61. 162. 124.  66.\n",
      " 140. 137.  66.  73. 250. 253.  26.  55. 191.  73.  60. 126. 146. 153.\n",
      " 108. 234. 184.  58. 125. 135.  84.  14. 139. 248.  91.  53. 200. 172.\n",
      "  63.  69. 134. 190.  75. 186. 127.  63.  52. 141. 182.  25.  56. 144.\n",
      "  89.  64. 160. 250. 182.  86. 245. 139.  18.  53. 134. 120.  54.  49.\n",
      " 165.  42.  51. 128. 133.  44.  21. 163. 232.  93. 193. 176. 102.  54.\n",
      " 116. 217.  17.  54. 209. 150.  60.  99. 204. 129.  43. 144. 252. 100.\n",
      " 106. 187. 196.  73.  13. 158.  40.  52. 122. 152. 128.  76. 202. 187.\n",
      "  50. 115. 180. 141.  71.  77. 208.  35.  72. 183. 168.  97.  99. 203.\n",
      " 172.  22. 158. 155.  64.  40. 118. 159.  30.  69. 252. 148.  45. 103.\n",
      " 173. 111.  38. 149. 184.   9.  49. 188. 174.  67.  53. 206.  53.  97.\n",
      " 235. 252.  66.  32. 182. 236. 114. 195. 241. 154.  83. 133. 240.  52.\n",
      "  16. 205. 144.  75. 101. 198. 237.  95. 251. 191.  52.  49. 227. 254.\n",
      "  54.  49. 206.  87.  48. 113. 150. 125.  73. 182. 229.  32. 114. 158.\n",
      " 119.  28.  60. 205.  27.  18. 215. 201.  79.  76. 153. 134.  13. 116.\n",
      " 192.  97.  63. 108. 163.  18.  95. 220. 156.  98. 141. 208. 144.  19.\n",
      " 193. 166.  36.  57. 212. 202.  34.  23. 206.  34.  91. 211. 236.  79.\n",
      "  55. 137. 182.  19. 117. 134.  76.  14.  87. 185.  28.  82. 224. 187.\n",
      "  92. 110. 214. 168.  80. 171. 197.  63.  51. 175. 199.  77.  62. 180.\n",
      "  98.   8.  91. 150.  77.  15. 130. 154.  65.  96. 197. 152.  11.  59.\n",
      " 155.  45.  12. 147. 145.  54.  35. 219. 210.  73. 181. 221. 124.  77.\n",
      " 149. 214.  66.  72. 185. 134.  42.  94. 198.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "palette = get_palette(colormap='matterport_160')\n",
    "print(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "284e32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(output_path, \"test\")\n",
    "os.makedirs(test_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c2b328ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_labels(list(range(len(labelset))),labelset,palette, os.path.join(test_path, \"labels.png\"), ncol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1fe6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0f9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eabbd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b69d0d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/test/office4_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/test/room2_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/office0_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/office1_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/office2_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/room0_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/val/office3_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/val/room1_masks.pt']\n",
      "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/office4_input.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/room2_input.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office0_input.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office1_input.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office2_input.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/room0_input.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/office3_input.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/room1_input.ply']\n",
      "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/office4_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/room2_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office0_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office1_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office2_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/room0_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/office3_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/room1_features.npy']\n",
      "dataset/data/replica_split/ground_truth\n"
     ]
    }
   ],
   "source": [
    "mask3d_path = os.path.join(output_path, \"mask3d\")\n",
    "#split = 'val'\n",
    "mask_paths = utils.get_all_files_in_dir_and_subdir(mask3d_path, \"pt\")#sorted(glob(os.path.join(mask3d_path, split, '*.pt')))\n",
    "\n",
    "openscene_path = os.path.join(output_path, \"openscene\")\n",
    "#features_paths = sorted(glob(os.path.join(openscene_path, '*.npy')))\n",
    "point_cloud_paths = utils.get_all_files_in_dir_and_subdir(openscene_path, \"input.ply\")\n",
    "\n",
    "features_path = utils.get_all_files_in_dir_and_subdir(openscene_path, \"npy\")\n",
    "\n",
    "pred_classes = utils.get_all_files_in_dir_and_subdir(os.path.join(output_path, \"instance_features\"), \"classes.pl\")\n",
    "\n",
    "per_point_gt_paths = \"dataset/data/replica_split/ground_truth\"\n",
    "\n",
    "print(mask_paths)\n",
    "#print(features_paths)\n",
    "print(point_cloud_paths)\n",
    "print(features_path)\n",
    "print(per_point_gt_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9bb6efba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office4\n",
      "(993008, 3)\n",
      "(993008,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fdfc6ab76646c99c7b9c29e24ab664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993008, 3)\n",
      "torch.Size([74])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd3f52f457747c1990c8b5258fe2c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import point_cloud\n",
    "import open3d as o3d\n",
    "%matplotlib inline \n",
    "\n",
    "ply_data = o3d.io.read_point_cloud(point_cloud_paths[0])\n",
    "\n",
    "name = os.path.basename(point_cloud_paths[0]).split(\"_\")[0]\n",
    "print(name)\n",
    "\n",
    "# Extract points and colors\n",
    "coords = np.asarray(ply_data.points)  # 3D coordinates\n",
    "colors = np.asarray(ply_data.colors)  # RGB values (normalized to [0, 1])\n",
    "\n",
    "print(colors.shape)\n",
    "\n",
    "# Set base color\n",
    "colors[:] = 0.5\n",
    "\n",
    "# Normalize colors to 0-255 and convert to hexadecimal\n",
    "colors = (colors * 255).astype(np.uint64)\n",
    "\n",
    "gt = np.load(os.path.join(gt_labels, f\"{name}.npy\"))\n",
    "print(gt.shape)\n",
    "\n",
    "for i,point in enumerate(gt):\n",
    "    if point == -1:\n",
    "        continue\n",
    "    colors[i] = (palette[point*3],palette[point*3+1],palette[point*3+2])\n",
    "\n",
    "#for i, mask in enumerate(binary_masks):\n",
    "#    random_index = random.randint(1, len(MATTERPORT_COLOR_MAP_21)-1)\n",
    " #   colors[mask] = MATTERPORT_COLOR_MAP_21[random_index]\n",
    "\n",
    "#colors_hex = (colors[:, 0] << 16) + (colors[:, 1] << 8) + colors[:, 2]\n",
    "\n",
    "# Visualize with k3d\n",
    "point_cloud.visualize_point_cloud_with_k3d(coords, colors,point_size=2, is_norm=True, is_rgb=True).display()\n",
    "\n",
    "\n",
    "\n",
    "# Extract points and colors\n",
    "coords = np.asarray(ply_data.points)  # 3D coordinates\n",
    "colors = np.asarray(ply_data.colors)  # RGB values (normalized to [0, 1])\n",
    "\n",
    "print(colors.shape)\n",
    "\n",
    "# Set base color\n",
    "colors[:] = 0.5\n",
    "\n",
    "# Normalize colors to 0-255 and convert to hexadecimal\n",
    "colors = (colors * 255).astype(np.uint64)\n",
    "\n",
    "pred_cl = torch.load(pred_classes[0])\n",
    "print(pred_cl.shape)\n",
    "masks = torch.load(mask_paths[0])\n",
    "\n",
    "for i,mask in enumerate(masks):\n",
    "    if point == -1:\n",
    "        continue\n",
    "    colors[mask] = (palette[pred_cl[i]*3],palette[pred_cl[i]*3+1],palette[pred_cl[i]*3+2])\n",
    "\n",
    "#for i, mask in enumerate(binary_masks):\n",
    "#    random_index = random.randint(1, len(MATTERPORT_COLOR_MAP_21)-1)\n",
    " #   colors[mask] = MATTERPORT_COLOR_MAP_21[random_index]\n",
    "\n",
    "#colors_hex = (colors[:, 0] << 16) + (colors[:, 1] << 8) + colors[:, 2]\n",
    "\n",
    "# Visualize with k3d\n",
    "point_cloud.visualize_point_cloud_with_k3d(coords, colors,point_size=2, is_norm=True, is_rgb=True).display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6495b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([993008, 512])\n",
      "torch.Size([993008])\n",
      "office4\n",
      "(993008, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d64a1b40df4b95a8af7c730673b438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instance_features = torch.from_numpy(np.load(features_path[0]))\n",
    "print(instance_features.shape)\n",
    "predicted_classes, confidence_scores = clip_utils.classify_features(text_features, instance_features)\n",
    "print(predicted_classes.shape)\n",
    "\n",
    "ply_data = o3d.io.read_point_cloud(point_cloud_paths[0])\n",
    "\n",
    "name = os.path.basename(point_cloud_paths[0]).split(\"_\")[0]\n",
    "print(name)\n",
    "\n",
    "# Extract points and colors\n",
    "coords = np.asarray(ply_data.points)  # 3D coordinates\n",
    "colors = np.asarray(ply_data.colors)  # RGB values (normalized to [0, 1])\n",
    "\n",
    "print(colors.shape)\n",
    "\n",
    "# Set base color\n",
    "colors[:] = 0.5\n",
    "\n",
    "# Normalize colors to 0-255 and convert to hexadecimal\n",
    "colors = (colors * 255).astype(np.uint64)\n",
    "\n",
    "for i,point in enumerate(predicted_classes):\n",
    "    colors[i] = (palette[point*3],palette[point*3+1],palette[point*3+2])\n",
    "\n",
    "#for i, mask in enumerate(binary_masks):\n",
    "#    random_index = random.randint(1, len(MATTERPORT_COLOR_MAP_21)-1)\n",
    " #   colors[mask] = MATTERPORT_COLOR_MAP_21[random_index]\n",
    "\n",
    "#colors_hex = (colors[:, 0] << 16) + (colors[:, 1] << 8) + colors[:, 2]\n",
    "\n",
    "# Visualize with k3d\n",
    "point_cloud.visualize_point_cloud_with_k3d(coords, colors,point_size=2, is_norm=True, is_rgb=True).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fc3d24a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993008, 3)\n",
      "(993008,)\n",
      "torch.Size([74])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3f9e33d99547f38d3e0ac13d1977c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract points and colors\n",
    "coords = np.asarray(ply_data.points)  # 3D coordinates\n",
    "colors = np.asarray(ply_data.colors)  # RGB values (normalized to [0, 1])\n",
    "\n",
    "print(colors.shape)\n",
    "\n",
    "# Set base color\n",
    "colors[:] = 0.5\n",
    "\n",
    "# Normalize colors to 0-255 and convert to hexadecimal\n",
    "colors = (colors * 255).astype(np.uint64)\n",
    "\n",
    "gt = np.load(os.path.join(gt_labels, f\"{name}.npy\"))\n",
    "print(gt.shape)\n",
    "print(pred_cl.shape)\n",
    "masks = torch.load(mask_paths[0])\n",
    "\n",
    "for i,mask in enumerate(masks):\n",
    "    instance_id = int(gt[mask].mean().item())\n",
    "    if instance_id == -1:\n",
    "        continue\n",
    "    colors[mask] = (palette[instance_id*3],palette[instance_id*3+1],palette[instance_id*3+2])\n",
    "\n",
    "#for i, mask in enumerate(binary_masks):\n",
    "#    random_index = random.randint(1, len(MATTERPORT_COLOR_MAP_21)-1)\n",
    " #   colors[mask] = MATTERPORT_COLOR_MAP_21[random_index]\n",
    "\n",
    "#colors_hex = (colors[:, 0] << 16) + (colors[:, 1] << 8) + colors[:, 2]\n",
    "\n",
    "# Visualize with k3d\n",
    "point_cloud.visualize_point_cloud_with_k3d(coords, colors,point_size=2, is_norm=True, is_rgb=True).display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
