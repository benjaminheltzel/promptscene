{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb52208",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5642bee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mexperiment\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclip_utils\u001b[39;00m\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/cluster/54/blessman/ml3d/clip_utils.py:13\u001b[0m\n\u001b[1;32m      5\u001b[0m MATTERPORT_LABELS_21 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcabinet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchair\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msofa\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoor\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbookshelf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpicture\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesk\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurtain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefrigerator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshower curtain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoilet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msink\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbathtub\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mceiling\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m REPLICA_LABELS \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasket\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbench\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblanket\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblinds\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbottle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbowl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcabinet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchair\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcloth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomforter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcushion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesk-organizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindoor-plant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlamp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonitor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnightstand\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpanel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpicture\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpillar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpillow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplant-stand\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msculpture\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshelf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msofa\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     11\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstool\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswitch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtablet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtissue-paper\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtv-screen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtv-stand\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwall-plug\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrug\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m VALID_CLASS_IDS \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39masarray([\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m29\u001b[39m, \u001b[38;5;241m34\u001b[39m, \u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m37\u001b[39m, \u001b[38;5;241m44\u001b[39m, \u001b[38;5;241m47\u001b[39m, \u001b[38;5;241m52\u001b[39m, \u001b[38;5;241m54\u001b[39m, \u001b[38;5;241m56\u001b[39m, \u001b[38;5;241m59\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m61\u001b[39m, \u001b[38;5;241m62\u001b[39m, \u001b[38;5;241m63\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m65\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m71\u001b[39m, \u001b[38;5;241m76\u001b[39m, \u001b[38;5;241m78\u001b[39m, \u001b[38;5;241m79\u001b[39m, \u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m82\u001b[39m, \u001b[38;5;241m83\u001b[39m, \u001b[38;5;241m87\u001b[39m, \u001b[38;5;241m88\u001b[39m, \u001b[38;5;241m91\u001b[39m, \u001b[38;5;241m92\u001b[39m, \u001b[38;5;241m95\u001b[39m, \u001b[38;5;241m97\u001b[39m, \u001b[38;5;241m98\u001b[39m])\n\u001b[1;32m     14\u001b[0m ID_TO_LABEL \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     15\u001b[0m LABEL_TO_ID \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import experiment\n",
    "import utils\n",
    "import clip_utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = experiment.setup_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43edf63",
   "metadata": {},
   "source": [
    "## Step 1: Instance/Group Feature Extraction for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a8d1d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ exp_dir=experiments/merged_pipline/run_2025-01-28-13-51-32/openscene\n",
      "+ config=./config/openscene/replica/replica_lseg.yaml\n",
      "+ feature_type=distill\n",
      "+ mkdir -p experiments/merged_pipline/run_2025-01-28-13-51-32/openscene\n",
      "+ result_dir=experiments/merged_pipline/run_2025-01-28-13-51-32/openscene\n",
      "+ export PYTHONPATH=models/openscene\n",
      "+ PYTHONPATH=models/openscene\n",
      "+ python -u models/openscene/run/evaluate_merged.py --config=./config/openscene/replica/replica_lseg.yaml feature_type distill save_folder experiments/merged_pipline/run_2025-01-28-13-51-32/openscene\n",
      "++ date +%Y%m%d_%H%M\n",
      "+ tee -a experiments/merged_pipline/run_2025-01-28-13-51-32/openscene/eval-20250128_1351.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__:1.12.1+cu113\n",
      "torch.version.cuda:11.3\n",
      "torch.backends.cudnn.version:8302\n",
      "torch.backends.cudnn.enabled:True\n",
      "[2025-01-28 13:52:47,111 evaluate_merged.py line 167] arch_3d: MinkUNet18A\n",
      "data_root: dataset/data/replica_split\n",
      "data_root_2d_fused_feature: data/replica_multiview_openseg\n",
      "dist_backend: nccl\n",
      "dist_url: tcp://127.0.0.1:6787\n",
      "distributed: False\n",
      "eval_iou: False\n",
      "exp_dir: ./experiments/openscene/replica_split\n",
      "feature_2d_extractor: lseg\n",
      "feature_type: distill\n",
      "input_color: False\n",
      "labelset: replica\n",
      "manual_seed: 3407\n",
      "mark_no_feature_to_unknown: True\n",
      "model_path: https://cvg-data.inf.ethz.ch/openscene/models/matterport_lseg.pth.tar\n",
      "multiprocessing_distributed: False\n",
      "ngpus_per_node: 1\n",
      "prompt_eng: True\n",
      "rank: 0\n",
      "save_feature_as_numpy: True\n",
      "save_folder: experiments/merged_pipline/run_2025-01-28-13-51-32/openscene\n",
      "split: all\n",
      "sync_bn: False\n",
      "test_batch_size: 1\n",
      "test_gpu: [0]\n",
      "test_repeats: 1\n",
      "test_workers: 0\n",
      "use_apex: False\n",
      "use_augmentations: False\n",
      "use_shm: False\n",
      "vis_gt: False\n",
      "vis_input: True\n",
      "vis_pred: True\n",
      "voxel_size: 0.02\n",
      "world_size: 1\n",
      "Use prompt engineering: a XX in a scene\n",
      "Loading CLIP ViT-B/32 model...\n",
      "Finish loading\n",
      "[2025-01-28 13:55:10,943 evaluate_merged.py line 291] \n",
      "Evaluation 1 out of 1 runs...\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      " 12%|█▎        | 1/8 [00:31<03:41, 31.60s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 25%|██▌       | 2/8 [00:58<02:52, 28.79s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 38%|███▊      | 3/8 [01:19<02:05, 25.15s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 50%|█████     | 4/8 [01:34<01:24, 21.21s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 75%|███████▌  | 6/8 [02:41<00:57, 28.63s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 88%|████████▊ | 7/8 [03:25<00:33, 33.49s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      "100%|██████████| 8/8 [03:49<00:00, 28.75s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ exp_dir=experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d\n",
      "+ mkdir -p experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d\n",
      "+ result_dir=experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d\n",
      "+ export PYTHONPATH=.\n",
      "+ PYTHONPATH=.\n",
      "+ python -u models/Mask3D/predict.py general.checkpoint=models/Mask3D/checkpoints/scannet/scannet_val.ckpt general.data_dir=dataset/data/replica_split general.save_dir=experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d general.split=all general.required_confidence=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/54/blessman/ml3d/dataset\n",
      "Running on device:  cuda\n",
      "{'_target_': 'models.Res16UNet34C', 'config': {'dialations': [1, 1, 1, 1], 'conv1_kernel_size': 5, 'bn_momentum': 0.02}, 'in_channels': '${data.in_channels}', 'out_channels': '${data.num_labels}', 'out_fpn': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 14:00:59.800 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:91 - Key not found, it will be initialized randomly: model.scene_min\n",
      "2025-01-28 14:00:59.801 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:91 - Key not found, it will be initialized randomly: model.scene_max\n",
      "2025-01-28 14:00:59.930 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:115 - excessive key: model.scene_min\n",
      "2025-01-28 14:00:59.931 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:115 - excessive key: model.scene_max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint!\n",
      "Save dir:  experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d\n",
      "Data root:  dataset/data/replica_split\n",
      "Dataset:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0 from file office4 ....\n",
      "Shape of mask:  torch.Size([456153, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  97\n",
      "Shape of confidences output:  97\n",
      "Shape of masks_binary output:  97 torch.Size([993008])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 from file room2 ....\n",
      "Shape of mask:  torch.Size([318867, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  99\n",
      "Shape of confidences output:  99\n",
      "Shape of masks_binary output:  99 torch.Size([722496])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2 from file office0 ....\n",
      "Shape of mask:  torch.Size([265922, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  95\n",
      "Shape of confidences output:  95\n",
      "Shape of masks_binary output:  95 torch.Size([589517])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3 from file office1 ....\n",
      "Shape of mask:  torch.Size([180492, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  90\n",
      "Shape of confidences output:  90\n",
      "Shape of masks_binary output:  90 torch.Size([423007])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4 from file office2 ....\n",
      "Shape of mask:  torch.Size([378125, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  93\n",
      "Shape of confidences output:  93\n",
      "Shape of masks_binary output:  93 torch.Size([858623])\n",
      "Processing batch 5 from file room0 ....\n",
      "Shape of mask:  torch.Size([435468, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  97\n",
      "Shape of confidences output:  97\n",
      "Shape of masks_binary output:  97 torch.Size([954492])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6 from file office3 ....\n",
      "Shape of mask:  torch.Size([515474, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  89\n",
      "Shape of confidences output:  89\n",
      "Shape of masks_binary output:  89 torch.Size([1187140])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7 from file room1 ....\n",
      "Shape of mask:  torch.Size([277142, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  94\n",
      "Shape of confidences output:  94\n",
      "Shape of masks_binary output:  94 torch.Size([645512])\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$output_path\"\n",
    "# Run openscene\n",
    "set -x\n",
    "\n",
    "exp_dir=\"$1/openscene\"\n",
    "config=\"./config/openscene/replica/replica_lseg.yaml\"\n",
    "feature_type=distill\n",
    "\n",
    "mkdir -p \"${exp_dir}\"\n",
    "result_dir=\"${exp_dir}\"\n",
    "\n",
    "export PYTHONPATH=\"models/openscene\"\n",
    "python -u models/openscene/run/evaluate_merged.py \\\n",
    "  --config=${config} \\\n",
    "  feature_type ${feature_type} \\\n",
    "  save_folder ${result_dir} \\\n",
    "  2>&1 | tee -a ${exp_dir}/eval-$(date +\"%Y%m%d_%H%M\").log\n",
    "\n",
    "\n",
    "# Run mask3d\n",
    "exp_dir=\"$1/mask3d\"\n",
    "\n",
    "mkdir -p \"${exp_dir}\"\n",
    "result_dir=\"${exp_dir}\"\n",
    "\n",
    "export PYTHONPATH=\".\"\n",
    "python -u models/Mask3D/predict.py \\\n",
    "general.checkpoint='models/Mask3D/checkpoints/scannet/scannet_val.ckpt' \\\n",
    "general.data_dir=\"dataset/data/replica_split\" \\\n",
    "general.save_dir=${result_dir} \\\n",
    "general.split=\"all\" \\\n",
    "general.required_confidence=0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dae50e",
   "metadata": {},
   "source": [
    "### Merge point features to get per instance features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4651a0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32\n",
      "Instance masks:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d/test/office4_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d/test/room2_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d/train/office0_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d/train/office1_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d/train/office2_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d/train/room0_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d/val/office3_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/mask3d/val/room1_masks.pt']\n",
      "Per point features:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/openscene/test/office4_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/openscene/test/room2_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/openscene/train/office0_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/openscene/train/office1_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/openscene/train/office2_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/openscene/train/room0_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/openscene/val/office3_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/openscene/val/room1_features.npy']\n",
      "Processing:  office4\n",
      "Masks shape: (97, 993008)\n",
      "Features shape: (993008, 512)\n",
      "(97, 512)\n",
      "Saved instance features for office4\n",
      "Processing:  room2\n",
      "Masks shape: (99, 722496)\n",
      "Features shape: (722496, 512)\n",
      "(99, 512)\n",
      "Saved instance features for room2\n",
      "Processing:  office0\n",
      "Masks shape: (95, 589517)\n",
      "Features shape: (589517, 512)\n",
      "(95, 512)\n",
      "Saved instance features for office0\n",
      "Processing:  office1\n",
      "Masks shape: (90, 423007)\n",
      "Features shape: (423007, 512)\n",
      "(90, 512)\n",
      "Saved instance features for office1\n",
      "Processing:  office2\n",
      "Masks shape: (93, 858623)\n",
      "Features shape: (858623, 512)\n",
      "(93, 512)\n",
      "Saved instance features for office2\n",
      "Processing:  room0\n",
      "Masks shape: (97, 954492)\n",
      "Features shape: (954492, 512)\n",
      "(97, 512)\n",
      "Saved instance features for room0\n",
      "Processing:  office3\n",
      "Masks shape: (89, 1187140)\n",
      "Features shape: (1187140, 512)\n",
      "(89, 512)\n",
      "Saved instance features for office3\n",
      "Processing:  room1\n",
      "Masks shape: (94, 645512)\n",
      "Features shape: (645512, 512)\n",
      "(94, 512)\n",
      "Saved instance features for room1\n"
     ]
    }
   ],
   "source": [
    "output_path = experiment.get_current_path()\n",
    "print(output_path)\n",
    "\n",
    "utils.merge_extracted_features(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f82eb3",
   "metadata": {},
   "source": [
    "## Step 2: Reconstruct learned prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb005d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General logic based on Ayaka's code in maple_prompt_scene.py\n",
    "# Will probably need to adjust variable names and paths to match your setup\n",
    "# Should talk about it in our meeting today\n",
    "\n",
    "def reconstruct_learned_prompts(checkpoint_path, class_names, clip_model, cfg):\n",
    "    \"\"\"\n",
    "    Reconstruct learned prompts for inference using the same format as MultiModalPromptLearner.\n",
    "    \"\"\"\n",
    "    # Get config parameters matching training\n",
    "    n_ctx = cfg.TRAINER.MAPLE_PROMPT_SCENE.N_CTX\n",
    "    ctx_init = cfg.TRAINER.MAPLE_PROMPT_SCENE.CTX_INIT\n",
    "    \n",
    "    # Load learned tokens - using same state_dict key as MultiModalPromptLearner\n",
    "    state_dict = torch.load(checkpoint_path)[\"state_dict\"]\n",
    "    ctx = state_dict[\"prompt_learner.ctx\"]  # This matches self.ctx in the learner\n",
    "    \n",
    "    # Process class names\n",
    "    classnames = [name.replace(\"_\", \" \") for name in class_names]\n",
    "    prompts = [f\"{ctx_init} {name}.\" for name in classnames]\n",
    "    \n",
    "    # Tokenize using same function\n",
    "    tokenized_prompts = torch.cat([clip.tokenize(p) for p in prompts])\n",
    "    \n",
    "    # Get token embeddings\n",
    "    with torch.no_grad():\n",
    "        embedding = clip_model.token_embedding(tokenized_prompts)\n",
    "        # Extract prefix/suffix matching MultiModalPromptLearner attributes\n",
    "        token_prefix = embedding[:, :1, :]  # SOS token\n",
    "        token_suffix = embedding[:, 1 + n_ctx:, :]  # class name + EOS\n",
    "        \n",
    "        # Reconstruct full prompts same way as construct_prompts() method\n",
    "        prompts = torch.cat([\n",
    "            token_prefix,  # (n_cls, 1, dim)\n",
    "            ctx.unsqueeze(0).expand(len(classnames), -1, -1),  # (n_cls, n_ctx, dim)\n",
    "            token_suffix,  # (n_cls, *, dim)\n",
    "        ], dim=1)\n",
    "    \n",
    "    # Encode through text encoder to get CLIP embeddings\n",
    "    text_features = clip_model.encode_text(prompts)\n",
    "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    return text_features\n",
    "\n",
    "\n",
    "text_features = reconstruct_learned_prompts(\n",
    "    checkpoint_path=\"path/to/model.pth.tar-2\",\n",
    "    class_names=REPLICA_LABELS,\n",
    "    clip_model=clip_model,\n",
    "    cfg=cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1383fa2",
   "metadata": {},
   "source": [
    "## Step 3: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58f8e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/instance_features/office0_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/instance_features/office1_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/instance_features/office2_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/instance_features/office3_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/instance_features/office4_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/instance_features/room0_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/instance_features/room1_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-51-32/instance_features/room2_instance_features.npy']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = experiment.get_current_path()\n",
    "print(output_path)\n",
    "\n",
    "# Load instance feature vectors\n",
    "instance_path = os.path.join(output_path, \"instance_features\")\n",
    "utils.get_all_files_in_dir_and_subdir(instance_path, \"npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0761b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load learned prompt clip embeddings\n",
    "# TODO: load prompts and encode with clip using clip_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37439799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify features\n",
    "for file in npy_files:\n",
    "    instance_features = np.load(file)\n",
    "    instance_features = torch.Tensor(instance_features)\n",
    "    \n",
    "    sample_name = os.path.basename(file).split('_')[0]\n",
    "    \n",
    "    print(f\"Processing {sample_name}\")\n",
    "    \n",
    "    print(text_features.shape)\n",
    "    print(instance_features.shape)\n",
    "    \n",
    "    predicted_classes, confidence_scores = classify_features(text_features, instance_features)\n",
    "\n",
    "    save_path = os.path.dirname(file)\n",
    "    torch.save(predicted_classes, os.path.join(save_path, f\"{sample_name}_predicted_classes.pl\"))\n",
    "    torch.save(confidence_scores, os.path.join(save_path, f\"{sample_name}_confidence_scores.pl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
