{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e4d44d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenScene + Mask3D + MaPLe\n",
      "torch.Size([722496, 100]) (100,) (100,)\n",
      "evaluating 1 scans...\n",
      "(100,)\n",
      "(100,)\n",
      "torch.Size([722496, 100])\n",
      "scans processed: 1\n",
      "\n",
      "################################################################\n",
      "what           :             AP         AP_50%         AP_25%\n",
      "################################################################\n",
      "basket         :            nan            nan            nan\n",
      "bed            :            nan            nan            nan\n",
      "bench          :            nan            nan            nan\n",
      "bin            :            nan            nan            nan\n",
      "blanket        :            nan            nan            nan\n",
      "blinds         :          0.000          0.000          0.333\n",
      "book           :            nan            nan            nan\n",
      "bottle         :          0.000          0.000          0.000\n",
      "box            :          0.000          0.000          0.000\n",
      "bowl           :          0.000          0.000          0.000\n",
      "camera         :            nan            nan            nan\n",
      "cabinet        :            nan            nan            nan\n",
      "candle         :            nan            nan            nan\n",
      "chair          :          0.000          0.000          0.000\n",
      "clock          :            nan            nan            nan\n",
      "cloth          :            nan            nan            nan\n",
      "comforter      :            nan            nan            nan\n",
      "cushion        :            nan            nan            nan\n",
      "desk           :            nan            nan            nan\n",
      "desk-organizer :            nan            nan            nan\n",
      "door           :          0.000          0.000          0.000\n",
      "indoor-plant   :          0.000          0.000          0.000\n",
      "lamp           :          0.000          0.000          0.000\n",
      "monitor        :            nan            nan            nan\n",
      "nightstand     :            nan            nan            nan\n",
      "panel          :            nan            nan            nan\n",
      "picture        :            nan            nan            nan\n",
      "pillar         :            nan            nan            nan\n",
      "pillow         :            nan            nan            nan\n",
      "pipe           :            nan            nan            nan\n",
      "plant-stand    :            nan            nan            nan\n",
      "plate          :          0.000          0.000          0.000\n",
      "pot            :            nan            nan            nan\n",
      "sculpture      :          0.000          0.000          0.000\n",
      "shelf          :          0.000          0.000          0.000\n",
      "sofa           :            nan            nan            nan\n",
      "stool          :            nan            nan            nan\n",
      "switch         :            nan            nan            nan\n",
      "table          :          0.000          0.000          0.000\n",
      "tablet         :            nan            nan            nan\n",
      "tissue-paper   :            nan            nan            nan\n",
      "tv-screen      :            nan            nan            nan\n",
      "tv-stand       :            nan            nan            nan\n",
      "vase           :          0.000          0.000          0.000\n",
      "vent           :          0.000          0.000          0.000\n",
      "wall-plug      :            nan            nan            nan\n",
      "window         :          0.000          0.000          0.000\n",
      "rug            :          0.000          0.000          0.000\n",
      "----------------------------------------------------------------\n",
      "average        :          0.000          0.000          0.021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python evaluate/eval_semantic_instance.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aa3a74",
   "metadata": {},
   "source": [
    "## generate label with OpenScene and ground truth masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20b1e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use prompt engineering: a XX in a scene\n",
      "Loading CLIP ViT-B/32 model...\n",
      "Finish loading\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['basket',\n",
       "  'bed',\n",
       "  'bench',\n",
       "  'bin',\n",
       "  'blanket',\n",
       "  'blinds',\n",
       "  'book',\n",
       "  'bottle',\n",
       "  'box',\n",
       "  'bowl',\n",
       "  'camera',\n",
       "  'cabinet',\n",
       "  'candle',\n",
       "  'chair',\n",
       "  'clock',\n",
       "  'cloth',\n",
       "  'comforter',\n",
       "  'cushion',\n",
       "  'desk',\n",
       "  'desk-organizer',\n",
       "  'door',\n",
       "  'indoor-plant',\n",
       "  'lamp',\n",
       "  'monitor',\n",
       "  'nightstand',\n",
       "  'panel',\n",
       "  'picture',\n",
       "  'pillar',\n",
       "  'pillow',\n",
       "  'pipe',\n",
       "  'plant-stand',\n",
       "  'plate',\n",
       "  'pot',\n",
       "  'sculpture',\n",
       "  'shelf',\n",
       "  'sofa',\n",
       "  'stool',\n",
       "  'switch',\n",
       "  'table',\n",
       "  'tablet',\n",
       "  'tissue-paper',\n",
       "  'tv-screen',\n",
       "  'tv-stand',\n",
       "  'vase',\n",
       "  'vent',\n",
       "  'wall-plug',\n",
       "  'window',\n",
       "  'rug',\n",
       "  'unlabeled'],\n",
       " ['a basket in a scene',\n",
       "  'a bed in a scene',\n",
       "  'a bench in a scene',\n",
       "  'a bin in a scene',\n",
       "  'a blanket in a scene',\n",
       "  'a blinds in a scene',\n",
       "  'a book in a scene',\n",
       "  'a bottle in a scene',\n",
       "  'a box in a scene',\n",
       "  'a bowl in a scene',\n",
       "  'a camera in a scene',\n",
       "  'a cabinet in a scene',\n",
       "  'a candle in a scene',\n",
       "  'a chair in a scene',\n",
       "  'a clock in a scene',\n",
       "  'a cloth in a scene',\n",
       "  'a comforter in a scene',\n",
       "  'a cushion in a scene',\n",
       "  'a desk in a scene',\n",
       "  'a desk-organizer in a scene',\n",
       "  'a door in a scene',\n",
       "  'a indoor-plant in a scene',\n",
       "  'a lamp in a scene',\n",
       "  'a monitor in a scene',\n",
       "  'a nightstand in a scene',\n",
       "  'a panel in a scene',\n",
       "  'a picture in a scene',\n",
       "  'a pillar in a scene',\n",
       "  'a pillow in a scene',\n",
       "  'a pipe in a scene',\n",
       "  'a plant-stand in a scene',\n",
       "  'a plate in a scene',\n",
       "  'a pot in a scene',\n",
       "  'a sculpture in a scene',\n",
       "  'a shelf in a scene',\n",
       "  'a sofa in a scene',\n",
       "  'a stool in a scene',\n",
       "  'a switch in a scene',\n",
       "  'a table in a scene',\n",
       "  'a tablet in a scene',\n",
       "  'a tissue-paper in a scene',\n",
       "  'a tv-screen in a scene',\n",
       "  'a tv-stand in a scene',\n",
       "  'a vase in a scene',\n",
       "  'a vent in a scene',\n",
       "  'a wall-plug in a scene',\n",
       "  'a window in a scene',\n",
       "  'a rug in a scene'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clip_utils import extract_text_feature, REPLICA_LABELS#, MATTERPORT_LABELS_21\n",
    "labelset = list(REPLICA_LABELS)\n",
    "text_features, new_label_set = extract_text_feature(labelset)\n",
    "labelset.append('unlabeled')\n",
    "labelset, new_label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e851f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/54/nanriayaka/ml3d/experiments/merged_pipline/run_2025-01-28-04-03-04'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import experiment\n",
    "current_path = experiment.get_current_path()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14656d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "path = os.path.join(current_path, \"clip_features.pt\")\n",
    "torch.save(text_features, path)\n",
    "\n",
    "with open(os.path.join(current_path, \"labels.txt\"), 'w') as file:\n",
    "        for string in labelset:\n",
    "            file.write(string + '\\n')\n",
    "            \n",
    "with open(os.path.join(current_path, \"text_prompts.txt\"), 'w') as file:\n",
    "        for string in new_label_set:\n",
    "            file.write(string + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e5d4568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = torch.load(os.path.join(current_path, \"clip_features.pt\"))\n",
    "text_features.shape  # torch.Size([21, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c5ef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/data/replica_features/test/office4_features.npy',\n",
       " 'dataset/data/replica_features/test/room2_features.npy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_instance_path = os.path.join(\"dataset\", \"data\", \"replica_features\", \"test\")\n",
    "# instance_path = os.path.join(current_path, \"instance_features\")\n",
    "npy_files = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(gt_instance_path)\n",
    "    for file in files\n",
    "    if file.endswith(\"_features.npy\")\n",
    "]\n",
    "npy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78019707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing office4\n",
      "torch.Size([48, 512])\n",
      "torch.Size([71, 512])\n",
      "Processing room2\n",
      "torch.Size([48, 512])\n",
      "torch.Size([61, 512])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from clip_utils import classify_features\n",
    "import torch\n",
    "os.makedirs(os.path.join(current_path, \"instance_features_with_gt\"), exist_ok=True)\n",
    "for file in npy_files:\n",
    "    instance_features = np.load(file)\n",
    "    instance_features = torch.Tensor(instance_features)\n",
    "    \n",
    "    sample_name = os.path.basename(file).split('_')[0]\n",
    "    \n",
    "    print(f\"Processing {sample_name}\")\n",
    "    \n",
    "    print(text_features.shape)\n",
    "    print(instance_features.shape)\n",
    "    \n",
    "    predicted_classes, confidence_scores = classify_features(text_features, instance_features)\n",
    "\n",
    "    # save_path = os.path.dirname(file)\n",
    "    save_path = os.path.join(current_path, \"instance_features_with_gt\")\n",
    "    torch.save(predicted_classes, os.path.join(save_path, f\"{sample_name}_predicted_classes.pl\"))\n",
    "    torch.save(confidence_scores, os.path.join(save_path, f\"{sample_name}_confidence_scores.pl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5db1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0224, 0.0224, 0.0225, 0.0224, 0.0224, 0.0224, 0.0224, 0.0225, 0.0232,\n",
       "        0.0221, 0.0220, 0.0221, 0.0220, 0.0221, 0.0224, 0.0221, 0.0233, 0.0227,\n",
       "        0.0230, 0.0234, 0.0227, 0.0232, 0.0232, 0.0236, 0.0224, 0.0224, 0.0219,\n",
       "        0.0222, 0.0218, 0.0224, 0.0224, 0.0224, 0.0224, 0.0232, 0.0225, 0.0223,\n",
       "        0.0220, 0.0222, 0.0224, 0.0235, 0.0227, 0.0221, 0.0222, 0.0219, 0.0221,\n",
       "        0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
       "        0.0224, 0.0221, 0.0225, 0.0226, 0.0223, 0.0224, 0.0223])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(os.path.join(save_path, \"room2_confidence_scores.pl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6526bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
