{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e4d44d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenScene + Mask3D + MaPLe\n",
      "torch.Size([423007, 94]) torch.Size([94]) (94,)\n",
      "evaluating 1 scans...\n",
      "(94,)\n",
      "torch.Size([94])\n",
      "torch.Size([423007, 94])\n",
      "scans processed: 1\n",
      "\n",
      "################################################################\n",
      "what           :             AP         AP_50%         AP_25%\n",
      "################################################################\n",
      "basket         :            nan            nan            nan\n",
      "bed            :            nan            nan            nan\n",
      "bench          :            nan            nan            nan\n",
      "bin            :          0.396          0.583          0.583\n",
      "blanket        :          0.243          0.332          0.458\n",
      "blinds         :          0.000          0.000          0.000\n",
      "book           :            nan            nan            nan\n",
      "bottle         :            nan            nan            nan\n",
      "box            :            nan            nan            nan\n",
      "bowl           :            nan            nan            nan\n",
      "camera         :            nan            nan            nan\n",
      "cabinet        :            nan            nan            nan\n",
      "candle         :            nan            nan            nan\n",
      "chair          :          1.000          1.000          1.000\n",
      "clock          :            nan            nan            nan\n",
      "cloth          :          0.000          0.000          0.000\n",
      "comforter      :            nan            nan            nan\n",
      "cushion        :            nan            nan            nan\n",
      "desk           :          0.000          0.000          0.000\n",
      "desk-organizer :          0.000          0.000          0.000\n",
      "door           :          0.000          0.000          0.000\n",
      "indoor-plant   :            nan            nan            nan\n",
      "lamp           :          0.000          0.000          0.000\n",
      "monitor        :          0.000          0.000          0.000\n",
      "nightstand     :            nan            nan            nan\n",
      "panel          :          0.167          0.250          1.000\n",
      "picture        :            nan            nan            nan\n",
      "pillar         :          0.000          0.000          0.000\n",
      "pillow         :          0.403          0.500          0.500\n",
      "pipe           :            nan            nan            nan\n",
      "plant-stand    :            nan            nan            nan\n",
      "plate          :            nan            nan            nan\n",
      "pot            :            nan            nan            nan\n",
      "sculpture      :            nan            nan            nan\n",
      "shelf          :            nan            nan            nan\n",
      "sofa           :            nan            nan            nan\n",
      "stool          :            nan            nan            nan\n",
      "switch         :            nan            nan            nan\n",
      "table          :          0.000          0.000          0.000\n",
      "tablet         :            nan            nan            nan\n",
      "tissue-paper   :          0.000          0.000          0.000\n",
      "tv-screen      :            nan            nan            nan\n",
      "tv-stand       :            nan            nan            nan\n",
      "vase           :            nan            nan            nan\n",
      "vent           :          0.056          0.500          0.500\n",
      "wall-plug      :          0.000          0.000          0.000\n",
      "window         :            nan            nan            nan\n",
      "rug            :            nan            nan            nan\n",
      "----------------------------------------------------------------\n",
      "average        :          0.133          0.186          0.238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python evaluate/eval_semantic_instance.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aa3a74",
   "metadata": {},
   "source": [
    "## generate label with OpenScene and ground truth masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e851f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/54/nanriayaka/ml3d/experiments/merged_pipline/run_2025-01-28-04-03-04'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import experiment\n",
    "current_path = experiment.get_current_path()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20b1e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use prompt engineering: a XX in a scene\n",
      "Loading CLIP ViT-B/32 model...\n",
      "Finish loading\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['basket',\n",
       "  'bed',\n",
       "  'bench',\n",
       "  'bin',\n",
       "  'blanket',\n",
       "  'blinds',\n",
       "  'book',\n",
       "  'bottle',\n",
       "  'box',\n",
       "  'bowl',\n",
       "  'camera',\n",
       "  'cabinet',\n",
       "  'candle',\n",
       "  'chair',\n",
       "  'clock',\n",
       "  'cloth',\n",
       "  'comforter',\n",
       "  'cushion',\n",
       "  'desk',\n",
       "  'desk-organizer',\n",
       "  'door',\n",
       "  'indoor-plant',\n",
       "  'lamp',\n",
       "  'monitor',\n",
       "  'nightstand',\n",
       "  'panel',\n",
       "  'picture',\n",
       "  'pillar',\n",
       "  'pillow',\n",
       "  'pipe',\n",
       "  'plant-stand',\n",
       "  'plate',\n",
       "  'pot',\n",
       "  'sculpture',\n",
       "  'shelf',\n",
       "  'sofa',\n",
       "  'stool',\n",
       "  'switch',\n",
       "  'table',\n",
       "  'tablet',\n",
       "  'tissue-paper',\n",
       "  'tv-screen',\n",
       "  'tv-stand',\n",
       "  'vase',\n",
       "  'vent',\n",
       "  'wall-plug',\n",
       "  'window',\n",
       "  'rug',\n",
       "  'unlabeled'],\n",
       " ['a photo of a basket.',\n",
       "  'a photo of a bed.',\n",
       "  'a photo of a bench.',\n",
       "  'a photo of a bin.',\n",
       "  'a photo of a blanket.',\n",
       "  'a photo of a blinds.',\n",
       "  'a photo of a book.',\n",
       "  'a photo of a bottle.',\n",
       "  'a photo of a box.',\n",
       "  'a photo of a bowl.',\n",
       "  'a photo of a camera.',\n",
       "  'a photo of a cabinet.',\n",
       "  'a photo of a candle.',\n",
       "  'a photo of a chair.',\n",
       "  'a photo of a clock.',\n",
       "  'a photo of a cloth.',\n",
       "  'a photo of a comforter.',\n",
       "  'a photo of a cushion.',\n",
       "  'a photo of a desk.',\n",
       "  'a photo of a desk-organizer.',\n",
       "  'a photo of a door.',\n",
       "  'a photo of a indoor-plant.',\n",
       "  'a photo of a lamp.',\n",
       "  'a photo of a monitor.',\n",
       "  'a photo of a nightstand.',\n",
       "  'a photo of a panel.',\n",
       "  'a photo of a picture.',\n",
       "  'a photo of a pillar.',\n",
       "  'a photo of a pillow.',\n",
       "  'a photo of a pipe.',\n",
       "  'a photo of a plant-stand.',\n",
       "  'a photo of a plate.',\n",
       "  'a photo of a pot.',\n",
       "  'a photo of a sculpture.',\n",
       "  'a photo of a shelf.',\n",
       "  'a photo of a sofa.',\n",
       "  'a photo of a stool.',\n",
       "  'a photo of a switch.',\n",
       "  'a photo of a table.',\n",
       "  'a photo of a tablet.',\n",
       "  'a photo of a tissue-paper.',\n",
       "  'a photo of a tv-screen.',\n",
       "  'a photo of a tv-stand.',\n",
       "  'a photo of a vase.',\n",
       "  'a photo of a vent.',\n",
       "  'a photo of a wall-plug.',\n",
       "  'a photo of a window.',\n",
       "  'a photo of a rug.'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clip_utils import extract_text_feature, REPLICA_LABELS#, MATTERPORT_LABELS_21\n",
    "labelset = list(REPLICA_LABELS)\n",
    "text_features, new_label_set = extract_text_feature(labelset)\n",
    "labelset.append('unlabeled')\n",
    "labelset, new_label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c5ef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/data/replica_features/test/office4_features.npy',\n",
       " 'dataset/data/replica_features/test/room2_features.npy',\n",
       " 'dataset/data/replica_features/val/room1_features.npy',\n",
       " 'dataset/data/replica_features/val/office3_features.npy',\n",
       " 'dataset/data/replica_features/train/office1_features.npy',\n",
       " 'dataset/data/replica_features/train/room0_features.npy',\n",
       " 'dataset/data/replica_features/train/office0_features.npy',\n",
       " 'dataset/data/replica_features/train/office2_features.npy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "gt_instance_path = os.path.join(\"dataset\", \"data\", \"replica_features\")\n",
    "# instance_path = os.path.join(current_path, \"instance_features\")\n",
    "npy_files = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(gt_instance_path)\n",
    "    for file in files\n",
    "    if file.endswith(\"_features.npy\")\n",
    "]\n",
    "npy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78019707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing office4\n",
      "torch.Size([48, 512])\n",
      "torch.Size([71, 512])\n",
      "Processing room2\n",
      "torch.Size([48, 512])\n",
      "torch.Size([61, 512])\n",
      "Processing room1\n",
      "torch.Size([48, 512])\n",
      "torch.Size([57, 512])\n",
      "Processing office3\n",
      "torch.Size([48, 512])\n",
      "torch.Size([113, 512])\n",
      "Processing office1\n",
      "torch.Size([48, 512])\n",
      "torch.Size([52, 512])\n",
      "Processing room0\n",
      "torch.Size([48, 512])\n",
      "torch.Size([94, 512])\n",
      "Processing office0\n",
      "torch.Size([48, 512])\n",
      "torch.Size([68, 512])\n",
      "Processing office2\n",
      "torch.Size([48, 512])\n",
      "torch.Size([94, 512])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from clip_utils import classify_features\n",
    "import torch\n",
    "os.makedirs(os.path.join(current_path, \"instance_features_with_gt\"), exist_ok=True)\n",
    "for file in npy_files:\n",
    "    instance_features = np.load(file)\n",
    "    instance_features = torch.Tensor(instance_features)\n",
    "    \n",
    "    sample_name = os.path.basename(file).split('_')[0]\n",
    "    \n",
    "    print(f\"Processing {sample_name}\")\n",
    "    \n",
    "    print(text_features.shape)\n",
    "    print(instance_features.shape)\n",
    "    \n",
    "    predicted_classes, confidence_scores = classify_features(text_features, instance_features)\n",
    "\n",
    "    # save_path = os.path.dirname(file)\n",
    "    save_path = os.path.join(current_path, \"instance_features_with_gt\")\n",
    "    torch.save(predicted_classes, os.path.join(save_path, f\"{sample_name}_predicted_classes.pl\"))\n",
    "    torch.save(confidence_scores, os.path.join(save_path, f\"{sample_name}_confidence_scores.pl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5db1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0224, 0.0224, 0.0225, 0.0224, 0.0224, 0.0224, 0.0224, 0.0225, 0.0232,\n",
       "        0.0221, 0.0220, 0.0221, 0.0220, 0.0221, 0.0224, 0.0221, 0.0233, 0.0227,\n",
       "        0.0230, 0.0234, 0.0227, 0.0232, 0.0232, 0.0236, 0.0224, 0.0224, 0.0219,\n",
       "        0.0222, 0.0218, 0.0224, 0.0224, 0.0224, 0.0224, 0.0232, 0.0225, 0.0223,\n",
       "        0.0220, 0.0222, 0.0224, 0.0235, 0.0227, 0.0221, 0.0222, 0.0219, 0.0221,\n",
       "        0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
       "        0.0224, 0.0221, 0.0225, 0.0226, 0.0223, 0.0224, 0.0223])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(os.path.join(save_path, \"room2_confidence_scores.pl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6526bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
