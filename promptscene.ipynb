{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: OpenPrompt: Open-Vocabulary 3D Scene Understanding and Instance Segmentation with Adaptive Prompt Learning\n",
    "\n",
    "### Dataset\n",
    "- **Replica Dataset**  \n",
    "  - Download link: [Replica dataset](https://github.com/aminebdj/OpenYOLO3D/blob/main/scripts/get_replica_dataset.sh)\n",
    "\n",
    "### Evaluation Script\n",
    "- **Replica Evaluation Script**  \n",
    "  - Link: [Replica evaluation script](https://github.com/aminebdj/OpenYOLO3D/tree/main/evaluate/replica)\n",
    "\n",
    "### Reference Papers for Prompt Learning\n",
    "1. **Align Your Prompts:** Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization\n",
    "2. **MaPLe:** Multi-modal Prompt Learning\n",
    "\n",
    "### Modifications and Goals\n",
    "1. **Objective:**  \n",
    "   Create an open-vocabulary 3D instance segmentation pipeline.\n",
    "   - Use **OpenScene** for feature extraction.\n",
    "   - Use **Mask3D** for class-agnostic proposal generation.\n",
    "\n",
    "2. **Testing:**  \n",
    "   Evaluate open-vocabulary instance segmentation results on the **Replica dataset**.  \n",
    "   - Metric: **Mean Average Precision (mAP)**  \n",
    "   - Evaluation script: Provided above.\n",
    "\n",
    "3. **Baseline and Improvements:**  \n",
    "   - Start with baseline model results.\n",
    "   - Implement **prompt learning** to improve performance.\n",
    "\n",
    "### Prompt Learning Details\n",
    "- Replace the fixed text features from the **CLIP text encoder** with a **trainable prompt** initialized with a text prompt.\n",
    "- **Training Objective:** Reduce the cosine similarity between visual features of the same object when augmented in different ways (e.g., translations, rotations, or color changes).  \n",
    "- Ensure consistency in visual features of the same object across augmentations by optimizing the learnable prompt during training.\n",
    "\n",
    "### Summary\n",
    "- Develop and test an open-vocabulary 3D instance segmentation pipeline with the specified modifications.\n",
    "- Leverage prompt learning techniques to enhance the baseline model's performance on the **Replica dataset**.\n",
    "- Evaluate using **mAP** as the primary metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: follow mask3d installation instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sudo apt-get install libopenexr-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Install clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install tensorboardx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: install sharedarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install sharedarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the merged pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "1. Download the scannet val checkpoint from https://github.com/JonasSchult/Mask3D -> https://omnomnom.vision.rwth-aachen.de/data/mask3d/checkpoints/scannet/scannet_val.ckpt\n",
    "2. Put it in models/Mask3D/checkpoints/scannet/scannet_val.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output folder structure\n",
    "```\n",
    ".\n",
    "└── experiments/ \n",
    "    └── merged_pipeline/      \n",
    "        ├── run_current_timestamp/\n",
    "        │   ├── mask3d            # inference results for Mask3D\n",
    "        │   │   ├── samplename_confidences.txt\n",
    "        │   │   ├── samplename_labels.txt\n",
    "        │   │   ├── samplename_masks.pt       # File containing a list of tensors (the masks for each instance)\n",
    "        │   │   └── ...     \n",
    "        │   ├── openscene         # inference results for openscene\n",
    "        │   │    ├── samplename_distill.ply    # Output point cloud\n",
    "        │   │    ├── samplename_input.ply      # Input point cloud\n",
    "        │   │    ├── samplename_labels_distill.jpg\n",
    "        │   │    ├── samplename_features.npy   # The per point features (shape: N x 768)\n",
    "        │   │    └── ...\n",
    "        │   ├── samplename_instance_features.npy # Per instance features after running the notebook\n",
    "        │   └── ...\n",
    "        └── run_.../\n",
    "            └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output folder structure\n",
    "```\n",
    ".\n",
    "└── experiments/ \n",
    "    └── merged_pipeline/      \n",
    "        ├── run_current_timestamp/\n",
    "        │   ├── mask3d            # Inference results for Mask3D\n",
    "        │   │   ├── train/        # Train files for Mask3D\n",
    "        │   │   │   ├── samplename_confidences.txt\n",
    "        │   │   │   ├── samplename_labels.txt\n",
    "        │   │   │   ├── samplename_masks.pt               # File containing a list of tensors (the masks for each instance) \n",
    "        │   │   │   └── ...\n",
    "        │   │   ├── val/          # Validation files for Mask3D\n",
    "        │   │   │   └── ...\n",
    "        │   │   └── test/         # Test files for Mask3D\n",
    "        │   │       └── ...\n",
    "        │   ├── openscene         # Inference results for OpenScene\n",
    "        │   │   ├── train/        # Train files for OpenScene\n",
    "        │   │   │   ├── samplename_distill.ply            # Output point cloud\n",
    "        │   │   │   ├── samplename_input.ply              # Input point cloud\n",
    "        │   │   │   ├── samplename_labels_distill.jpg\n",
    "        │   │   │   ├── samplename_features.npy           # The per point features (shape: N x 768)\n",
    "        │   │   │   └── ...\n",
    "        │   │   ├── val/          # Validation files for OpenScene\n",
    "        │   │   │   └── ...\n",
    "        │   │   └── test/         # Test files for OpenScene\n",
    "        │   │       └── ...\n",
    "        │   └── instance_features\n",
    "        │        ├── train/        # Instance features for training samples\n",
    "        │        │     ├──  samplename_instance_features.npy # Per instance features after running the notebook\n",
    "        │        │     └──  ...\n",
    "        │        ├── val/          # Instance features for validation samples\n",
    "        │        │     ├── samplename_instance_features.npy # Per instance features after running the notebook\n",
    "        │        │     └── ...\n",
    "        │        └── test/         # Instance features for test samples\n",
    "        │              ├── samplename_instance_features.npy # Per instance features after running the notebook\n",
    "        │              └── ...\n",
    "        └── run_.../\n",
    "            └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new experiment folder: experiments/merged_pipline/run_2025-01-25-10-52-32\n"
     ]
    }
   ],
   "source": [
    "import experiment\n",
    "output_path = experiment.setup_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this to get the current output folder\n",
    "experiment.get_current_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Openscene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ exp_dir=experiments/merged_pipline/run_2025-01-25-10-52-32/openscene\n",
      "+ config=./config/openscene/replica/replica_lseg.yaml\n",
      "+ feature_type=distill\n",
      "+ mkdir -p experiments/merged_pipline/run_2025-01-25-10-52-32/openscene\n",
      "+ result_dir=experiments/merged_pipline/run_2025-01-25-10-52-32/openscene\n",
      "+ export PYTHONPATH=models/openscene\n",
      "+ PYTHONPATH=models/openscene\n",
      "+ python -u models/openscene/run/evaluate_merged.py --config=./config/openscene/replica/replica_lseg.yaml feature_type distill save_folder experiments/merged_pipline/run_2025-01-25-10-52-32/openscene\n",
      "++ date +%Y%m%d_%H%M\n",
      "+ tee -a experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/eval-20250125_1052.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/54/blessman/ml3d/dataset\n",
      "torch.__version__:1.12.1+cu113\n",
      "torch.version.cuda:11.3\n",
      "torch.backends.cudnn.version:8302\n",
      "torch.backends.cudnn.enabled:True\n",
      "[2025-01-25 10:52:51,976 evaluate_merged.py line 164] arch_3d: MinkUNet18A\n",
      "data_root: dataset/data/replica_split\n",
      "data_root_2d_fused_feature: data/replica_multiview_openseg\n",
      "dist_backend: nccl\n",
      "dist_url: tcp://127.0.0.1:6787\n",
      "distributed: False\n",
      "eval_iou: False\n",
      "exp_dir: ./experiments/openscene/replica_split\n",
      "feature_2d_extractor: lseg\n",
      "feature_type: distill\n",
      "input_color: False\n",
      "labelset: matterport\n",
      "manual_seed: 3407\n",
      "mark_no_feature_to_unknown: True\n",
      "model_path: https://cvg-data.inf.ethz.ch/openscene/models/matterport_lseg.pth.tar\n",
      "multiprocessing_distributed: False\n",
      "ngpus_per_node: 1\n",
      "prompt_eng: True\n",
      "rank: 0\n",
      "save_feature_as_numpy: True\n",
      "save_folder: experiments/merged_pipline/run_2025-01-25-10-52-32/openscene\n",
      "split: all\n",
      "sync_bn: False\n",
      "test_batch_size: 1\n",
      "test_gpu: [0]\n",
      "test_repeats: 1\n",
      "test_workers: 0\n",
      "use_apex: False\n",
      "use_shm: False\n",
      "vis_gt: False\n",
      "vis_input: True\n",
      "vis_pred: True\n",
      "voxel_size: 0.02\n",
      "world_size: 1\n",
      "test\n",
      "['dataset/data/replica_split/test/office4.pth', 'dataset/data/replica_split/test/room2.pth', 'dataset/data/replica_split/train/office0.pth', 'dataset/data/replica_split/train/office1.pth', 'dataset/data/replica_split/train/office2.pth', 'dataset/data/replica_split/train/room0.pth', 'dataset/data/replica_split/val/office3.pth', 'dataset/data/replica_split/val/room1.pth']\n",
      "Use prompt engineering: a XX in a scene\n",
      "Loading CLIP ViT-B/32 model...\n",
      "Finish loading\n",
      "[2025-01-25 10:53:36,998 evaluate_merged.py line 288] \n",
      "Evaluation 1 out of 1 runs...\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      "torch.Size([993008, 512])\n",
      " 12%|█▎        | 1/8 [00:35<04:10, 35.76s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      "torch.Size([722496, 512])\n",
      " 25%|██▌       | 2/8 [01:02<03:02, 30.45s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      "torch.Size([589517, 512])\n",
      " 38%|███▊      | 3/8 [01:24<02:12, 26.48s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      "torch.Size([423007, 512])\n",
      " 50%|█████     | 4/8 [01:39<01:28, 22.19s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      "torch.Size([858623, 512])\n",
      " 62%|██████▎   | 5/8 [02:11<01:17, 25.73s/it]torch.Size([954492, 512])\n",
      " 75%|███████▌  | 6/8 [02:47<00:58, 29.17s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      "torch.Size([1187140, 512])\n",
      " 88%|████████▊ | 7/8 [03:24<00:31, 31.58s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      "torch.Size([645512, 512])\n",
      "100%|██████████| 8/8 [03:48<00:00, 28.51s/it]\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$output_path\"\n",
    "# Run openscene\n",
    "set -x\n",
    "\n",
    "exp_dir=\"$1/openscene\"\n",
    "config=\"./config/openscene/replica/replica_lseg.yaml\"\n",
    "feature_type=distill\n",
    "\n",
    "mkdir -p \"${exp_dir}\"\n",
    "result_dir=\"${exp_dir}\"\n",
    "\n",
    "export PYTHONPATH=\"models/openscene\"\n",
    "python -u models/openscene/run/evaluate_merged.py \\\n",
    "  --config=${config} \\\n",
    "  feature_type ${feature_type} \\\n",
    "  save_folder ${result_dir} \\\n",
    "  2>&1 | tee -a ${exp_dir}/eval-$(date +\"%Y%m%d_%H%M\").log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY file loaded successfully!\n",
      "Number of points: 1187140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  warnings.warn(\n",
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"uint64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bf3d3e4e864a13bd6382ae0d65f9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY file loaded successfully!\n",
      "Number of points: 1187140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa548ca91ce4e3a8403a337c1959ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY file loaded successfully!\n",
      "Number of points: 645512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cee8c5d9bbd4746888427f473078179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY file loaded successfully!\n",
      "Number of points: 645512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae50ccd6b204abda0730590965ab4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import k3d\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def visualize_ply_with_k3d(file_path, point_size=0.05):\n",
    "    \"\"\"\n",
    "    Load a PLY file and visualize it using k3d in a Jupyter Notebook.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PLY file.\n",
    "        point_size (float): Size of the points in the visualization.\n",
    "    \"\"\"\n",
    "    # Load the PLY file using Open3D\n",
    "    ply_data = o3d.io.read_point_cloud(file_path)\n",
    "    \n",
    "    # Check if the file is loaded correctly\n",
    "    if ply_data.is_empty():\n",
    "        print(\"Failed to load PLY file.\")\n",
    "        return\n",
    "\n",
    "    print(\"PLY file loaded successfully!\")\n",
    "    print(f\"Number of points: {len(ply_data.points)}\")\n",
    "\n",
    "    # Extract points and colors\n",
    "    coords = np.asarray(ply_data.points)  # 3D coordinates\n",
    "    colors = np.asarray(ply_data.colors)  # RGB values (normalized to [0, 1])\n",
    "\n",
    "    # Normalize colors to 0-255 and convert to hexadecimal\n",
    "    colors = (colors * 255).astype(np.uint64)\n",
    "    colors_hex = (colors[:, 0] << 16) + (colors[:, 1] << 8) + colors[:, 2]\n",
    "\n",
    "    # Visualize with k3d\n",
    "    plot = k3d.plot()\n",
    "    point_cloud = k3d.points(positions=coords, point_size=point_size, colors=colors_hex)\n",
    "    plot += point_cloud\n",
    "    return plot\n",
    "\n",
    "# Path to your PLY file\n",
    "file_path = os.path.join(output_path, \"openscene\")\n",
    "split = \"val\"\n",
    "files = glob.glob(os.path.join(file_path, split, \"*.ply\"))\n",
    "\n",
    "# Call the visualization function\n",
    "for file in files:\n",
    "    plot = visualize_ply_with_k3d(file)\n",
    "    if plot:\n",
    "        plot.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mask3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ exp_dir=experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d\n",
      "+ mkdir -p experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d\n",
      "+ result_dir=experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d\n",
      "+ python -u models/Mask3D/predict.py general.checkpoint=models/Mask3D/checkpoints/scannet/scannet_val.ckpt general.data_dir=dataset/data/replica_split general.save_dir=experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d general.split=all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/54/blessman/ml3d/dataset\n",
      "Running on device:  cuda\n",
      "{'_target_': 'models.Res16UNet34C', 'config': {'dialations': [1, 1, 1, 1], 'conv1_kernel_size': 5, 'bn_momentum': 0.02}, 'in_channels': '${data.in_channels}', 'out_channels': '${data.num_labels}', 'out_fpn': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 11:12:02.658 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:91 - Key not found, it will be initialized randomly: model.scene_min\n",
      "2025-01-25 11:12:02.658 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:91 - Key not found, it will be initialized randomly: model.scene_max\n",
      "2025-01-25 11:12:02.769 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:115 - excessive key: model.scene_min\n",
      "2025-01-25 11:12:02.769 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:115 - excessive key: model.scene_max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint!\n",
      "Save dir:  experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d\n",
      "Data root:  dataset/data/replica_split\n",
      "['dataset/data/replica_split/test/office4.pth', 'dataset/data/replica_split/test/room2.pth', 'dataset/data/replica_split/train/office0.pth', 'dataset/data/replica_split/train/office1.pth', 'dataset/data/replica_split/train/office2.pth', 'dataset/data/replica_split/train/room0.pth', 'dataset/data/replica_split/val/office3.pth', 'dataset/data/replica_split/val/room1.pth']\n",
      "Dataset:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0 from file office4 ....\n",
      "Shape of mask:  torch.Size([456153, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  99\n",
      "Shape of confidences output:  99\n",
      "Shape of masks_binary output:  99 torch.Size([993008])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 from file room2 ....\n",
      "Shape of mask:  torch.Size([318867, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  100\n",
      "Shape of confidences output:  100\n",
      "Shape of masks_binary output:  100 torch.Size([722496])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2 from file office0 ....\n",
      "Shape of mask:  torch.Size([265922, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  100\n",
      "Shape of confidences output:  100\n",
      "Shape of masks_binary output:  100 torch.Size([589517])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3 from file office1 ....\n",
      "Shape of mask:  torch.Size([180492, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  99\n",
      "Shape of confidences output:  99\n",
      "Shape of masks_binary output:  99 torch.Size([423007])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4 from file office2 ....\n",
      "Shape of mask:  torch.Size([378125, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  98\n",
      "Shape of confidences output:  98\n",
      "Shape of masks_binary output:  98 torch.Size([858623])\n",
      "Processing batch 5 from file room0 ....\n",
      "Shape of mask:  torch.Size([435468, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  100\n",
      "Shape of confidences output:  100\n",
      "Shape of masks_binary output:  100 torch.Size([954492])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6 from file office3 ....\n",
      "Shape of mask:  torch.Size([515474, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  100\n",
      "Shape of confidences output:  100\n",
      "Shape of masks_binary output:  100 torch.Size([1187140])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7 from file room1 ....\n",
      "Shape of mask:  torch.Size([277142, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  100\n",
      "Shape of confidences output:  100\n",
      "Shape of masks_binary output:  100 torch.Size([645512])\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$output_path\"\n",
    "# Run openscene\n",
    "set -x\n",
    "\n",
    "exp_dir=\"$1/mask3d\"\n",
    "\n",
    "mkdir -p \"${exp_dir}\"\n",
    "result_dir=\"${exp_dir}\"\n",
    "\n",
    "python -u models/Mask3D/predict.py \\\n",
    "general.checkpoint='models/Mask3D/checkpoints/scannet/scannet_val.ckpt' \\\n",
    "general.data_dir=\"dataset/data/replica_split\" \\\n",
    "general.save_dir=${result_dir} \\\n",
    "general.split=\"all\"\n",
    "#general.num_targets=21 \\\n",
    "#data.num_labels=21\n",
    "#model.config.backbone._target_=models.Res16UNet18B \\\n",
    "#general.checkpoint=\"/cluster/54/blessman/ml3d/models/Mask3D/checkpoints/stpls3d/stpls3d_benchmark_03.ckpt\" \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merge results and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import k3d\n",
    "from glob import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32\n"
     ]
    }
   ],
   "source": [
    "import experiment\n",
    "# Do this if you don't want to run the models again. Returns the path to the current output folder\n",
    "output_path = experiment.get_current_path()\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load masks, pointclouds and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/val/office3_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/val/room1_masks.pt']\n",
      "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/val/office3_input.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/val/room1_input.ply']\n"
     ]
    }
   ],
   "source": [
    "mask3d_path = os.path.join(output_path, \"mask3d\")\n",
    "split = 'val'\n",
    "mask_paths = sorted(glob(os.path.join(mask3d_path, split, '*.pt')))\n",
    "\n",
    "openscene_path = os.path.join(output_path, \"openscene\")\n",
    "#features_paths = sorted(glob(os.path.join(openscene_path, '*.npy')))\n",
    "point_cloud_paths = sorted(glob(os.path.join(openscene_path, split, '*input.ply')))\n",
    "\n",
    "print(mask_paths)\n",
    "#print(features_paths)\n",
    "print(point_cloud_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for visualization purposes (the output colors don't correspond to the actual instance classes)\n",
    "MATTERPORT_COLOR_MAP_21 = {\n",
    "    1: (174., 199., 232.), # wall\n",
    "    2: (152., 223., 138.), # floor\n",
    "    3: (31., 119., 180.), # cabinet\n",
    "    4: (255., 187., 120.), # bed\n",
    "    5: (188., 189., 34.), # chair\n",
    "    6: (140., 86., 75.), # sofa\n",
    "    7: (255., 152., 150.), # table\n",
    "    8: (214., 39., 40.), # door\n",
    "    9: (197., 176., 213.), # window\n",
    "    10: (148., 103., 189.), # bookshelf\n",
    "    11: (196., 156., 148.), # picture\n",
    "    12: (23., 190., 207.), # counter\n",
    "    13: (247., 182., 210.), # desk\n",
    "    14: (219., 219., 141.), # curtain\n",
    "    15: (255., 127., 14.), # refrigerator\n",
    "    16: (158., 218., 229.), # shower curtain\n",
    "    17: (44., 160., 44.), # toilet\n",
    "    18: (112., 128., 144.), # sink\n",
    "    19: (227., 119., 194.), # bathtub\n",
    "    20: (82., 84., 163.), # other\n",
    "    # 41: (186., 197., 62.), # ceiling\n",
    "    21: (58., 98., 26.), # ceiling\n",
    "    0: (0., 0., 0.), # unlabel/unknown\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(mask_paths) == len(point_cloud_paths) #== len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1187140, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  warnings.warn(\n",
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"uint64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d86204eda21465290a55b128f10aa39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(645512, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1691a6282b74e619cad36ca7fc37921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(mask_paths)):\n",
    "    binary_masks = torch.load(mask_paths[i])\n",
    "    ply_data = o3d.io.read_point_cloud(point_cloud_paths[i])\n",
    "    \n",
    "    # Extract points and colors\n",
    "    coords = np.asarray(ply_data.points)  # 3D coordinates\n",
    "    colors = np.asarray(ply_data.colors)  # RGB values (normalized to [0, 1])\n",
    "\n",
    "    print(colors.shape)\n",
    "\n",
    "    # Set base color\n",
    "    colors[:] = 0.5\n",
    "\n",
    "    # Normalize colors to 0-255 and convert to hexadecimal\n",
    "    colors = (colors * 255).astype(np.uint64)\n",
    "\n",
    "    for i, mask in enumerate(binary_masks):\n",
    "        random_index = random.randint(1, len(MATTERPORT_COLOR_MAP_21)-1)\n",
    "        colors[mask] = MATTERPORT_COLOR_MAP_21[random_index]\n",
    "\n",
    "    colors_hex = (colors[:, 0] << 16) + (colors[:, 1] << 8) + colors[:, 2]\n",
    "\n",
    "    # Visualize with k3d\n",
    "    plot = k3d.plot()\n",
    "    point_cloud = k3d.points(positions=coords, point_size=0.05, colors=colors_hex)\n",
    "    plot += point_cloud\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import experiment\n",
    "\n",
    "output_path = experiment.get_current_path()\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running split:  train  -----------------\n",
      "Instance masks:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/train/office0_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/train/office1_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/train/office2_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/train/room0_masks.pt']\n",
      "Per point features:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/train/office0_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/train/office1_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/train/office2_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/train/room0_features.npy']\n",
      "Masks shape: (100, 589517)\n",
      "Features shape: (589517, 512)\n",
      "(100, 512)\n",
      "Saved instance features for office0\n",
      "Masks shape: (99, 423007)\n",
      "Features shape: (423007, 512)\n",
      "(99, 512)\n",
      "Saved instance features for office1\n",
      "Masks shape: (98, 858623)\n",
      "Features shape: (858623, 512)\n",
      "(98, 512)\n",
      "Saved instance features for office2\n",
      "Masks shape: (100, 954492)\n",
      "Features shape: (954492, 512)\n",
      "(100, 512)\n",
      "Saved instance features for room0\n",
      "\n",
      "Running split:  val  -----------------\n",
      "Instance masks:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/val/office3_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/val/room1_masks.pt']\n",
      "Per point features:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/val/office3_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/val/room1_features.npy']\n",
      "Masks shape: (100, 1187140)\n",
      "Features shape: (1187140, 512)\n",
      "(100, 512)\n",
      "Saved instance features for office3\n",
      "Masks shape: (100, 645512)\n",
      "Features shape: (645512, 512)\n",
      "(100, 512)\n",
      "Saved instance features for room1\n",
      "\n",
      "Running split:  test  -----------------\n",
      "Instance masks:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/test/office4_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/mask3d/test/room2_masks.pt']\n",
      "Per point features:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/test/office4_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-25-10-52-32/openscene/test/room2_features.npy']\n",
      "Masks shape: (99, 993008)\n",
      "Features shape: (993008, 512)\n",
      "(99, 512)\n",
      "Saved instance features for office4\n",
      "Masks shape: (100, 722496)\n",
      "Features shape: (722496, 512)\n",
      "(100, 512)\n",
      "Saved instance features for room2\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'val', 'test']:\n",
    "    \n",
    "    print(\"\\nRunning split: \", split, \" -----------------\")\n",
    "    \n",
    "    mask3d_path = os.path.join(output_path, \"mask3d\")\n",
    "    mask_paths = sorted(glob(os.path.join(mask3d_path, split, '*.pt')))\n",
    "\n",
    "    openscene_path = os.path.join(output_path, \"openscene\")\n",
    "    features_paths = sorted(glob(os.path.join(openscene_path, split, '*.npy')))\n",
    "\n",
    "    print(\"Instance masks: \", mask_paths)\n",
    "    print(\"Per point features: \", features_paths)\n",
    "    \n",
    "    assert len(mask_paths) == len(features_paths)\n",
    "    \n",
    "    for i in range(len(mask_paths)):\n",
    "    \n",
    "        sample_name = os.path.basename(mask_paths[i]).split('_')[0]\n",
    "\n",
    "        # Make sure that the instance masks and the point feature are from the same input sample\n",
    "        assert sample_name == os.path.basename(features_paths[i]).split('_')[0]\n",
    "\n",
    "        # Load masks and features\n",
    "        masks = torch.load(mask_paths[i])\n",
    "        features = np.load(features_paths[i])\n",
    "        print(f\"Masks shape: ({len(masks)}, {masks[0].shape[0]})\")\n",
    "        print(f\"Features shape: {features.shape}\")\n",
    "\n",
    "        mean_instance_features = []\n",
    "        # Compute average instance features\n",
    "        for mask in masks:\n",
    "            masked_features = features[mask,:]\n",
    "            mean_instance_features.append(features[mask,:].mean(axis=0))\n",
    "        mean_instance_features = np.array(mean_instance_features)\n",
    "        print(mean_instance_features.shape)\n",
    "        \n",
    "        folder_path = os.path.join(output_path, \"instance_features\", split)\n",
    "            \n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "        file_path = os.path.join(folder_path, f\"{sample_name}_instance_features.npy\")\n",
    "            \n",
    "        np.save(file_path, mean_instance_features)\n",
    "\n",
    "        print(f\"Saved instance features for {sample_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
