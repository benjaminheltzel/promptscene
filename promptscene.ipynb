{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: OpenPrompt: Open-Vocabulary 3D Scene Understanding and Instance Segmentation with Adaptive Prompt Learning\n",
    "\n",
    "### Dataset\n",
    "- **Replica Dataset**  \n",
    "  - Download link: [Replica dataset](https://github.com/aminebdj/OpenYOLO3D/blob/main/scripts/get_replica_dataset.sh)\n",
    "\n",
    "### Evaluation Script\n",
    "- **Replica Evaluation Script**  \n",
    "  - Link: [Replica evaluation script](https://github.com/aminebdj/OpenYOLO3D/tree/main/evaluate/replica)\n",
    "\n",
    "### Reference Papers for Prompt Learning\n",
    "1. **Align Your Prompts:** Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization\n",
    "2. **MaPLe:** Multi-modal Prompt Learning\n",
    "\n",
    "### Modifications and Goals\n",
    "1. **Objective:**  \n",
    "   Create an open-vocabulary 3D instance segmentation pipeline.\n",
    "   - Use **OpenScene** for feature extraction.\n",
    "   - Use **Mask3D** for class-agnostic proposal generation.\n",
    "\n",
    "2. **Testing:**  \n",
    "   Evaluate open-vocabulary instance segmentation results on the **Replica dataset**.  \n",
    "   - Metric: **Mean Average Precision (mAP)**  \n",
    "   - Evaluation script: Provided above.\n",
    "\n",
    "3. **Baseline and Improvements:**  \n",
    "   - Start with baseline model results.\n",
    "   - Implement **prompt learning** to improve performance.\n",
    "\n",
    "### Prompt Learning Details\n",
    "- Replace the fixed text features from the **CLIP text encoder** with a **trainable prompt** initialized with a text prompt.\n",
    "- **Training Objective:** Reduce the cosine similarity between visual features of the same object when augmented in different ways (e.g., translations, rotations, or color changes).  \n",
    "- Ensure consistency in visual features of the same object across augmentations by optimizing the learnable prompt during training.\n",
    "\n",
    "### Summary\n",
    "- Develop and test an open-vocabulary 3D instance segmentation pipeline with the specified modifications.\n",
    "- Leverage prompt learning techniques to enhance the baseline model's performance on the **Replica dataset**.\n",
    "- Evaluate using **mAP** as the primary metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: follow mask3d installation instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sudo apt-get install libopenexr-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Install clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install tensorboardx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: install sharedarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install sharedarray"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
