{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: OpenPrompt: Open-Vocabulary 3D Scene Understanding and Instance Segmentation with Adaptive Prompt Learning\n",
    "\n",
    "### Dataset\n",
    "- **Replica Dataset**  \n",
    "  - Download link: [Replica dataset](https://github.com/aminebdj/OpenYOLO3D/blob/main/scripts/get_replica_dataset.sh)\n",
    "\n",
    "### Evaluation Script\n",
    "- **Replica Evaluation Script**  \n",
    "  - Link: [Replica evaluation script](https://github.com/aminebdj/OpenYOLO3D/tree/main/evaluate/replica)\n",
    "\n",
    "### Reference Papers for Prompt Learning\n",
    "1. **Align Your Prompts:** Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization\n",
    "2. **MaPLe:** Multi-modal Prompt Learning\n",
    "\n",
    "### Modifications and Goals\n",
    "1. **Objective:**  \n",
    "   Create an open-vocabulary 3D instance segmentation pipeline.\n",
    "   - Use **OpenScene** for feature extraction.\n",
    "   - Use **Mask3D** for class-agnostic proposal generation.\n",
    "\n",
    "2. **Testing:**  \n",
    "   Evaluate open-vocabulary instance segmentation results on the **Replica dataset**.  \n",
    "   - Metric: **Mean Average Precision (mAP)**  \n",
    "   - Evaluation script: Provided above.\n",
    "\n",
    "3. **Baseline and Improvements:**  \n",
    "   - Start with baseline model results.\n",
    "   - Implement **prompt learning** to improve performance.\n",
    "\n",
    "### Prompt Learning Details\n",
    "- Replace the fixed text features from the **CLIP text encoder** with a **trainable prompt** initialized with a text prompt.\n",
    "- **Training Objective:** Reduce the cosine similarity between visual features of the same object when augmented in different ways (e.g., translations, rotations, or color changes).  \n",
    "- Ensure consistency in visual features of the same object across augmentations by optimizing the learnable prompt during training.\n",
    "\n",
    "### Summary\n",
    "- Develop and test an open-vocabulary 3D instance segmentation pipeline with the specified modifications.\n",
    "- Leverage prompt learning techniques to enhance the baseline model's performance on the **Replica dataset**.\n",
    "- Evaluate using **mAP** as the primary metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: follow mask3d installation instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sudo apt-get install libopenexr-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Install clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install tensorboardx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: install sharedarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install sharedarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the merged pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "1. Download the scannet val checkpoint from https://github.com/JonasSchult/Mask3D -> https://omnomnom.vision.rwth-aachen.de/data/mask3d/checkpoints/scannet/scannet_val.ckpt\n",
    "2. Put it in models/Mask3D/checkpoints/scannet/scannet_val.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output folder structure\n",
    "```\n",
    ".\n",
    "└── experiments/ \n",
    "    └── merged_pipeline/      \n",
    "        ├── run_current_timestamp/\n",
    "        │   ├── mask3d            # Inference results for Mask3D\n",
    "        │   │   ├── train/        # Train files for Mask3D\n",
    "        │   │   │   ├── samplename_confidences.txt\n",
    "        │   │   │   ├── samplename_labels.txt\n",
    "        │   │   │   ├── samplename_masks.pt               # File containing a list of tensors (the masks for each instance) \n",
    "        │   │   │   └── ...\n",
    "        │   │   ├── val/          # Validation files for Mask3D\n",
    "        │   │   │   └── ...\n",
    "        │   │   └── test/         # Test files for Mask3D\n",
    "        │   │       └── ...\n",
    "        │   ├── openscene         # Inference results for OpenScene\n",
    "        │   │   ├── train/        # Train files for OpenScene\n",
    "        │   │   │   ├── samplename_distill.ply            # Output point cloud\n",
    "        │   │   │   ├── samplename_input.ply              # Input point cloud\n",
    "        │   │   │   ├── samplename_labels_distill.jpg\n",
    "        │   │   │   ├── samplename_features.npy           # The per point features (shape: N x 768)\n",
    "        │   │   │   └── ...\n",
    "        │   │   ├── val/          # Validation files for OpenScene\n",
    "        │   │   │   └── ...\n",
    "        │   │   └── test/         # Test files for OpenScene\n",
    "        │   │       └── ...\n",
    "        │   └── instance_features\n",
    "        │        ├── train/        # Instance features for training samples\n",
    "        │        │     ├──  samplename_instance_features.npy # Per instance features after running the notebook\n",
    "        │        │     └──  ...\n",
    "        │        ├── val/          # Instance features for validation samples\n",
    "        │        │     ├── samplename_instance_features.npy # Per instance features after running the notebook\n",
    "        │        │     └── ...\n",
    "        │        └── test/         # Instance features for test samples\n",
    "        │              ├── samplename_instance_features.npy # Per instance features after running the notebook\n",
    "        │              └── ...\n",
    "        └── run_.../\n",
    "            └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new experiment folder: experiments/merged_pipline/run_2025-01-28-13-50-10\n"
     ]
    }
   ],
   "source": [
    "import experiment\n",
    "output_path = experiment.setup_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-28-13-50-10'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this to get the current output folder\n",
    "experiment.get_current_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Openscene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ exp_dir=experiments/merged_pipline/run_2025-01-28-13-50-10/openscene\n",
      "+ config=./config/openscene/replica/replica_lseg.yaml\n",
      "+ feature_type=distill\n",
      "+ mkdir -p experiments/merged_pipline/run_2025-01-28-13-50-10/openscene\n",
      "+ result_dir=experiments/merged_pipline/run_2025-01-28-13-50-10/openscene\n",
      "+ python -u models/openscene/run/evaluate_merged.py --config=./config/openscene/replica/replica_lseg.yaml feature_type distill save_folder experiments/merged_pipline/run_2025-01-28-13-50-10/openscene\n",
      "++ date +%Y%m%d_%H%M\n",
      "+ tee -a experiments/merged_pipline/run_2025-01-28-13-50-10/openscene/eval-20250128_1350.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/cluster/54/blessman/ml3d/models/openscene/run/evaluate_merged.py\", line 16, in <module>\n",
      "    from util import metric\n",
      "ModuleNotFoundError: No module named 'util'\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$output_path\"\n",
    "# Run openscene\n",
    "set -x\n",
    "\n",
    "exp_dir=\"$1/openscene\"\n",
    "config=\"./config/openscene/replica/replica_lseg.yaml\"\n",
    "feature_type=distill\n",
    "\n",
    "mkdir -p \"${exp_dir}\"\n",
    "result_dir=\"${exp_dir}\"\n",
    "\n",
    "export PYTHONPATH=\"models/openscene\"\n",
    "python -u models/openscene/run/evaluate_merged.py \\\n",
    "  --config=${config} \\\n",
    "  feature_type ${feature_type} \\\n",
    "  save_folder ${result_dir} \\\n",
    "  2>&1 | tee -a ${exp_dir}/eval-$(date +\"%Y%m%d_%H%M\").log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY file loaded successfully!\n",
      "Number of points: 1187140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  warnings.warn(\n",
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"uint64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cc9cff7dc246f5816fe8741c057dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY file loaded successfully!\n",
      "Number of points: 1187140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c69b43937d49a787e1cad6ce888f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY file loaded successfully!\n",
      "Number of points: 645512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71fe597b85304bec98d9f70d8a364302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY file loaded successfully!\n",
      "Number of points: 645512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdef0cfd4d54b3c87243cabd5d7d287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from point_cloud import visualize_ply_with_k3d\n",
    "\n",
    "# Path to your PLY file\n",
    "file_path = os.path.join(output_path, \"openscene\")\n",
    "split = \"val\"\n",
    "files = glob.glob(os.path.join(file_path, split, \"*.ply\"))\n",
    "\n",
    "# Call the visualization function\n",
    "for file in files:\n",
    "    plot = visualize_ply_with_k3d(file)\n",
    "    if plot:\n",
    "        plot.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mask3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ exp_dir=/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d\n",
      "+ mkdir -p /cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d\n",
      "+ result_dir=/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d\n",
      "+ python -u models/Mask3D/predict.py general.checkpoint=models/Mask3D/checkpoints/scannet/scannet_val.ckpt general.data_dir=dataset/data/replica_split general.save_dir=/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d general.split=all general.required_confidence=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/54/blessman/ml3d/dataset\n",
      "Running on device:  cuda\n",
      "{'_target_': 'models.Res16UNet34C', 'config': {'dialations': [1, 1, 1, 1], 'conv1_kernel_size': 5, 'bn_momentum': 0.02}, 'in_channels': '${data.in_channels}', 'out_channels': '${data.num_labels}', 'out_fpn': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 22:35:27.565 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:91 - Key not found, it will be initialized randomly: model.scene_min\n",
      "2025-01-29 22:35:27.565 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:91 - Key not found, it will be initialized randomly: model.scene_max\n",
      "2025-01-29 22:35:27.687 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:115 - excessive key: model.scene_min\n",
      "2025-01-29 22:35:27.687 | WARNING  | utils.utils:load_checkpoint_with_missing_or_exsessive_keys:115 - excessive key: model.scene_max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint!\n",
      "Save dir:  /cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d\n",
      "Data root:  dataset/data/replica_split\n",
      "Dataset:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0 from file office4 ....\n",
      "Shape of mask:  torch.Size([456153, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  74\n",
      "Shape of confidences output:  74\n",
      "Shape of masks_binary output:  74 torch.Size([993008])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 from file room2 ....\n",
      "Shape of mask:  torch.Size([318867, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  80\n",
      "Shape of confidences output:  80\n",
      "Shape of masks_binary output:  80 torch.Size([722496])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2 from file office0 ....\n",
      "Shape of mask:  torch.Size([265922, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  76\n",
      "Shape of confidences output:  76\n",
      "Shape of masks_binary output:  76 torch.Size([589517])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3 from file office1 ....\n",
      "Shape of mask:  torch.Size([180492, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  61\n",
      "Shape of confidences output:  61\n",
      "Shape of masks_binary output:  61 torch.Size([423007])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4 from file office2 ....\n",
      "Shape of mask:  torch.Size([378125, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  69\n",
      "Shape of confidences output:  69\n",
      "Shape of masks_binary output:  69 torch.Size([858623])\n",
      "Processing batch 5 from file room0 ....\n",
      "Shape of mask:  torch.Size([435468, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  73\n",
      "Shape of confidences output:  73\n",
      "Shape of masks_binary output:  73 torch.Size([954492])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6 from file office3 ....\n",
      "Shape of mask:  torch.Size([515474, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  63\n",
      "Shape of confidences output:  63\n",
      "Shape of masks_binary output:  63 torch.Size([1187140])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7 from file room1 ....\n",
      "Shape of mask:  torch.Size([277142, 100])\n",
      "Shape of logits:  torch.Size([100, 19])\n",
      "Shape of labels output:  70\n",
      "Shape of confidences output:  70\n",
      "Shape of masks_binary output:  70 torch.Size([645512])\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$output_path\"\n",
    "# Run mask3d\n",
    "set -x\n",
    "\n",
    "exp_dir=\"$1/mask3d\"\n",
    "\n",
    "mkdir -p \"${exp_dir}\"\n",
    "result_dir=\"${exp_dir}\"\n",
    "\n",
    "python -u models/Mask3D/predict.py \\\n",
    "general.checkpoint='models/Mask3D/checkpoints/scannet/scannet_val.ckpt' \\\n",
    "general.data_dir=\"dataset/data/replica_split\" \\\n",
    "general.save_dir=${result_dir} \\\n",
    "general.split=\"all\" \\\n",
    "general.required_confidence=0.9\n",
    "#general.num_targets=21 \\\n",
    "#data.num_labels=21\n",
    "#model.config.backbone._target_=models.Res16UNet18B \\\n",
    "#general.checkpoint=\"/cluster/54/blessman/ml3d/models/Mask3D/checkpoints/stpls3d/stpls3d_benchmark_03.ckpt\" \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merge results and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import k3d\n",
    "from glob import glob\n",
    "import random\n",
    "import point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08\n"
     ]
    }
   ],
   "source": [
    "import experiment\n",
    "# Do this if you don't want to run the models again. Returns the path to the current output folder\n",
    "output_path = experiment.get_current_path()\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load masks, pointclouds and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/test/office4_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/test/room2_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/office0_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/office1_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/office2_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/room0_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/val/office3_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/val/room1_masks.pt']\n",
      "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/office4_distill.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/room2_distill.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office0_distill.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office1_distill.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office2_distill.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/room0_distill.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/office3_distill.ply', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/room1_distill.ply']\n"
     ]
    }
   ],
   "source": [
    "mask3d_path = os.path.join(output_path, \"mask3d\")\n",
    "#split = 'val'\n",
    "mask_paths = utils.get_all_files_in_dir_and_subdir(mask3d_path, \"pt\")#sorted(glob(os.path.join(mask3d_path, split, '*.pt')))\n",
    "\n",
    "openscene_path = os.path.join(output_path, \"openscene\")\n",
    "#features_paths = sorted(glob(os.path.join(openscene_path, '*.npy')))\n",
    "point_cloud_paths = utils.get_all_files_in_dir_and_subdir(openscene_path, \"distill.ply\")\n",
    "\n",
    "print(mask_paths)\n",
    "#print(features_paths)\n",
    "print(point_cloud_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for visualization purposes (the output colors don't correspond to the actual instance classes)\n",
    "MATTERPORT_COLOR_MAP_21 = {\n",
    "    1: (174., 199., 232.), # wall\n",
    "    2: (152., 223., 138.), # floor\n",
    "    3: (31., 119., 180.), # cabinet\n",
    "    4: (255., 187., 120.), # bed\n",
    "    5: (188., 189., 34.), # chair\n",
    "    6: (140., 86., 75.), # sofa\n",
    "    7: (255., 152., 150.), # table\n",
    "    8: (214., 39., 40.), # door\n",
    "    9: (197., 176., 213.), # window\n",
    "    10: (148., 103., 189.), # bookshelf\n",
    "    11: (196., 156., 148.), # picture\n",
    "    12: (23., 190., 207.), # counter\n",
    "    13: (247., 182., 210.), # desk\n",
    "    14: (219., 219., 141.), # curtain\n",
    "    15: (255., 127., 14.), # refrigerator\n",
    "    16: (158., 218., 229.), # shower curtain\n",
    "    17: (44., 160., 44.), # toilet\n",
    "    18: (112., 128., 144.), # sink\n",
    "    19: (227., 119., 194.), # bathtub\n",
    "    20: (82., 84., 163.), # other\n",
    "    # 41: (186., 197., 62.), # ceiling\n",
    "    21: (58., 98., 26.), # ceiling\n",
    "    0: (0., 0., 0.), # unlabel/unknown\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(mask_paths) == len(point_cloud_paths) #== len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office4_distill.ply\n",
      "PLY file loaded successfully!\n",
      "Number of points: 993008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  warnings.warn(\n",
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"uint64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0c6db798284212bf97470368984ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room2_distill.ply\n",
      "PLY file loaded successfully!\n",
      "Number of points: 722496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78434aa88164ceaa07e04b831225ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office0_distill.ply\n",
      "PLY file loaded successfully!\n",
      "Number of points: 589517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ef422091d54fe59c74ff7cd12990fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office1_distill.ply\n",
      "PLY file loaded successfully!\n",
      "Number of points: 423007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef30e1311117438b82d1ab0bded531fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office2_distill.ply\n",
      "PLY file loaded successfully!\n",
      "Number of points: 858623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499938d2fede4fb9b7e7cf7b7757115f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room0_distill.ply\n",
      "PLY file loaded successfully!\n",
      "Number of points: 954492\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b860c5e93d5241a8a2eb1311913611df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office3_distill.ply\n",
      "PLY file loaded successfully!\n",
      "Number of points: 1187140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db89aecfdc3840188850766e7fc7f16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room1_distill.ply\n",
      "PLY file loaded successfully!\n",
      "Number of points: 645512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8467d68243c242cabf101ab756d10acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for file in point_cloud_paths:\n",
    "    print(os.path.basename(file))\n",
    "    point_cloud.visualize_ply_with_k3d(file, point_size=2).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "(993008, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02da43512e5244c6af1e867b741facf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "(722496, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a2a7ac1a2542fc8cbd47c82b3c9560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "(589517, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec9dc4d305047789f6d5edc0c83c5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "(423007, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e49232f8944a8f860c004a65d7a036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "(858623, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4918cf5aec4446ac110a06081ecc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "(954492, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedd50a3803144f59cda23a7c31bca6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "(1187140, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc70d56731347dfb12a7435c122ea98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "(645512, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2847aadaf7bb4731aa45584d6df89e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(mask_paths)):\n",
    "    binary_masks = torch.load(mask_paths[i])\n",
    "    print(len(binary_masks))\n",
    "    ply_data = o3d.io.read_point_cloud(point_cloud_paths[i])\n",
    "    \n",
    "    # Extract points and colors\n",
    "    coords = np.asarray(ply_data.points)  # 3D coordinates\n",
    "    colors = np.asarray(ply_data.colors)  # RGB values (normalized to [0, 1])\n",
    "\n",
    "    print(colors.shape)\n",
    "\n",
    "    # Set base color\n",
    "    colors[:] = 0.5\n",
    "\n",
    "    # Normalize colors to 0-255 and convert to hexadecimal\n",
    "    colors = (colors * 255).astype(np.uint64)\n",
    "\n",
    "    for i, mask in enumerate(binary_masks):\n",
    "        random_index = random.randint(1, len(MATTERPORT_COLOR_MAP_21)-1)\n",
    "        colors[mask] = MATTERPORT_COLOR_MAP_21[random_index]\n",
    "\n",
    "    colors_hex = (colors[:, 0] << 16) + (colors[:, 1] << 8) + colors[:, 2]\n",
    "\n",
    "    # Visualize with k3d\n",
    "    plot = k3d.plot()\n",
    "    point_cloud = k3d.points(positions=coords, point_size=2, colors=colors_hex)\n",
    "    plot += point_cloud\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import experiment\n",
    "from glob import glob\n",
    "\n",
    "output_path = experiment.get_current_path()\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running split:  train  -----------------\n",
      "Instance masks:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/office0_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/office1_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/office2_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/train/room0_masks.pt']\n",
      "Per point features:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office0_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office1_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/office2_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/train/room0_features.npy']\n",
      "Masks shape: (76, 589517)\n",
      "Features shape: (589517, 512)\n",
      "(76, 512)\n",
      "Saved instance features for office0\n",
      "Masks shape: (61, 423007)\n",
      "Features shape: (423007, 512)\n",
      "(61, 512)\n",
      "Saved instance features for office1\n",
      "Masks shape: (69, 858623)\n",
      "Features shape: (858623, 512)\n",
      "(69, 512)\n",
      "Saved instance features for office2\n",
      "Masks shape: (73, 954492)\n",
      "Features shape: (954492, 512)\n",
      "(73, 512)\n",
      "Saved instance features for room0\n",
      "\n",
      "Running split:  val  -----------------\n",
      "Instance masks:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/val/office3_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/val/room1_masks.pt']\n",
      "Per point features:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/office3_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/val/room1_features.npy']\n",
      "Masks shape: (63, 1187140)\n",
      "Features shape: (1187140, 512)\n",
      "(63, 512)\n",
      "Saved instance features for office3\n",
      "Masks shape: (70, 645512)\n",
      "Features shape: (645512, 512)\n",
      "(70, 512)\n",
      "Saved instance features for room1\n",
      "\n",
      "Running split:  test  -----------------\n",
      "Instance masks:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/test/office4_masks.pt', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/mask3d/test/room2_masks.pt']\n",
      "Per point features:  ['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/office4_features.npy', '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/openscene/test/room2_features.npy']\n",
      "Masks shape: (74, 993008)\n",
      "Features shape: (993008, 512)\n",
      "(74, 512)\n",
      "Saved instance features for office4\n",
      "Masks shape: (80, 722496)\n",
      "Features shape: (722496, 512)\n",
      "(80, 512)\n",
      "Saved instance features for room2\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'val', 'test']:\n",
    "    \n",
    "    print(\"\\nRunning split: \", split, \" -----------------\")\n",
    "    \n",
    "    mask3d_path = os.path.join(output_path, \"mask3d\")\n",
    "    mask_paths = sorted(glob(os.path.join(mask3d_path, split, '*.pt')))\n",
    "\n",
    "    openscene_path = os.path.join(output_path, \"openscene\")\n",
    "    features_paths = sorted(glob(os.path.join(openscene_path, split, '*.npy')))\n",
    "\n",
    "    print(\"Instance masks: \", mask_paths)\n",
    "    print(\"Per point features: \", features_paths)\n",
    "    \n",
    "    assert len(mask_paths) == len(features_paths)\n",
    "    \n",
    "    for i in range(len(mask_paths)):\n",
    "    \n",
    "        sample_name = os.path.basename(mask_paths[i]).split('_')[0]\n",
    "\n",
    "        # Make sure that the instance masks and the point feature are from the same input sample\n",
    "        assert sample_name == os.path.basename(features_paths[i]).split('_')[0]\n",
    "\n",
    "        # Load masks and features\n",
    "        masks = torch.load(mask_paths[i])\n",
    "        features = np.load(features_paths[i])\n",
    "        print(f\"Masks shape: ({len(masks)}, {masks[0].shape[0]})\")\n",
    "        print(f\"Features shape: {features.shape}\")\n",
    "\n",
    "        mean_instance_features = []\n",
    "        # Compute average instance features\n",
    "        for mask in masks:\n",
    "            masked_features = features[mask,:]\n",
    "            mean_instance_features.append(features[mask,:].mean(axis=0))\n",
    "        mean_instance_features = np.array(mean_instance_features)\n",
    "        print(mean_instance_features.shape)\n",
    "        \n",
    "        folder_path = os.path.join(output_path, \"instance_features\", split)\n",
    "            \n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "        file_path = os.path.join(folder_path, f\"{sample_name}_instance_features.npy\")\n",
    "            \n",
    "        np.save(file_path, mean_instance_features)\n",
    "\n",
    "        print(f\"Saved instance features for {sample_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08\n"
     ]
    }
   ],
   "source": [
    "import experiment\n",
    "current_path = experiment.get_current_path()\n",
    "\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get clip features for replica classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip_utils import extract_text_feature, REPLICA_LABELS#, MATTERPORT_LABELS_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use prompt engineering: a XX in a scene\n",
      "Loading CLIP ViT-B/32 model...\n",
      "Finish loading\n"
     ]
    }
   ],
   "source": [
    "labelset = list(REPLICA_LABELS)\n",
    "text_features, new_label_set = extract_text_feature(labelset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelset.append('unlabeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['basket',\n",
       "  'bed',\n",
       "  'bench',\n",
       "  'bin',\n",
       "  'blanket',\n",
       "  'blinds',\n",
       "  'book',\n",
       "  'bottle',\n",
       "  'box',\n",
       "  'bowl',\n",
       "  'camera',\n",
       "  'cabinet',\n",
       "  'candle',\n",
       "  'chair',\n",
       "  'clock',\n",
       "  'cloth',\n",
       "  'comforter',\n",
       "  'cushion',\n",
       "  'desk',\n",
       "  'desk-organizer',\n",
       "  'door',\n",
       "  'indoor-plant',\n",
       "  'lamp',\n",
       "  'monitor',\n",
       "  'nightstand',\n",
       "  'panel',\n",
       "  'picture',\n",
       "  'pillar',\n",
       "  'pillow',\n",
       "  'pipe',\n",
       "  'plant-stand',\n",
       "  'plate',\n",
       "  'pot',\n",
       "  'sculpture',\n",
       "  'shelf',\n",
       "  'sofa',\n",
       "  'stool',\n",
       "  'switch',\n",
       "  'table',\n",
       "  'tablet',\n",
       "  'tissue-paper',\n",
       "  'tv-screen',\n",
       "  'tv-stand',\n",
       "  'vase',\n",
       "  'vent',\n",
       "  'wall-plug',\n",
       "  'window',\n",
       "  'rug',\n",
       "  'unlabeled'],\n",
       " ['a basket in a scene',\n",
       "  'a bed in a scene',\n",
       "  'a bench in a scene',\n",
       "  'a bin in a scene',\n",
       "  'a blanket in a scene',\n",
       "  'a blinds in a scene',\n",
       "  'a book in a scene',\n",
       "  'a bottle in a scene',\n",
       "  'a box in a scene',\n",
       "  'a bowl in a scene',\n",
       "  'a camera in a scene',\n",
       "  'a cabinet in a scene',\n",
       "  'a candle in a scene',\n",
       "  'a chair in a scene',\n",
       "  'a clock in a scene',\n",
       "  'a cloth in a scene',\n",
       "  'a comforter in a scene',\n",
       "  'a cushion in a scene',\n",
       "  'a desk in a scene',\n",
       "  'a desk-organizer in a scene',\n",
       "  'a door in a scene',\n",
       "  'a indoor-plant in a scene',\n",
       "  'a lamp in a scene',\n",
       "  'a monitor in a scene',\n",
       "  'a nightstand in a scene',\n",
       "  'a panel in a scene',\n",
       "  'a picture in a scene',\n",
       "  'a pillar in a scene',\n",
       "  'a pillow in a scene',\n",
       "  'a pipe in a scene',\n",
       "  'a plant-stand in a scene',\n",
       "  'a plate in a scene',\n",
       "  'a pot in a scene',\n",
       "  'a sculpture in a scene',\n",
       "  'a shelf in a scene',\n",
       "  'a sofa in a scene',\n",
       "  'a stool in a scene',\n",
       "  'a switch in a scene',\n",
       "  'a table in a scene',\n",
       "  'a tablet in a scene',\n",
       "  'a tissue-paper in a scene',\n",
       "  'a tv-screen in a scene',\n",
       "  'a tv-stand in a scene',\n",
       "  'a vase in a scene',\n",
       "  'a vent in a scene',\n",
       "  'a wall-plug in a scene',\n",
       "  'a window in a scene',\n",
       "  'a rug in a scene'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelset, new_label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "path = os.path.join(current_path, \"clip_features.pt\")\n",
    "torch.save(text_features, path)\n",
    "\n",
    "with open(os.path.join(current_path, \"labels.txt\"), 'w') as file:\n",
    "        for string in labelset:\n",
    "            file.write(string + '\\n')\n",
    "            \n",
    "with open(os.path.join(current_path, \"text_prompts.txt\"), 'w') as file:\n",
    "        for string in new_label_set:\n",
    "            file.write(string + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get per instance features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 512])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = torch.load(os.path.join(current_path, \"clip_features.pt\"))\n",
    "text_features.shape  # torch.Size([21, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/test/room2_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/test/office4_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/val/room1_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/val/office3_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/train/office1_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/train/office0_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/train/room0_instance_features.npy',\n",
       " '/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-29-20-44-08/instance_features/train/office2_instance_features.npy']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_path = os.path.join(current_path, \"instance_features\")\n",
    "npy_files = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(instance_path)\n",
    "    for file in files\n",
    "    if file.endswith(\".npy\")\n",
    "]\n",
    "npy_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing room2\n",
      "torch.Size([48, 512])\n",
      "torch.Size([80, 512])\n",
      "Processing office4\n",
      "torch.Size([48, 512])\n",
      "torch.Size([74, 512])\n",
      "Processing room1\n",
      "torch.Size([48, 512])\n",
      "torch.Size([70, 512])\n",
      "Processing office3\n",
      "torch.Size([48, 512])\n",
      "torch.Size([63, 512])\n",
      "Processing office1\n",
      "torch.Size([48, 512])\n",
      "torch.Size([61, 512])\n",
      "Processing office0\n",
      "torch.Size([48, 512])\n",
      "torch.Size([76, 512])\n",
      "Processing room0\n",
      "torch.Size([48, 512])\n",
      "torch.Size([73, 512])\n",
      "Processing office2\n",
      "torch.Size([48, 512])\n",
      "torch.Size([69, 512])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from clip_utils import classify_features\n",
    "import torch\n",
    "\n",
    "for file in npy_files:\n",
    "    instance_features = np.load(file)\n",
    "    instance_features = torch.Tensor(instance_features)\n",
    "    \n",
    "    sample_name = os.path.basename(file).split('_')[0]\n",
    "    \n",
    "    print(f\"Processing {sample_name}\")\n",
    "    \n",
    "    print(text_features.shape)\n",
    "    print(instance_features.shape)\n",
    "    \n",
    "    predicted_classes, confidence_scores = classify_features(text_features, instance_features)\n",
    "\n",
    "    save_path = os.path.dirname(file)\n",
    "    torch.save(predicted_classes, os.path.join(save_path, f\"{sample_name}_predicted_classes.pl\"))\n",
    "    torch.save(confidence_scores, os.path.join(save_path, f\"{sample_name}_confidence_scores.pl\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Augmenations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office0.pt\n",
      "torch.Size([589517, 22])\n",
      "torch.Size([22])\n",
      "torch.Size([589517, 68])\n",
      "torch.Size([68])\n",
      "office1.pt\n",
      "torch.Size([423007, 23])\n",
      "torch.Size([23])\n",
      "torch.Size([423007, 52])\n",
      "torch.Size([52])\n",
      "office2.pt\n",
      "torch.Size([858623, 27])\n",
      "torch.Size([27])\n",
      "torch.Size([858623, 94])\n",
      "torch.Size([94])\n",
      "office3.pt\n",
      "torch.Size([1187140, 27])\n",
      "torch.Size([27])\n",
      "torch.Size([1187140, 113])\n",
      "torch.Size([113])\n",
      "office4.pt\n",
      "torch.Size([993008, 28])\n",
      "torch.Size([28])\n",
      "torch.Size([993008, 71])\n",
      "torch.Size([71])\n",
      "room0.pt\n",
      "torch.Size([954492, 36])\n",
      "torch.Size([36])\n",
      "torch.Size([954492, 94])\n",
      "torch.Size([94])\n",
      "room1.pt\n",
      "torch.Size([645512, 25])\n",
      "torch.Size([25])\n",
      "torch.Size([645512, 57])\n",
      "torch.Size([57])\n",
      "room2.pt\n",
      "torch.Size([722496, 21])\n",
      "torch.Size([21])\n",
      "torch.Size([722496, 61])\n",
      "torch.Size([61])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "# Use rotation, translation, change of color\n",
    "path = \"dataset/OpenYOLO3D/output/replica/replica_masks\"  # Classes\n",
    "path1 = \"dataset/OpenYOLO3D/output/replica/replica_ground_truth_masks\" # Instances\n",
    "files_masks = sorted(glob(os.path.join(path, '*.pt')))\n",
    "\n",
    "for file in files_masks:\n",
    "    sample_name = os.path.basename(file)  \n",
    "    print(sample_name)\n",
    "    \n",
    "    masks, confidences = torch.load(os.path.join(path, sample_name))\n",
    "    print(masks.shape)\n",
    "    print(confidences.shape)\n",
    "    masks, confidences = torch.load(os.path.join(path1, sample_name))\n",
    "    print(masks.shape)\n",
    "    print(confidences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/data/replica_split/test/room2.pth', 'dataset/data/replica_split/test/office4.pth', 'dataset/data/replica_split/val/room1.pth', 'dataset/data/replica_split/val/office3.pth', 'dataset/data/replica_split/train/office2.pth', 'dataset/data/replica_split/train/room0.pth', 'dataset/data/replica_split/train/office0.pth', 'dataset/data/replica_split/train/office1.pth']\n"
     ]
    }
   ],
   "source": [
    "gt_path = \"dataset/OpenYOLO3D/output/replica/replica_ground_truth_masks\"\n",
    "point_cloud_base_path = \"dataset/data/replica_split\"\n",
    "point_cloud_files = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(point_cloud_base_path)\n",
    "    for file in files\n",
    "    if file.endswith(\".pth\")\n",
    "]\n",
    "print(point_cloud_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import augmentations\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"float32\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  warnings.warn(\n",
      "/rhome/blessman/miniconda3/envs/mask3d/lib/python3.10/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"uint64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e373efae01564271b41daf87406edd2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f377a285794b4fb9959fa46d4da71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from point_cloud import visualize_point_cloud_with_k3d\n",
    "\n",
    "for point_cloud in point_cloud_files:\n",
    "    coords, colors, labels = torch.load(point_cloud)\n",
    "    \n",
    "    visualize_point_cloud_with_k3d(coords, colors).display()\n",
    "    \n",
    "    sample_name = os.path.basename(point_cloud).split('.')[0]\n",
    "    \n",
    "    gt_mask,_ = torch.load(os.path.join(gt_path, f\"{sample_name}.pt\"))\n",
    "    for mask in gt_mask.T:\n",
    "        mask = mask != 0\n",
    "        _, colors[mask] = augmentations.add_rgb_noise_to_object(coords[mask], colors[mask], sigma=0.1)\n",
    "    \n",
    "    normalized_rgb = (colors + 1) / 2\n",
    "    normalized_rgb = (normalized_rgb * 255).astype(np.uint64)\n",
    "    \n",
    "    visualize_point_cloud_with_k3d(coords, normalized_rgb, is_rgb=True, is_norm=True).display()\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63c8a6689de4052ad92984657bfb92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ef3d277e614d20a16f91d0cfd4e40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from point_cloud import visualize_point_cloud_with_k3d\n",
    "\n",
    "for point_cloud in point_cloud_files:\n",
    "    coords, colors, labels = torch.load(point_cloud)\n",
    "    \n",
    "    visualize_point_cloud_with_k3d(coords, colors).display()\n",
    "    \n",
    "    sample_name = os.path.basename(point_cloud).split('.')[0]\n",
    "    \n",
    "    gt_mask,labels = torch.load(os.path.join(gt_path, f\"{sample_name}.pt\"))\n",
    "    mask = gt_mask[:,5] != 0\n",
    "    \n",
    "    #normalized_rgb = (colors + 1) / 2\n",
    "    #normalized_rgb = (normalized_rgb * 255).astype(np.uint64)\n",
    "    #normalized_rgb[mask] = (255., 187., 120.)\n",
    "    \n",
    "    for mask in gt_mask.T:\n",
    "        mask = mask != 0\n",
    "        coords_tmp = coords.copy()\n",
    "        colors_tmp = colors.copy()\n",
    "        coords_tmp[mask], colors_tmp[mask] = augmentations.random_augmentation(coords_tmp[mask], colors_tmp[mask])\n",
    "    \n",
    "    visualize_point_cloud_with_k3d(coords, colors).display()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Instance/Group Feature Extraction for Prompt Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Save augmented scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/data/replica_split/test/room2.pth\n",
      "dataset/data/replica_split/test/office4.pth\n",
      "dataset/data/replica_split/val/room1.pth\n",
      "dataset/data/replica_split/val/office3.pth\n",
      "dataset/data/replica_split/train/office2.pth\n",
      "dataset/data/replica_split/train/room0.pth\n",
      "dataset/data/replica_split/train/office0.pth\n",
      "dataset/data/replica_split/train/office1.pth\n"
     ]
    }
   ],
   "source": [
    "import augmentations\n",
    "\n",
    "num_augmentations = 10\n",
    "use_color = False\n",
    "\n",
    "\n",
    "for point_cloud in point_cloud_files:\n",
    "    print(point_cloud)\n",
    "    \n",
    "    # Load point cloud\n",
    "    coords, colors, labels = torch.load(point_cloud)\n",
    "    \n",
    "    # Get name of current sample (e.g \"room0\")\n",
    "    sample_name = os.path.basename(point_cloud).split('.')[0]\n",
    "    \n",
    "    # Get ground truth masks to find points in instance\n",
    "    gt_mask,_ = torch.load(os.path.join(gt_path, f\"{sample_name}.pt\"))\n",
    "    mask = gt_mask[:,5] != 0\n",
    "    \n",
    "    # Create dir to store augmentations\n",
    "    output_dir = os.path.join(os.path.dirname(point_cloud), f\"{sample_name}_augmentations\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create n augmentations and save to disk\n",
    "    for i in range(num_augmentations_per_instance):\n",
    "        coords_tmp = coords.copy()\n",
    "        colors_tmp = colors.copy()\n",
    "        for mask in gt_mask.T:\n",
    "            mask = mask != 0\n",
    "            coords_tmp[mask], colors_tmp[mask] = augmentations.random_augmentation(coords_tmp[mask], colors_tmp[mask], use_color)\n",
    "        \n",
    "        # Save to file\n",
    "        file_path = os.path.join(output_dir, f\"{sample_name}_{i}.pth\")\n",
    "\n",
    "        output = (coords_tmp, colors_tmp, labels)\n",
    "        torch.save(output, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feed augmented scenes through openscne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import experiment\n",
    "output_path = experiment.get_current_path()\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ exp_dir=/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning\n",
      "+ config=./config/openscene/replica/replica_lseg_aug.yaml\n",
      "+ feature_type=distill\n",
      "+ mkdir -p /cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning\n",
      "+ result_dir=/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning\n",
      "+ export PYTHONPATH=models/openscene\n",
      "+ PYTHONPATH=models/openscene\n",
      "+ python -u models/openscene/run/evaluate_merged.py --config=./config/openscene/replica/replica_lseg_aug.yaml feature_type distill save_folder /cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning\n",
      "++ date +%Y%m%d_%H%M\n",
      "+ tee -a /cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/eval-20250127_1311.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__:1.12.1+cu113\n",
      "torch.version.cuda:11.3\n",
      "torch.backends.cudnn.version:8302\n",
      "torch.backends.cudnn.enabled:True\n",
      "[2025-01-27 13:12:02,881 evaluate_merged.py line 164] arch_3d: MinkUNet18A\n",
      "data_root: dataset/data/replica_split\n",
      "data_root_2d_fused_feature: data/replica_multiview_openseg\n",
      "dist_backend: nccl\n",
      "dist_url: tcp://127.0.0.1:6787\n",
      "distributed: False\n",
      "eval_iou: False\n",
      "exp_dir: ./experiments/openscene/replica_split\n",
      "feature_2d_extractor: lseg\n",
      "feature_type: distill\n",
      "input_color: False\n",
      "labelset: matterport\n",
      "manual_seed: 3407\n",
      "mark_no_feature_to_unknown: True\n",
      "model_path: https://cvg-data.inf.ethz.ch/openscene/models/matterport_lseg.pth.tar\n",
      "multiprocessing_distributed: False\n",
      "ngpus_per_node: 1\n",
      "prompt_eng: True\n",
      "rank: 0\n",
      "save_feature_as_numpy: True\n",
      "save_folder: /cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning\n",
      "split: all\n",
      "sync_bn: False\n",
      "test_batch_size: 1\n",
      "test_gpu: [0]\n",
      "test_repeats: 1\n",
      "test_workers: 0\n",
      "use_apex: False\n",
      "use_augmentations: True\n",
      "use_shm: False\n",
      "vis_gt: False\n",
      "vis_input: False\n",
      "vis_pred: False\n",
      "voxel_size: 0.02\n",
      "world_size: 1\n",
      "['dataset/data/replica_split/test/office4.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_0.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_1.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_2.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_3.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_4.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_5.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_6.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_7.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_8.pth', 'dataset/data/replica_split/test/office4_augmentations/office4_9.pth', 'dataset/data/replica_split/test/room2.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_0.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_1.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_2.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_3.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_4.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_5.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_6.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_7.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_8.pth', 'dataset/data/replica_split/test/room2_augmentations/room2_9.pth', 'dataset/data/replica_split/train/office0.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_0.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_1.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_2.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_3.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_4.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_5.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_6.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_7.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_8.pth', 'dataset/data/replica_split/train/office0_augmentations/office0_9.pth', 'dataset/data/replica_split/train/office1.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_0.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_1.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_2.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_3.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_4.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_5.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_6.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_7.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_8.pth', 'dataset/data/replica_split/train/office1_augmentations/office1_9.pth', 'dataset/data/replica_split/train/office2.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_0.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_1.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_2.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_3.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_4.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_5.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_6.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_7.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_8.pth', 'dataset/data/replica_split/train/office2_augmentations/office2_9.pth', 'dataset/data/replica_split/train/room0.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_0.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_1.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_2.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_3.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_4.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_5.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_6.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_7.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_8.pth', 'dataset/data/replica_split/train/room0_augmentations/room0_9.pth', 'dataset/data/replica_split/val/office3.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_0.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_1.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_2.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_3.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_4.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_5.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_6.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_7.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_8.pth', 'dataset/data/replica_split/val/office3_augmentations/office3_9.pth', 'dataset/data/replica_split/val/room1.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_0.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_1.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_2.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_3.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_4.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_5.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_6.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_7.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_8.pth', 'dataset/data/replica_split/val/room1_augmentations/room1_9.pth']\n",
      "Use prompt engineering: a XX in a scene\n",
      "Loading CLIP ViT-B/32 model...\n",
      "Finish loading\n",
      "[2025-01-27 13:12:07,169 evaluate_merged.py line 288] \n",
      "Evaluation 1 out of 1 runs...\n",
      "\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      "  1%|          | 1/88 [00:26<37:50, 26.10s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      "  2%|▏         | 2/88 [01:01<45:13, 31.55s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      "  3%|▎         | 3/88 [01:35<45:59, 32.46s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      "  5%|▍         | 4/88 [02:08<46:05, 32.92s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      "  6%|▌         | 5/88 [02:42<46:03, 33.30s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      "  7%|▋         | 6/88 [03:16<45:47, 33.50s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      "  8%|▊         | 7/88 [03:50<45:15, 33.52s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      "  9%|▉         | 8/88 [04:24<44:53, 33.67s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      " 10%|█         | 9/88 [04:58<44:33, 33.84s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      " 11%|█▏        | 10/88 [05:32<44:10, 33.97s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/office4_mesh.ply\u001b[0;m\n",
      " 12%|█▎        | 11/88 [06:06<43:37, 33.99s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 14%|█▎        | 12/88 [06:31<39:33, 31.24s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 15%|█▍        | 13/88 [06:56<36:46, 29.42s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 16%|█▌        | 14/88 [07:21<34:30, 27.97s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 17%|█▋        | 15/88 [07:46<33:05, 27.20s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 18%|█▊        | 16/88 [08:12<32:00, 26.68s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 19%|█▉        | 17/88 [08:37<30:58, 26.18s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 20%|██        | 18/88 [09:02<30:05, 25.79s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 22%|██▏       | 19/88 [09:27<29:21, 25.53s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 23%|██▎       | 20/88 [09:51<28:43, 25.34s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 24%|██▍       | 21/88 [10:16<28:09, 25.22s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/test/room2_mesh.ply\u001b[0;m\n",
      " 25%|██▌       | 22/88 [10:42<27:49, 25.30s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 26%|██▌       | 23/88 [11:03<25:57, 23.97s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 27%|██▋       | 24/88 [11:23<24:31, 23.00s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 28%|██▊       | 25/88 [11:44<23:14, 22.13s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 30%|██▉       | 26/88 [12:04<22:25, 21.70s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 31%|███       | 27/88 [12:25<21:43, 21.37s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 32%|███▏      | 28/88 [12:45<21:01, 21.02s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 33%|███▎      | 29/88 [13:05<20:26, 20.78s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 34%|███▍      | 30/88 [13:26<19:59, 20.68s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 35%|███▌      | 31/88 [13:46<19:35, 20.63s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 36%|███▋      | 32/88 [14:07<19:16, 20.65s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office0_mesh.ply\u001b[0;m\n",
      " 38%|███▊      | 33/88 [14:27<18:50, 20.55s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 39%|███▊      | 34/88 [14:42<16:54, 18.79s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 40%|███▉      | 35/88 [14:57<15:28, 17.52s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 41%|████      | 36/88 [15:11<14:24, 16.62s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 42%|████▏     | 37/88 [15:26<13:34, 15.97s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 43%|████▎     | 38/88 [15:40<12:56, 15.53s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 44%|████▍     | 39/88 [15:55<12:31, 15.33s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 45%|████▌     | 40/88 [16:10<12:12, 15.26s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 47%|████▋     | 41/88 [16:25<11:52, 15.15s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 48%|████▊     | 42/88 [16:40<11:34, 15.10s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 49%|████▉     | 43/88 [16:55<11:13, 14.98s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office1_mesh.ply\u001b[0;m\n",
      " 50%|█████     | 44/88 [17:09<10:53, 14.84s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 51%|█████     | 45/88 [17:38<13:44, 19.18s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 52%|█████▏    | 46/88 [18:08<15:36, 22.31s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 53%|█████▎    | 47/88 [18:38<16:46, 24.56s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 55%|█████▍    | 48/88 [19:08<17:24, 26.12s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 56%|█████▌    | 49/88 [19:37<17:40, 27.19s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 57%|█████▋    | 50/88 [20:07<17:39, 27.87s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 58%|█████▊    | 51/88 [20:37<17:32, 28.45s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 59%|█████▉    | 52/88 [21:07<17:22, 28.97s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 60%|██████    | 53/88 [21:36<16:57, 29.07s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 61%|██████▏   | 54/88 [22:06<16:40, 29.44s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/train/office2_mesh.ply\u001b[0;m\n",
      " 75%|███████▌  | 66/88 [28:41<12:08, 33.14s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 76%|███████▌  | 67/88 [29:22<12:22, 35.38s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 77%|███████▋  | 68/88 [30:03<12:19, 36.96s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 78%|███████▊  | 69/88 [30:45<12:10, 38.45s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 80%|███████▉  | 70/88 [31:26<11:46, 39.24s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 81%|████████  | 71/88 [32:07<11:14, 39.69s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 82%|████████▏ | 72/88 [32:47<10:41, 40.07s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 83%|████████▎ | 73/88 [33:29<10:06, 40.44s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 84%|████████▍ | 74/88 [34:09<09:23, 40.23s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 85%|████████▌ | 75/88 [34:46<08:34, 39.54s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 86%|████████▋ | 76/88 [35:24<07:48, 39.08s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/office3_mesh.ply\u001b[0;m\n",
      " 88%|████████▊ | 77/88 [36:03<07:07, 38.86s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 89%|████████▊ | 78/88 [36:23<05:33, 33.39s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 90%|████████▉ | 79/88 [36:37<04:08, 27.60s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 91%|█████████ | 80/88 [36:58<03:23, 25.48s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 92%|█████████▏| 81/88 [37:19<02:48, 24.01s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 93%|█████████▎| 82/88 [37:39<02:17, 22.97s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 94%|█████████▍| 83/88 [38:00<01:51, 22.22s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 95%|█████████▌| 84/88 [38:20<01:26, 21.74s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 97%|█████████▋| 85/88 [38:41<01:04, 21.44s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 98%|█████████▊| 86/88 [39:02<00:42, 21.30s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      " 99%|█████████▉| 87/88 [39:23<00:21, 21.21s/it]\u001b[1;33m[Open3D WARNING] Read PLY failed: A polygon in the mesh could not be decomposed into triangles.\u001b[0;m\n",
      "RPly: Aborted by user\n",
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to read file: dataset/data/replica_split/val/room1_mesh.ply\u001b[0;m\n",
      "100%|██████████| 88/88 [39:44<00:00, 27.10s/it]\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$output_path\"\n",
    "# Run openscene\n",
    "set -x\n",
    "\n",
    "exp_dir=\"$1/openscene/prompt_learning\"\n",
    "config=\"./config/openscene/replica/replica_lseg_aug.yaml\"\n",
    "feature_type=distill\n",
    "\n",
    "mkdir -p \"${exp_dir}\"\n",
    "result_dir=\"${exp_dir}\"\n",
    "\n",
    "export PYTHONPATH=\"models/openscene\"\n",
    "python -u models/openscene/run/evaluate_merged.py \\\n",
    "  --config=${config} \\\n",
    "  feature_type ${feature_type} \\\n",
    "  save_folder ${result_dir} \\\n",
    "  2>&1 | tee -a ${exp_dir}/eval-$(date +\"%Y%m%d_%H%M\").log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance masks:  8\n",
      "Per point features:  88\n",
      "Processing office4:\n",
      "Masks shape: torch.Size([71, 993008])\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_0_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_1_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_2_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_3_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_4_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_5_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_6_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_7_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_8_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_9_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/office4_features.npy\n",
      "Features shape: (993008, 512)\n",
      "(71, 512)\n",
      "Mean instance feature list shape:  (11, 71, 512)\n",
      "Saved instance features for office4\n",
      "Processing room2:\n",
      "Masks shape: torch.Size([61, 722496])\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_0_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_1_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_2_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_3_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_4_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_5_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_6_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_7_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_8_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_9_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/test/room2_features.npy\n",
      "Features shape: (722496, 512)\n",
      "(61, 512)\n",
      "Mean instance feature list shape:  (11, 61, 512)\n",
      "Saved instance features for room2\n",
      "Processing office0:\n",
      "Masks shape: torch.Size([68, 589517])\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_0_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_1_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_2_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_3_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_4_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_5_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_6_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_7_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_8_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_9_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office0_features.npy\n",
      "Features shape: (589517, 512)\n",
      "(68, 512)\n",
      "Mean instance feature list shape:  (11, 68, 512)\n",
      "Saved instance features for office0\n",
      "Processing office1:\n",
      "Masks shape: torch.Size([52, 423007])\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_0_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_1_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_2_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_3_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_4_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_5_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_6_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_7_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_8_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_9_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office1_features.npy\n",
      "Features shape: (423007, 512)\n",
      "(52, 512)\n",
      "Mean instance feature list shape:  (11, 52, 512)\n",
      "Saved instance features for office1\n",
      "Processing office2:\n",
      "Masks shape: torch.Size([94, 858623])\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_0_features.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_1_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_2_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_3_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_4_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_5_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_6_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_7_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_8_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_9_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/office2_features.npy\n",
      "Features shape: (858623, 512)\n",
      "(94, 512)\n",
      "Mean instance feature list shape:  (11, 94, 512)\n",
      "Saved instance features for office2\n",
      "Processing room0:\n",
      "Masks shape: torch.Size([94, 954492])\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_0_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_1_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_2_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_3_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_4_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_5_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_6_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_7_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_8_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_9_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/train/room0_features.npy\n",
      "Features shape: (954492, 512)\n",
      "(94, 512)\n",
      "Mean instance feature list shape:  (11, 94, 512)\n",
      "Saved instance features for room0\n",
      "Processing office3:\n",
      "Masks shape: torch.Size([113, 1187140])\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_0_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_1_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_2_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_3_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_4_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_5_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_6_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_7_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_8_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_9_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/office3_features.npy\n",
      "Features shape: (1187140, 512)\n",
      "(113, 512)\n",
      "Mean instance feature list shape:  (11, 113, 512)\n",
      "Saved instance features for office3\n",
      "Processing room1:\n",
      "Masks shape: torch.Size([57, 645512])\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_0_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_1_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_2_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_3_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_4_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_5_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_6_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_7_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_8_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_9_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "/cluster/54/blessman/ml3d/experiments/merged_pipline/run_2025-01-27-00-42-47/openscene/prompt_learning/val/room1_features.npy\n",
      "Features shape: (645512, 512)\n",
      "(57, 512)\n",
      "Mean instance feature list shape:  (11, 57, 512)\n",
      "Saved instance features for room1\n"
     ]
    }
   ],
   "source": [
    "import experiment\n",
    "import utils\n",
    "output_path = experiment.get_current_path()\n",
    "utils.merge_extracted_features_augmented(output_path, num_aug=num_augmentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize augmented scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "base_path = \"dataset/data/replica_split\"\n",
    "point_cloud_files = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(base_path)\n",
    "    for file in files\n",
    "    if file.endswith(\".pth\")\n",
    "]\n",
    "len(point_cloud_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5848cf1bb9084cf68ac2fe02269d84d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616f4b46ac7b449089c888516c346804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce6af6495bb410bac833ac9ec79092f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f21a9cce63340baae20c1915f910466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fc859b9d114c889123a12d5f690994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef89c3dda1c84fe8b508389b82b8677c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c868ed9879548e3a9364ffd84b59f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a59897adfec4826ac1d39ce33745938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a749ac5d35374466bc159cc512dd0b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255 ... 255 255 255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef5fafb26e04c7484315dd8a58ee752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from point_cloud import visualize_point_cloud_with_k3d\n",
    "\n",
    "for point_cloud_file in point_cloud_files[:10]:\n",
    "    coords, colors, labels = torch.load(point_cloud_file)\n",
    "    \n",
    "    visualize_point_cloud_with_k3d(coords, colors).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ground truth textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import utils\n",
    "import point_cloud\n",
    "import clip_utils\n",
    "import numpy as np\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"dataset/data/replica_split/ground_truth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/data/replica_split/ground_truth/office0.npy',\n",
       " 'dataset/data/replica_split/ground_truth/office1.npy',\n",
       " 'dataset/data/replica_split/ground_truth/office2.npy',\n",
       " 'dataset/data/replica_split/ground_truth/office3.npy',\n",
       " 'dataset/data/replica_split/ground_truth/office4.npy',\n",
       " 'dataset/data/replica_split/ground_truth/room0.npy',\n",
       " 'dataset/data/replica_split/ground_truth/room1.npy',\n",
       " 'dataset/data/replica_split/ground_truth/room2.npy']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = utils.get_all_files_in_dir(gt_path, \"npy\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_point_ids = np.load(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT id:  38\n",
      "Label:  table\n"
     ]
    }
   ],
   "source": [
    "use_id = per_point_ids[36464]\n",
    "print(\"GT id: \", use_id)\n",
    "print(\"Label: \", clip_utils.get_label(use_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_mask = per_point_ids == use_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b875c59f09464d87881c4f2be0a7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f44424b41e462b969858fd09cbc735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coords, colors, _ = torch.load(\"dataset/data/replica_split/train/office0.pth\")\n",
    "point_cloud.visualize_point_cloud_with_k3d(coords, colors).display()\n",
    "\n",
    "colors = (colors + 1) / 2\n",
    "colors = (colors * 255).astype(np.uint64)\n",
    "\n",
    "colors[tv_mask] = (214., 39., 40.)\n",
    "\n",
    "point_cloud.visualize_point_cloud_with_k3d(coords, colors, is_rgb=True, is_norm=True).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGNORE THIS FOR NOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/openscene\")\n",
    "sys.path.append(\"dataset\")\n",
    "\n",
    "from models.mink_unet import mink_unet as model3D\n",
    "from torch import nn\n",
    "from torch.utils import model_zoo\n",
    "from voxelizer import Voxelizer\n",
    "import experiment\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import augmentations\n",
    "\n",
    "from MinkowskiEngine import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/data/replica_split/test/room2.pth', 'dataset/data/replica_split/test/office4.pth', 'dataset/data/replica_split/val/room1.pth', 'dataset/data/replica_split/val/office3.pth', 'dataset/data/replica_split/train/office2.pth', 'dataset/data/replica_split/train/room0.pth', 'dataset/data/replica_split/train/office0.pth', 'dataset/data/replica_split/train/office1.pth']\n"
     ]
    }
   ],
   "source": [
    "gt_path = \"dataset/OpenYOLO3D/output/replica/replica_ground_truth_masks\"\n",
    "point_cloud_base_path = \"dataset/data/replica_split\"\n",
    "point_cloud_files = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(point_cloud_base_path)\n",
    "    for file in files\n",
    "    if file.endswith(\".pth\")\n",
    "]\n",
    "print(point_cloud_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new experiment folder: experiments/merged_pipline/run_2025-01-27-10-48-29\n"
     ]
    }
   ],
   "source": [
    "current_path = experiment.setup_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructor3d(**kwargs):\n",
    "    model = model3D(**kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "class DisNet(nn.Module):\n",
    "    '''3D Sparse UNet for Distillation.'''\n",
    "    def __init__(self, cfg=None):\n",
    "        super(DisNet, self).__init__()\n",
    "        last_dim = 512\n",
    "\n",
    "        # MinkowskiNet for 3D point clouds\n",
    "        net3d = constructor3d(in_channels=3, out_channels=last_dim, D=3, arch=\"MinkUNet18A\")\n",
    "        self.net3d = net3d\n",
    "\n",
    "    def forward(self, sparse_3d):\n",
    "        '''Forward method.'''\n",
    "        return self.net3d(sparse_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DisNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"https://cvg-data.inf.ethz.ch/openscene/models/matterport_lseg.pth.tar\"\n",
    "checkpoint = model_zoo.load_url(model_path, progress=True)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler():\n",
    "    \n",
    "    # Augmentation arguments\n",
    "    SCALE_AUGMENTATION_BOUND = (0.9, 1.1)\n",
    "    ROTATION_AUGMENTATION_BOUND = ((-np.pi / 64, np.pi / 64), (-np.pi / 64, np.pi / 64), (-np.pi,\n",
    "                                                                                          np.pi))\n",
    "    TRANSLATION_AUGMENTATION_RATIO_BOUND = ((-0.2, 0.2), (-0.2, 0.2), (0, 0))\n",
    "    ELASTIC_DISTORT_PARAMS = ((0.2, 0.4), (0.8, 1.6))\n",
    "\n",
    "    ROTATION_AXIS = 'z'\n",
    "    LOCFEAT_IDX = 2\n",
    "    \n",
    "    def __init__(self, use_color, voxel_size, use_augmentation):\n",
    "        self.voxelizer = Voxelizer(\n",
    "                voxel_size=voxel_size,\n",
    "                clip_bound=None,\n",
    "                use_augmentation=use_augmentation,\n",
    "                scale_augmentation_bound=self.SCALE_AUGMENTATION_BOUND,\n",
    "                rotation_augmentation_bound=self.ROTATION_AUGMENTATION_BOUND,\n",
    "                translation_augmentation_ratio_bound=self.TRANSLATION_AUGMENTATION_RATIO_BOUND)\n",
    "        self.use_color = use_color\n",
    "    \n",
    "    def get_point_cloud_samples(self, locs, feats_in, labels):\n",
    "        # no color in the input point cloud, e.g nuscenes\n",
    "        if np.isscalar(feats_in) and feats_in == 0:\n",
    "            feats_in = np.zeros_like(locs_in)\n",
    "        feats_in = (feats_in + 1.) * 127.5\n",
    "\n",
    "        locs, feats, _, inds_reconstruct = self.voxelizer.voxelize(\n",
    "            locs, feats_in, labels)\n",
    "        coords = torch.from_numpy(locs).int()\n",
    "        coords = torch.cat(\n",
    "            (torch.ones(coords.shape[0], 1, dtype=torch.int), coords), dim=1)\n",
    "        if self.use_color:\n",
    "            feats = torch.from_numpy(feats).float() / 127.5 - 1.\n",
    "        else:\n",
    "            feats = torch.ones(coords.shape[0], 3)\n",
    "        return coords, feats, torch.from_numpy(inds_reconstruct).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_color = False\n",
    "use_vox_augmentation = False\n",
    "data_handler = DataHandler(use_color=use_color, voxel_size=0.02, use_augmentation=use_vox_augmentation)\n",
    "num_augmentatibns_per_instance = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [32,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [33,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [34,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [35,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [36,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [37,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [38,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [39,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [40,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [41,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [42,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [43,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [44,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [45,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [46,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [47,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [48,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [49,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [50,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [51,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [52,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [53,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [54,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [55,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [56,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [57,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [58,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [59,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [60,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [61,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [62,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:91: operator(): block: [211524,0,0], thread: [63,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model(sinput)\n\u001b[1;32m     50\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m predictions[inds_reverse, :]\n\u001b[0;32m---> 51\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "for point_cloud_file in point_cloud_files:\n",
    "    coords, colors, labels = torch.load(point_cloud_file)\n",
    "    \n",
    "    sample_name = os.path.basename(point_cloud_file).split('.')[0]\n",
    "    \n",
    "    gt_mask,_ = torch.load(os.path.join(gt_path, f\"{sample_name}.pt\"))\n",
    "    mask = gt_mask[:,5] != 0\n",
    "    \n",
    "    \n",
    "    for mask in gt_mask.T:\n",
    "        mask = mask != 0\n",
    "        instance_coords = coords.copy()\n",
    "        instance_colors = colors.copy()\n",
    "        \n",
    "        batch = data_handler.get_point_cloud_samples(instance_coords, instance_colors, labels)\n",
    "        transformed_instance_coords, transformed_instance_colors, transformed_instance_colors_recon = batch\n",
    "        \n",
    "        transformed_instances_coords = [transformed_instance_coords]\n",
    "        transformed_instances_colors = [transformed_instance_colors]\n",
    "        transformed_instances_recon = [transformed_instance_recon]\n",
    "        \n",
    "        for _ in range(num_augmentations_per_instance-1):\n",
    "            aug_instance_coords = coords.copy()\n",
    "            aug_instance_colors = colors.copy()\n",
    "            aug_instance_coords[mask], aug_instance_colors[mask] = augmentations.random_augmentation(\n",
    "                aug_instance_coords[mask], aug_instance_colors[mask]\n",
    "            )\n",
    "            \n",
    "            batch = data_handler.get_point_cloud_samples(aug_instance_coords, aug_instance_colors, labels)\n",
    "            transformed_instance_coords, transformed_instance_colors, transformed_instance_colors_recon = batch                                                                                                                                  \n",
    "                                                                                                                                          \n",
    "            transformed_instances_coords.append(transformed_instance_coords)\n",
    "            transformed_instances_colors.append(transformed_instance_colors)\n",
    "            transformed_instances_recon.append(transformed_instance_colors_recon)\n",
    "\n",
    "        # Stack augmented versions into a single tensor\n",
    "        #coords = torch.stack(transformed_instances_coords)\n",
    "        #feat = torch.stack(transformed_instances_colors)\n",
    "        #inds_reverse = torch.stack(transformed_instances_recon)\n",
    "        for i in range(len(transformed_instances_coords)):\n",
    "            coords = transformed_instances_coords[i]\n",
    "            feat = transformed_instances_colors[i]\n",
    "            inds_reverse = transformed_instances_recon[i]\n",
    "            sinput = SparseTensor(feat.cuda(non_blocking=True), coords.cuda(non_blocking=True))\n",
    "\n",
    "            # Use openscene to get features\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                predictions = model(sinput)\n",
    "                predictions = predictions[inds_reverse, :]\n",
    "                predictions = predictions.cpu().numpy()\n",
    "\n",
    "            print(predictions.shape)\n",
    "            break\n",
    "        break   \n",
    "    \n",
    "    #visualize_point_cloud_with_k3d(coords, colors).display()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
